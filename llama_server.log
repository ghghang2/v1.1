ggml_cuda_init: found 1 CUDA devices:
  Device 0: Tesla T4, compute capability 7.5, VMM: yes
common_download_file_single_online: no previous model file found /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_preset.ini
common_download_file_single_online: HEAD invalid http status code received: 404
no remote preset found, skipping
common_download_file_single_online: no previous model file found /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf
common_download_file_single_online: trying to download model from https://huggingface.co/unsloth/gpt-oss-20b-GGUF/resolve/main/gpt-oss-20b-F16.gguf to /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf.downloadInProgress (etag:"78f73a4ef91c8f92d4df971f570ff3719007201f6d955b8695384a1b21b04a80")...
main: n_parallel is set to auto, using n_parallel = 4 and kv_unified = true
build: 7772 (287a33017) with GNU 11.4.0 for Linux x86_64
system info: n_threads = 1, n_threads_batch = 1, total_threads = 2

system_info: n_threads = 1 (n_threads_batch = 1) / 2 | CUDA : ARCHS = 750 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | 

Running without SSL
init: using 6 threads for HTTP server
start: binding port with default address family
main: loading model
srv    load_model: loading model '/root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf'
common_init_result: fitting params to device memory, for bugs during this step try to reproduce them with -fit off, or provide --verbose logs if the bug only occurs with -fit on
srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
llama_params_fit_impl: projected to use 15546 MiB of device memory vs. 14992 MiB of free device memory
llama_params_fit_impl: cannot meet free memory target of 1024 MiB, need to reduce device memory by 1578 MiB
srv  log_server_r: request: GET /health 127.0.0.1 503
llama_params_fit_impl: context size reduced from 131072 to 64000 -> need 1580 MiB less memory in total
llama_params_fit_impl: entire model can be fit by reducing context
llama_params_fit: successfully fit params to free device memory
llama_params_fit: fitting params to free memory took 2.49 seconds
llama_model_load_from_file_impl: using device CUDA0 (Tesla T4) (0000:00:04.0) - 14992 MiB free
llama_model_loader: direct I/O is enabled, disabling mmap
llama_model_loader: loaded meta data with 37 key-value pairs and 459 tensors from /root/.cache/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-F16.gguf (version GGUF V3 (latest))
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = gpt-oss
llama_model_loader: - kv   1:                               general.type str              = model
llama_model_loader: - kv   2:                               general.name str              = Gpt-Oss-20B
llama_model_loader: - kv   3:                           general.basename str              = Gpt-Oss-20B
llama_model_loader: - kv   4:                       general.quantized_by str              = Unsloth
llama_model_loader: - kv   5:                         general.size_label str              = 20B
llama_model_loader: - kv   6:                            general.license str              = apache-2.0
llama_model_loader: - kv   7:                           general.repo_url str              = https://huggingface.co/unsloth
llama_model_loader: - kv   8:                               general.tags arr[str,2]       = ["vllm", "text-generation"]
llama_model_loader: - kv   9:                        gpt-oss.block_count u32              = 24
llama_model_loader: - kv  10:                     gpt-oss.context_length u32              = 131072
llama_model_loader: - kv  11:                   gpt-oss.embedding_length u32              = 2880
llama_model_loader: - kv  12:                gpt-oss.feed_forward_length u32              = 2880
llama_model_loader: - kv  13:               gpt-oss.attention.head_count u32              = 64
llama_model_loader: - kv  14:            gpt-oss.attention.head_count_kv u32              = 8
llama_model_loader: - kv  15:                     gpt-oss.rope.freq_base f32              = 150000.000000
llama_model_loader: - kv  16:   gpt-oss.attention.layer_norm_rms_epsilon f32              = 0.000010
llama_model_loader: - kv  17:                       gpt-oss.expert_count u32              = 32
llama_model_loader: - kv  18:                  gpt-oss.expert_used_count u32              = 4
llama_model_loader: - kv  19:               gpt-oss.attention.key_length u32              = 64
llama_model_loader: - kv  20:             gpt-oss.attention.value_length u32              = 64
llama_model_loader: - kv  21:                          general.file_type u32              = 1
llama_model_loader: - kv  22:           gpt-oss.attention.sliding_window u32              = 128
llama_model_loader: - kv  23:         gpt-oss.expert_feed_forward_length u32              = 2880
llama_model_loader: - kv  24:                  gpt-oss.rope.scaling.type str              = yarn
llama_model_loader: - kv  25:                gpt-oss.rope.scaling.factor f32              = 32.000000
llama_model_loader: - kv  26: gpt-oss.rope.scaling.original_context_length u32              = 4096
llama_model_loader: - kv  27:               general.quantization_version u32              = 2
llama_model_loader: - kv  28:                       tokenizer.ggml.model str              = gpt2
llama_model_loader: - kv  29:                         tokenizer.ggml.pre str              = gpt-4o
llama_model_loader: - kv  30:                      tokenizer.ggml.tokens arr[str,201088]  = ["!", "\"", "#", "$", "%", "&", "'", ...
llama_model_loader: - kv  31:                  tokenizer.ggml.token_type arr[i32,201088]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
llama_model_loader: - kv  32:                      tokenizer.ggml.merges arr[str,446189]  = ["Ġ Ġ", "Ġ ĠĠĠ", "ĠĠ ĠĠ", "...
llama_model_loader: - kv  33:                tokenizer.ggml.bos_token_id u32              = 199998
llama_model_loader: - kv  34:                tokenizer.ggml.eos_token_id u32              = 200002
llama_model_loader: - kv  35:            tokenizer.ggml.padding_token_id u32              = 200017
llama_model_loader: - kv  36:                    tokenizer.chat_template str              = {# Chat template fixes by Unsloth #}\n...
llama_model_loader: - type  f32:  289 tensors
llama_model_loader: - type  f16:   98 tensors
llama_model_loader: - type mxfp4:   72 tensors
print_info: file format = GGUF V3 (latest)
print_info: file type   = F16
print_info: file size   = 12.83 GiB (5.27 BPW) 
srv  log_server_r: request: GET /health 127.0.0.1 503
load: 0 unused tokens
load: setting token '<|message|>' (200008) attribute to USER_DEFINED (16), old attributes: 8
load: setting token '<|start|>' (200006) attribute to USER_DEFINED (16), old attributes: 8
load: setting token '<|constrain|>' (200003) attribute to USER_DEFINED (16), old attributes: 8
load: setting token '<|channel|>' (200005) attribute to USER_DEFINED (16), old attributes: 8
load: printing all EOG tokens:
load:   - 199999 ('<|endoftext|>')
load:   - 200002 ('<|return|>')
load:   - 200007 ('<|end|>')
load:   - 200012 ('<|call|>')
load: special_eog_ids contains both '<|return|>' and '<|call|>', or '<|calls|>' and '<|flush|>' tokens, removing '<|end|>' token from EOG list
load: special tokens cache size = 21
load: token to piece cache size = 1.3332 MB
print_info: arch                  = gpt-oss
print_info: vocab_only            = 0
print_info: no_alloc              = 0
print_info: n_ctx_train           = 131072
print_info: n_embd                = 2880
print_info: n_embd_inp            = 2880
print_info: n_layer               = 24
print_info: n_head                = 64
print_info: n_head_kv             = 8
print_info: n_rot                 = 64
print_info: n_swa                 = 128
print_info: is_swa_any            = 1
print_info: n_embd_head_k         = 64
print_info: n_embd_head_v         = 64
print_info: n_gqa                 = 8
print_info: n_embd_k_gqa          = 512
print_info: n_embd_v_gqa          = 512
print_info: f_norm_eps            = 0.0e+00
print_info: f_norm_rms_eps        = 1.0e-05
print_info: f_clamp_kqv           = 0.0e+00
print_info: f_max_alibi_bias      = 0.0e+00
print_info: f_logit_scale         = 0.0e+00
print_info: f_attn_scale          = 0.0e+00
print_info: n_ff                  = 2880
print_info: n_expert              = 32
print_info: n_expert_used         = 4
print_info: n_expert_groups       = 0
print_info: n_group_used          = 0
print_info: causal attn           = 1
print_info: pooling type          = 0
print_info: rope type             = 2
print_info: rope scaling          = yarn
print_info: freq_base_train       = 150000.0
print_info: freq_scale_train      = 0.03125
print_info: freq_base_swa         = 150000.0
print_info: freq_scale_swa        = 0.03125
print_info: n_ctx_orig_yarn       = 4096
print_info: rope_yarn_log_mul     = 0.0000
print_info: rope_finetuned        = unknown
print_info: model type            = 20B
print_info: model params          = 20.91 B
print_info: general.name          = Gpt-Oss-20B
print_info: n_ff_exp              = 2880
print_info: vocab type            = BPE
print_info: n_vocab               = 201088
print_info: n_merges              = 446189
print_info: BOS token             = 199998 '<|startoftext|>'
print_info: EOS token             = 200002 '<|return|>'
print_info: EOT token             = 199999 '<|endoftext|>'
print_info: PAD token             = 200017 '<|reserved_200017|>'
print_info: LF token              = 198 'Ċ'
print_info: EOG token             = 199999 '<|endoftext|>'
print_info: EOG token             = 200002 '<|return|>'
print_info: EOG token             = 200012 '<|call|>'
print_info: max token length      = 256
load_tensors: loading model tensors, this can take a while... (mmap = false, direct_io = true)
srv  log_server_r: request: GET /health 127.0.0.1 503
load_tensors: offloading output layer to GPU
load_tensors: offloading 23 repeating layers to GPU
load_tensors: offloaded 25/25 layers to GPU
load_tensors:        CUDA0 model buffer size = 12036.68 MiB
load_tensors:    CUDA_Host model buffer size =  1104.61 MiB
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
...srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
..srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
.srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
srv  log_server_r: request: GET /health 127.0.0.1 503
.
common_init_result: added <|endoftext|> logit bias = -inf
common_init_result: added <|return|> logit bias = -inf
common_init_result: added <|call|> logit bias = -inf
llama_context: constructing llama_context
llama_context: n_seq_max     = 4
llama_context: n_ctx         = 64000
llama_context: n_ctx_seq     = 64000
llama_context: n_batch       = 2048
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = auto
llama_context: kv_unified    = true
llama_context: freq_base     = 150000.0
llama_context: freq_scale    = 0.03125
llama_context: n_ctx_seq (64000) < n_ctx_train (131072) -- the full capacity of the model will not be utilized
llama_context:  CUDA_Host  output buffer size =     3.07 MiB
llama_kv_cache_iswa: creating non-SWA KV cache, size = 64000 cells
llama_kv_cache:      CUDA0 KV buffer size =  1500.00 MiB
llama_kv_cache: size = 1500.00 MiB ( 64000 cells,  12 layers,  4/1 seqs), K (f16):  750.00 MiB, V (f16):  750.00 MiB
llama_kv_cache_iswa: creating     SWA KV cache, size = 1024 cells
llama_kv_cache:      CUDA0 KV buffer size =    24.00 MiB
llama_kv_cache: size =   24.00 MiB (  1024 cells,  12 layers,  4/1 seqs), K (f16):   12.00 MiB, V (f16):   12.00 MiB
sched_reserve: reserving ...
sched_reserve: Flash Attention was auto, set to enabled
sched_reserve:      CUDA0 compute buffer size =   398.38 MiB
sched_reserve:  CUDA_Host compute buffer size =   132.65 MiB
sched_reserve: graph nodes  = 1352
sched_reserve: graph splits = 2
sched_reserve: reserve took 97.02 ms, sched copies = 1
common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)
srv    load_model: initializing slots, n_slots = 4
slot   load_model: id  0 | task -1 | new slot, n_ctx = 64000
slot   load_model: id  1 | task -1 | new slot, n_ctx = 64000
slot   load_model: id  2 | task -1 | new slot, n_ctx = 64000
slot   load_model: id  3 | task -1 | new slot, n_ctx = 64000
srv    load_model: prompt cache is enabled, size limit: 8192 MiB
srv    load_model: use `--cache-ram 0` to disable the prompt cache
srv    load_model: for more info see https://github.com/ggml-org/llama.cpp/pull/16391
srv    load_model: thinking = 0
load_model: chat template, example_format: '<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2026-02-07

Reasoning: medium

# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions

You are a helpful assistant<|end|><|start|>user<|message|>Hello<|end|><|start|>assistant<|channel|>final<|message|>Hi there<|end|><|start|>user<|message|>How are you?<|end|><|start|>assistant'
main: model loaded
main: server is listening on http://127.0.0.1:8000
main: starting the main loop...
srv  update_slots: all slots are idle
srv  log_server_r: request: GET /health 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LRU, t_last = -1
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 0 | processing task, is_child = 0
slot update_slots: id  3 | task 0 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 408
slot update_slots: id  3 | task 0 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 0 | prompt processing progress, n_tokens = 344, batch.n_tokens = 344, progress = 0.843137
slot update_slots: id  3 | task 0 | n_tokens = 344, memory_seq_rm [344, end)
slot update_slots: id  3 | task 0 | prompt processing progress, n_tokens = 408, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 0 | prompt done, n_tokens = 408, batch.n_tokens = 64
slot init_sampler: id  3 | task 0 | init sampler, took 0.09 ms, tokens: text = 408, total = 408
slot update_slots: id  3 | task 0 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 343, size = 8.067 MiB)
slot print_timing: id  3 | task 0 | 
prompt eval time =     867.59 ms /   408 tokens (    2.13 ms per token,   470.27 tokens per second)
       eval time =   14955.69 ms /   635 tokens (   23.55 ms per token,    42.46 tokens per second)
      total time =   15823.29 ms /  1043 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 0 | stop processing: n_tokens = 1042, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.926 (> 0.100 thold), f_keep = 0.385
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 1042, total state size = 48.446 MiB
srv          load:  - looking for better prompt, base f_keep = 0.385, sim = 0.926
srv        update:  - cache state: 1 prompts, 56.513 MiB (limits: 8192.000 MiB, 64000 tokens, 151046 est)
srv        update:    - prompt 0x5b74dc0d5ef0:    1042 tokens, checkpoints:  1,    56.513 MiB
srv  get_availabl: prompt cache update took 48.43 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 637 | processing task, is_child = 0
slot update_slots: id  3 | task 637 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 433
slot update_slots: id  3 | task 637 | n_tokens = 401, memory_seq_rm [401, end)
slot update_slots: id  3 | task 637 | prompt processing progress, n_tokens = 433, batch.n_tokens = 32, progress = 1.000000
slot update_slots: id  3 | task 637 | prompt done, n_tokens = 433, batch.n_tokens = 32
slot init_sampler: id  3 | task 637 | init sampler, took 0.08 ms, tokens: text = 433, total = 433
slot print_timing: id  3 | task 637 | 
prompt eval time =     188.23 ms /    32 tokens (    5.88 ms per token,   170.00 tokens per second)
       eval time =    7669.59 ms /   312 tokens (   24.58 ms per token,    40.68 tokens per second)
      total time =    7857.83 ms /   344 tokens
slot      release: id  3 | task 637 | stop processing: n_tokens = 744, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.959 (> 0.100 thold), f_keep = 0.539
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 950 | processing task, is_child = 0
slot update_slots: id  3 | task 950 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 418
slot update_slots: id  3 | task 950 | n_past = 401, slot.prompt.tokens.size() = 744, seq_id = 3, pos_min = 343, n_swa = 128
slot update_slots: id  3 | task 950 | restored context checkpoint (pos_min = 0, pos_max = 343, size = 8.067 MiB)
slot update_slots: id  3 | task 950 | n_tokens = 343, memory_seq_rm [343, end)
slot update_slots: id  3 | task 950 | prompt processing progress, n_tokens = 354, batch.n_tokens = 11, progress = 0.846890
slot update_slots: id  3 | task 950 | n_tokens = 354, memory_seq_rm [354, end)
slot update_slots: id  3 | task 950 | prompt processing progress, n_tokens = 418, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 950 | prompt done, n_tokens = 418, batch.n_tokens = 64
slot init_sampler: id  3 | task 950 | init sampler, took 0.08 ms, tokens: text = 418, total = 418
slot print_timing: id  3 | task 950 | 
prompt eval time =     343.60 ms /    75 tokens (    4.58 ms per token,   218.28 tokens per second)
       eval time =    2842.49 ms /   120 tokens (   23.69 ms per token,    42.22 tokens per second)
      total time =    3186.09 ms /   195 tokens
slot      release: id  3 | task 950 | stop processing: n_tokens = 537, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.834 (> 0.100 thold), f_keep = 0.747
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1072 | processing task, is_child = 0
slot update_slots: id  3 | task 1072 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 481
slot update_slots: id  3 | task 1072 | n_tokens = 401, memory_seq_rm [401, end)
slot update_slots: id  3 | task 1072 | prompt processing progress, n_tokens = 417, batch.n_tokens = 16, progress = 0.866944
slot update_slots: id  3 | task 1072 | n_tokens = 417, memory_seq_rm [417, end)
slot update_slots: id  3 | task 1072 | prompt processing progress, n_tokens = 481, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1072 | prompt done, n_tokens = 481, batch.n_tokens = 64
slot init_sampler: id  3 | task 1072 | init sampler, took 0.09 ms, tokens: text = 481, total = 481
slot update_slots: id  3 | task 1072 | created context checkpoint 2 of 8 (pos_min = 0, pos_max = 416, size = 9.778 MiB)
slot print_timing: id  3 | task 1072 | 
prompt eval time =     309.39 ms /    80 tokens (    3.87 ms per token,   258.57 tokens per second)
       eval time =    2538.78 ms /   103 tokens (   24.65 ms per token,    40.57 tokens per second)
      total time =    2848.17 ms /   183 tokens
slot      release: id  3 | task 1072 | stop processing: n_tokens = 583, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.523 (> 0.100 thold), f_keep = 0.825
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1177 | processing task, is_child = 0
slot update_slots: id  3 | task 1177 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 920
slot update_slots: id  3 | task 1177 | n_tokens = 481, memory_seq_rm [481, end)
slot update_slots: id  3 | task 1177 | prompt processing progress, n_tokens = 856, batch.n_tokens = 375, progress = 0.930435
slot update_slots: id  3 | task 1177 | n_tokens = 856, memory_seq_rm [856, end)
slot update_slots: id  3 | task 1177 | prompt processing progress, n_tokens = 920, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1177 | prompt done, n_tokens = 920, batch.n_tokens = 64
slot init_sampler: id  3 | task 1177 | init sampler, took 0.20 ms, tokens: text = 920, total = 920
slot update_slots: id  3 | task 1177 | created context checkpoint 3 of 8 (pos_min = 0, pos_max = 855, size = 20.073 MiB)
slot print_timing: id  3 | task 1177 | 
prompt eval time =     559.81 ms /   439 tokens (    1.28 ms per token,   784.19 tokens per second)
       eval time =    1723.92 ms /    68 tokens (   25.35 ms per token,    39.45 tokens per second)
      total time =    2283.73 ms /   507 tokens
slot      release: id  3 | task 1177 | stop processing: n_tokens = 987, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.936 (> 0.100 thold), f_keep = 0.932
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1247 | processing task, is_child = 0
slot update_slots: id  3 | task 1247 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 983
slot update_slots: id  3 | task 1247 | n_tokens = 920, memory_seq_rm [920, end)
slot update_slots: id  3 | task 1247 | prompt processing progress, n_tokens = 983, batch.n_tokens = 63, progress = 1.000000
slot update_slots: id  3 | task 1247 | prompt done, n_tokens = 983, batch.n_tokens = 63
slot init_sampler: id  3 | task 1247 | init sampler, took 0.20 ms, tokens: text = 983, total = 983
slot print_timing: id  3 | task 1247 | 
prompt eval time =     237.26 ms /    63 tokens (    3.77 ms per token,   265.53 tokens per second)
       eval time =    1182.65 ms /    44 tokens (   26.88 ms per token,    37.20 tokens per second)
      total time =    1419.91 ms /   107 tokens
slot      release: id  3 | task 1247 | stop processing: n_tokens = 1026, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.750 (> 0.100 thold), f_keep = 0.958
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1292 | processing task, is_child = 0
slot update_slots: id  3 | task 1292 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1310
slot update_slots: id  3 | task 1292 | n_tokens = 983, memory_seq_rm [983, end)
slot update_slots: id  3 | task 1292 | prompt processing progress, n_tokens = 1246, batch.n_tokens = 263, progress = 0.951145
slot update_slots: id  3 | task 1292 | n_tokens = 1246, memory_seq_rm [1246, end)
slot update_slots: id  3 | task 1292 | prompt processing progress, n_tokens = 1310, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1292 | prompt done, n_tokens = 1310, batch.n_tokens = 64
slot init_sampler: id  3 | task 1292 | init sampler, took 0.28 ms, tokens: text = 1310, total = 1310
slot update_slots: id  3 | task 1292 | created context checkpoint 4 of 8 (pos_min = 263, pos_max = 1245, size = 23.051 MiB)
slot print_timing: id  3 | task 1292 | 
prompt eval time =     497.55 ms /   327 tokens (    1.52 ms per token,   657.22 tokens per second)
       eval time =    1296.85 ms /    51 tokens (   25.43 ms per token,    39.33 tokens per second)
      total time =    1794.40 ms /   378 tokens
slot      release: id  3 | task 1292 | stop processing: n_tokens = 1360, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.442 (> 0.100 thold), f_keep = 0.963
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1345 | processing task, is_child = 0
slot update_slots: id  3 | task 1345 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2965
slot update_slots: id  3 | task 1345 | n_tokens = 1310, memory_seq_rm [1310, end)
slot update_slots: id  3 | task 1345 | prompt processing progress, n_tokens = 2901, batch.n_tokens = 1591, progress = 0.978415
slot update_slots: id  3 | task 1345 | n_tokens = 2901, memory_seq_rm [2901, end)
slot update_slots: id  3 | task 1345 | prompt processing progress, n_tokens = 2965, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1345 | prompt done, n_tokens = 2965, batch.n_tokens = 64
slot init_sampler: id  3 | task 1345 | init sampler, took 0.64 ms, tokens: text = 2965, total = 2965
slot update_slots: id  3 | task 1345 | created context checkpoint 5 of 8 (pos_min = 1877, pos_max = 2900, size = 24.012 MiB)
slot print_timing: id  3 | task 1345 | 
prompt eval time =    1885.45 ms /  1655 tokens (    1.14 ms per token,   877.77 tokens per second)
       eval time =    1022.42 ms /    40 tokens (   25.56 ms per token,    39.12 tokens per second)
      total time =    2907.87 ms /  1695 tokens
slot      release: id  3 | task 1345 | stop processing: n_tokens = 3004, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.758 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1387 | processing task, is_child = 0
slot update_slots: id  3 | task 1387 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3910
slot update_slots: id  3 | task 1387 | n_tokens = 2965, memory_seq_rm [2965, end)
slot update_slots: id  3 | task 1387 | prompt processing progress, n_tokens = 3846, batch.n_tokens = 881, progress = 0.983632
slot update_slots: id  3 | task 1387 | n_tokens = 3846, memory_seq_rm [3846, end)
slot update_slots: id  3 | task 1387 | prompt processing progress, n_tokens = 3910, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1387 | prompt done, n_tokens = 3910, batch.n_tokens = 64
slot init_sampler: id  3 | task 1387 | init sampler, took 0.76 ms, tokens: text = 3910, total = 3910
slot update_slots: id  3 | task 1387 | created context checkpoint 6 of 8 (pos_min = 2822, pos_max = 3845, size = 24.012 MiB)
slot print_timing: id  3 | task 1387 | 
prompt eval time =    1129.06 ms /   945 tokens (    1.19 ms per token,   836.98 tokens per second)
       eval time =    2671.60 ms /   105 tokens (   25.44 ms per token,    39.30 tokens per second)
      total time =    3800.66 ms /  1050 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 1387 | stop processing: n_tokens = 4014, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.717 (> 0.100 thold), f_keep = 0.974
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 1494 | processing task, is_child = 0
slot update_slots: id  3 | task 1494 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5453
slot update_slots: id  3 | task 1494 | n_tokens = 3910, memory_seq_rm [3910, end)
slot update_slots: id  3 | task 1494 | prompt processing progress, n_tokens = 5389, batch.n_tokens = 1479, progress = 0.988263
slot update_slots: id  3 | task 1494 | n_tokens = 5389, memory_seq_rm [5389, end)
slot update_slots: id  3 | task 1494 | prompt processing progress, n_tokens = 5453, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 1494 | prompt done, n_tokens = 5453, batch.n_tokens = 64
slot init_sampler: id  3 | task 1494 | init sampler, took 1.09 ms, tokens: text = 5453, total = 5453
slot update_slots: id  3 | task 1494 | created context checkpoint 7 of 8 (pos_min = 4365, pos_max = 5388, size = 24.012 MiB)
slot print_timing: id  3 | task 1494 | 
prompt eval time =    1768.44 ms /  1543 tokens (    1.15 ms per token,   872.52 tokens per second)
       eval time =   33870.55 ms /  1328 tokens (   25.50 ms per token,    39.21 tokens per second)
      total time =   35638.99 ms /  2871 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 1494 | stop processing: n_tokens = 6780, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.937 (> 0.100 thold), f_keep = 0.804
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 2824 | processing task, is_child = 0
slot update_slots: id  3 | task 2824 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5821
slot update_slots: id  3 | task 2824 | n_past = 5453, slot.prompt.tokens.size() = 6780, seq_id = 3, pos_min = 5756, n_swa = 128
slot update_slots: id  3 | task 2824 | restored context checkpoint (pos_min = 4365, pos_max = 5388, size = 24.012 MiB)
slot update_slots: id  3 | task 2824 | n_tokens = 5388, memory_seq_rm [5388, end)
slot update_slots: id  3 | task 2824 | prompt processing progress, n_tokens = 5757, batch.n_tokens = 369, progress = 0.989005
slot update_slots: id  3 | task 2824 | n_tokens = 5757, memory_seq_rm [5757, end)
slot update_slots: id  3 | task 2824 | prompt processing progress, n_tokens = 5821, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 2824 | prompt done, n_tokens = 5821, batch.n_tokens = 64
slot init_sampler: id  3 | task 2824 | init sampler, took 1.12 ms, tokens: text = 5821, total = 5821
slot update_slots: id  3 | task 2824 | created context checkpoint 8 of 8 (pos_min = 4733, pos_max = 5756, size = 24.012 MiB)
slot print_timing: id  3 | task 2824 | 
prompt eval time =     647.75 ms /   433 tokens (    1.50 ms per token,   668.46 tokens per second)
       eval time =    1310.21 ms /    52 tokens (   25.20 ms per token,    39.69 tokens per second)
      total time =    1957.96 ms /   485 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 2824 | stop processing: n_tokens = 5872, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.892 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 2878 | processing task, is_child = 0
slot update_slots: id  3 | task 2878 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6525
slot update_slots: id  3 | task 2878 | n_tokens = 5821, memory_seq_rm [5821, end)
slot update_slots: id  3 | task 2878 | prompt processing progress, n_tokens = 6461, batch.n_tokens = 640, progress = 0.990192
slot update_slots: id  3 | task 2878 | n_tokens = 6461, memory_seq_rm [6461, end)
slot update_slots: id  3 | task 2878 | prompt processing progress, n_tokens = 6525, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 2878 | prompt done, n_tokens = 6525, batch.n_tokens = 64
slot init_sampler: id  3 | task 2878 | init sampler, took 1.22 ms, tokens: text = 6525, total = 6525
slot update_slots: id  3 | task 2878 | erasing old context checkpoint (pos_min = 0, pos_max = 343, size = 8.067 MiB)
slot update_slots: id  3 | task 2878 | created context checkpoint 8 of 8 (pos_min = 5437, pos_max = 6460, size = 24.012 MiB)
slot print_timing: id  3 | task 2878 | 
prompt eval time =     973.43 ms /   704 tokens (    1.38 ms per token,   723.21 tokens per second)
       eval time =    9200.79 ms /   366 tokens (   25.14 ms per token,    39.78 tokens per second)
      total time =   10174.22 ms /  1070 tokens
slot      release: id  3 | task 2878 | stop processing: n_tokens = 6890, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.950 (> 0.100 thold), f_keep = 0.947
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3246 | processing task, is_child = 0
slot update_slots: id  3 | task 3246 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6870
slot update_slots: id  3 | task 3246 | n_tokens = 6525, memory_seq_rm [6525, end)
slot update_slots: id  3 | task 3246 | prompt processing progress, n_tokens = 6806, batch.n_tokens = 281, progress = 0.990684
slot update_slots: id  3 | task 3246 | n_tokens = 6806, memory_seq_rm [6806, end)
slot update_slots: id  3 | task 3246 | prompt processing progress, n_tokens = 6870, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3246 | prompt done, n_tokens = 6870, batch.n_tokens = 64
slot init_sampler: id  3 | task 3246 | init sampler, took 3.16 ms, tokens: text = 6870, total = 6870
slot update_slots: id  3 | task 3246 | erasing old context checkpoint (pos_min = 0, pos_max = 416, size = 9.778 MiB)
slot update_slots: id  3 | task 3246 | created context checkpoint 8 of 8 (pos_min = 5866, pos_max = 6805, size = 22.042 MiB)
slot print_timing: id  3 | task 3246 | 
prompt eval time =     565.01 ms /   345 tokens (    1.64 ms per token,   610.61 tokens per second)
       eval time =    1298.20 ms /    51 tokens (   25.45 ms per token,    39.29 tokens per second)
      total time =    1863.21 ms /   396 tokens
slot      release: id  3 | task 3246 | stop processing: n_tokens = 6920, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.887 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3299 | processing task, is_child = 0
slot update_slots: id  3 | task 3299 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7741
slot update_slots: id  3 | task 3299 | n_tokens = 6870, memory_seq_rm [6870, end)
slot update_slots: id  3 | task 3299 | prompt processing progress, n_tokens = 7677, batch.n_tokens = 807, progress = 0.991732
slot update_slots: id  3 | task 3299 | n_tokens = 7677, memory_seq_rm [7677, end)
slot update_slots: id  3 | task 3299 | prompt processing progress, n_tokens = 7741, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3299 | prompt done, n_tokens = 7741, batch.n_tokens = 64
slot init_sampler: id  3 | task 3299 | init sampler, took 1.75 ms, tokens: text = 7741, total = 7741
slot update_slots: id  3 | task 3299 | erasing old context checkpoint (pos_min = 0, pos_max = 855, size = 20.073 MiB)
slot update_slots: id  3 | task 3299 | created context checkpoint 8 of 8 (pos_min = 6653, pos_max = 7676, size = 24.012 MiB)
slot print_timing: id  3 | task 3299 | 
prompt eval time =    1058.93 ms /   871 tokens (    1.22 ms per token,   822.53 tokens per second)
       eval time =    1428.76 ms /    56 tokens (   25.51 ms per token,    39.19 tokens per second)
      total time =    2487.69 ms /   927 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 3299 | stop processing: n_tokens = 7796, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.953 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3357 | processing task, is_child = 0
slot update_slots: id  3 | task 3357 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8125
slot update_slots: id  3 | task 3357 | n_tokens = 7741, memory_seq_rm [7741, end)
slot update_slots: id  3 | task 3357 | prompt processing progress, n_tokens = 8061, batch.n_tokens = 320, progress = 0.992123
slot update_slots: id  3 | task 3357 | n_tokens = 8061, memory_seq_rm [8061, end)
slot update_slots: id  3 | task 3357 | prompt processing progress, n_tokens = 8125, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3357 | prompt done, n_tokens = 8125, batch.n_tokens = 64
slot init_sampler: id  3 | task 3357 | init sampler, took 1.56 ms, tokens: text = 8125, total = 8125
slot update_slots: id  3 | task 3357 | erasing old context checkpoint (pos_min = 263, pos_max = 1245, size = 23.051 MiB)
slot update_slots: id  3 | task 3357 | created context checkpoint 8 of 8 (pos_min = 7037, pos_max = 8060, size = 24.012 MiB)
slot print_timing: id  3 | task 3357 | 
prompt eval time =     571.86 ms /   384 tokens (    1.49 ms per token,   671.49 tokens per second)
       eval time =    8969.49 ms /   351 tokens (   25.55 ms per token,    39.13 tokens per second)
      total time =    9541.35 ms /   735 tokens
slot      release: id  3 | task 3357 | stop processing: n_tokens = 8475, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.960 (> 0.100 thold), f_keep = 0.959
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3710 | processing task, is_child = 0
slot update_slots: id  3 | task 3710 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8466
slot update_slots: id  3 | task 3710 | n_tokens = 8125, memory_seq_rm [8125, end)
slot update_slots: id  3 | task 3710 | prompt processing progress, n_tokens = 8402, batch.n_tokens = 277, progress = 0.992440
slot update_slots: id  3 | task 3710 | n_tokens = 8402, memory_seq_rm [8402, end)
slot update_slots: id  3 | task 3710 | prompt processing progress, n_tokens = 8466, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3710 | prompt done, n_tokens = 8466, batch.n_tokens = 64
slot init_sampler: id  3 | task 3710 | init sampler, took 3.76 ms, tokens: text = 8466, total = 8466
slot update_slots: id  3 | task 3710 | erasing old context checkpoint (pos_min = 1877, pos_max = 2900, size = 24.012 MiB)
slot update_slots: id  3 | task 3710 | created context checkpoint 8 of 8 (pos_min = 7451, pos_max = 8401, size = 22.300 MiB)
slot print_timing: id  3 | task 3710 | 
prompt eval time =     558.56 ms /   341 tokens (    1.64 ms per token,   610.50 tokens per second)
       eval time =    1439.93 ms /    56 tokens (   25.71 ms per token,    38.89 tokens per second)
      total time =    1998.49 ms /   397 tokens
slot      release: id  3 | task 3710 | stop processing: n_tokens = 8521, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.899 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 3768 | processing task, is_child = 0
slot update_slots: id  3 | task 3768 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 9412
slot update_slots: id  3 | task 3768 | n_tokens = 8466, memory_seq_rm [8466, end)
slot update_slots: id  3 | task 3768 | prompt processing progress, n_tokens = 9348, batch.n_tokens = 882, progress = 0.993200
slot update_slots: id  3 | task 3768 | n_tokens = 9348, memory_seq_rm [9348, end)
slot update_slots: id  3 | task 3768 | prompt processing progress, n_tokens = 9412, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 3768 | prompt done, n_tokens = 9412, batch.n_tokens = 64
slot init_sampler: id  3 | task 3768 | init sampler, took 1.96 ms, tokens: text = 9412, total = 9412
slot update_slots: id  3 | task 3768 | erasing old context checkpoint (pos_min = 2822, pos_max = 3845, size = 24.012 MiB)
slot update_slots: id  3 | task 3768 | created context checkpoint 8 of 8 (pos_min = 8324, pos_max = 9347, size = 24.012 MiB)
slot print_timing: id  3 | task 3768 | 
prompt eval time =    1173.80 ms /   946 tokens (    1.24 ms per token,   805.93 tokens per second)
       eval time =   10134.29 ms /   395 tokens (   25.66 ms per token,    38.98 tokens per second)
      total time =   11308.08 ms /  1341 tokens
slot      release: id  3 | task 3768 | stop processing: n_tokens = 9806, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.965 (> 0.100 thold), f_keep = 0.960
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4165 | processing task, is_child = 0
slot update_slots: id  3 | task 4165 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 9757
slot update_slots: id  3 | task 4165 | n_tokens = 9412, memory_seq_rm [9412, end)
slot update_slots: id  3 | task 4165 | prompt processing progress, n_tokens = 9693, batch.n_tokens = 281, progress = 0.993441
slot update_slots: id  3 | task 4165 | n_tokens = 9693, memory_seq_rm [9693, end)
slot update_slots: id  3 | task 4165 | prompt processing progress, n_tokens = 9757, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4165 | prompt done, n_tokens = 9757, batch.n_tokens = 64
slot init_sampler: id  3 | task 4165 | init sampler, took 1.88 ms, tokens: text = 9757, total = 9757
slot update_slots: id  3 | task 4165 | erasing old context checkpoint (pos_min = 4365, pos_max = 5388, size = 24.012 MiB)
slot update_slots: id  3 | task 4165 | created context checkpoint 8 of 8 (pos_min = 8782, pos_max = 9692, size = 21.362 MiB)
slot print_timing: id  3 | task 4165 | 
prompt eval time =     578.49 ms /   345 tokens (    1.68 ms per token,   596.38 tokens per second)
       eval time =    1328.65 ms /    50 tokens (   26.57 ms per token,    37.63 tokens per second)
      total time =    1907.14 ms /   395 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 4165 | stop processing: n_tokens = 9806, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.970 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4217 | processing task, is_child = 0
slot update_slots: id  3 | task 4217 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10060
slot update_slots: id  3 | task 4217 | n_tokens = 9757, memory_seq_rm [9757, end)
slot update_slots: id  3 | task 4217 | prompt processing progress, n_tokens = 9996, batch.n_tokens = 239, progress = 0.993638
slot update_slots: id  3 | task 4217 | n_tokens = 9996, memory_seq_rm [9996, end)
slot update_slots: id  3 | task 4217 | prompt processing progress, n_tokens = 10060, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4217 | prompt done, n_tokens = 10060, batch.n_tokens = 64
slot init_sampler: id  3 | task 4217 | init sampler, took 2.10 ms, tokens: text = 10060, total = 10060
slot update_slots: id  3 | task 4217 | erasing old context checkpoint (pos_min = 4733, pos_max = 5756, size = 24.012 MiB)
slot update_slots: id  3 | task 4217 | created context checkpoint 8 of 8 (pos_min = 8972, pos_max = 9995, size = 24.012 MiB)
slot print_timing: id  3 | task 4217 | 
prompt eval time =     552.13 ms /   303 tokens (    1.82 ms per token,   548.78 tokens per second)
       eval time =   10065.14 ms /   391 tokens (   25.74 ms per token,    38.85 tokens per second)
      total time =   10617.27 ms /   694 tokens
slot      release: id  3 | task 4217 | stop processing: n_tokens = 10450, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.969 (> 0.100 thold), f_keep = 0.963
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4610 | processing task, is_child = 0
slot update_slots: id  3 | task 4610 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10384
slot update_slots: id  3 | task 4610 | n_tokens = 10060, memory_seq_rm [10060, end)
slot update_slots: id  3 | task 4610 | prompt processing progress, n_tokens = 10320, batch.n_tokens = 260, progress = 0.993837
slot update_slots: id  3 | task 4610 | n_tokens = 10320, memory_seq_rm [10320, end)
slot update_slots: id  3 | task 4610 | prompt processing progress, n_tokens = 10384, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4610 | prompt done, n_tokens = 10384, batch.n_tokens = 64
slot init_sampler: id  3 | task 4610 | init sampler, took 2.13 ms, tokens: text = 10384, total = 10384
slot update_slots: id  3 | task 4610 | erasing old context checkpoint (pos_min = 5437, pos_max = 6460, size = 24.012 MiB)
slot update_slots: id  3 | task 4610 | created context checkpoint 8 of 8 (pos_min = 9426, pos_max = 10319, size = 20.964 MiB)
slot print_timing: id  3 | task 4610 | 
prompt eval time =     577.65 ms /   324 tokens (    1.78 ms per token,   560.90 tokens per second)
       eval time =    1598.71 ms /    58 tokens (   27.56 ms per token,    36.28 tokens per second)
      total time =    2176.36 ms /   382 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 4610 | stop processing: n_tokens = 10441, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.980 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4670 | processing task, is_child = 0
slot update_slots: id  3 | task 4670 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10597
slot update_slots: id  3 | task 4670 | n_tokens = 10384, memory_seq_rm [10384, end)
slot update_slots: id  3 | task 4670 | prompt processing progress, n_tokens = 10533, batch.n_tokens = 149, progress = 0.993961
slot update_slots: id  3 | task 4670 | n_tokens = 10533, memory_seq_rm [10533, end)
slot update_slots: id  3 | task 4670 | prompt processing progress, n_tokens = 10597, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4670 | prompt done, n_tokens = 10597, batch.n_tokens = 64
slot init_sampler: id  3 | task 4670 | init sampler, took 2.36 ms, tokens: text = 10597, total = 10597
slot update_slots: id  3 | task 4670 | erasing old context checkpoint (pos_min = 5866, pos_max = 6805, size = 22.042 MiB)
slot update_slots: id  3 | task 4670 | created context checkpoint 8 of 8 (pos_min = 9622, pos_max = 10532, size = 21.362 MiB)
slot print_timing: id  3 | task 4670 | 
prompt eval time =     439.13 ms /   213 tokens (    2.06 ms per token,   485.04 tokens per second)
       eval time =    1590.00 ms /    61 tokens (   26.07 ms per token,    38.36 tokens per second)
      total time =    2029.13 ms /   274 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 4670 | stop processing: n_tokens = 10657, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.953 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4733 | processing task, is_child = 0
slot update_slots: id  3 | task 4733 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11116
slot update_slots: id  3 | task 4733 | n_tokens = 10597, memory_seq_rm [10597, end)
slot update_slots: id  3 | task 4733 | prompt processing progress, n_tokens = 11052, batch.n_tokens = 455, progress = 0.994243
slot update_slots: id  3 | task 4733 | n_tokens = 11052, memory_seq_rm [11052, end)
slot update_slots: id  3 | task 4733 | prompt processing progress, n_tokens = 11116, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4733 | prompt done, n_tokens = 11116, batch.n_tokens = 64
slot init_sampler: id  3 | task 4733 | init sampler, took 2.50 ms, tokens: text = 11116, total = 11116
slot update_slots: id  3 | task 4733 | erasing old context checkpoint (pos_min = 6653, pos_max = 7676, size = 24.012 MiB)
slot update_slots: id  3 | task 4733 | created context checkpoint 8 of 8 (pos_min = 10060, pos_max = 11051, size = 23.262 MiB)
slot print_timing: id  3 | task 4733 | 
prompt eval time =     701.46 ms /   519 tokens (    1.35 ms per token,   739.89 tokens per second)
       eval time =    1545.78 ms /    59 tokens (   26.20 ms per token,    38.17 tokens per second)
      total time =    2247.23 ms /   578 tokens
slot      release: id  3 | task 4733 | stop processing: n_tokens = 11174, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.954 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4794 | processing task, is_child = 0
slot update_slots: id  3 | task 4794 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11657
slot update_slots: id  3 | task 4794 | n_tokens = 11116, memory_seq_rm [11116, end)
slot update_slots: id  3 | task 4794 | prompt processing progress, n_tokens = 11593, batch.n_tokens = 477, progress = 0.994510
slot update_slots: id  3 | task 4794 | n_tokens = 11593, memory_seq_rm [11593, end)
slot update_slots: id  3 | task 4794 | prompt processing progress, n_tokens = 11657, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4794 | prompt done, n_tokens = 11657, batch.n_tokens = 64
slot init_sampler: id  3 | task 4794 | init sampler, took 2.55 ms, tokens: text = 11657, total = 11657
slot update_slots: id  3 | task 4794 | erasing old context checkpoint (pos_min = 7037, pos_max = 8060, size = 24.012 MiB)
slot update_slots: id  3 | task 4794 | created context checkpoint 8 of 8 (pos_min = 10569, pos_max = 11592, size = 24.012 MiB)
slot print_timing: id  3 | task 4794 | 
prompt eval time =     738.12 ms /   541 tokens (    1.36 ms per token,   732.95 tokens per second)
       eval time =    2004.17 ms /    77 tokens (   26.03 ms per token,    38.42 tokens per second)
      total time =    2742.29 ms /   618 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 4794 | stop processing: n_tokens = 11733, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.975 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4873 | processing task, is_child = 0
slot update_slots: id  3 | task 4873 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11960
slot update_slots: id  3 | task 4873 | n_tokens = 11657, memory_seq_rm [11657, end)
slot update_slots: id  3 | task 4873 | prompt processing progress, n_tokens = 11896, batch.n_tokens = 239, progress = 0.994649
slot update_slots: id  3 | task 4873 | n_tokens = 11896, memory_seq_rm [11896, end)
slot update_slots: id  3 | task 4873 | prompt processing progress, n_tokens = 11960, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4873 | prompt done, n_tokens = 11960, batch.n_tokens = 64
slot init_sampler: id  3 | task 4873 | init sampler, took 2.49 ms, tokens: text = 11960, total = 11960
slot update_slots: id  3 | task 4873 | erasing old context checkpoint (pos_min = 7451, pos_max = 8401, size = 22.300 MiB)
slot update_slots: id  3 | task 4873 | created context checkpoint 8 of 8 (pos_min = 10872, pos_max = 11895, size = 24.012 MiB)
slot print_timing: id  3 | task 4873 | 
prompt eval time =     556.29 ms /   303 tokens (    1.84 ms per token,   544.68 tokens per second)
       eval time =    1326.36 ms /    50 tokens (   26.53 ms per token,    37.70 tokens per second)
      total time =    1882.64 ms /   353 tokens
slot      release: id  3 | task 4873 | stop processing: n_tokens = 12009, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.956 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 4925 | processing task, is_child = 0
slot update_slots: id  3 | task 4925 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12507
slot update_slots: id  3 | task 4925 | n_tokens = 11960, memory_seq_rm [11960, end)
slot update_slots: id  3 | task 4925 | prompt processing progress, n_tokens = 12443, batch.n_tokens = 483, progress = 0.994883
slot update_slots: id  3 | task 4925 | n_tokens = 12443, memory_seq_rm [12443, end)
slot update_slots: id  3 | task 4925 | prompt processing progress, n_tokens = 12507, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 4925 | prompt done, n_tokens = 12507, batch.n_tokens = 64
slot init_sampler: id  3 | task 4925 | init sampler, took 4.55 ms, tokens: text = 12507, total = 12507
slot update_slots: id  3 | task 4925 | erasing old context checkpoint (pos_min = 8324, pos_max = 9347, size = 24.012 MiB)
slot update_slots: id  3 | task 4925 | created context checkpoint 8 of 8 (pos_min = 11419, pos_max = 12442, size = 24.012 MiB)
slot print_timing: id  3 | task 4925 | 
prompt eval time =     793.26 ms /   547 tokens (    1.45 ms per token,   689.56 tokens per second)
       eval time =    2147.40 ms /    78 tokens (   27.53 ms per token,    36.32 tokens per second)
      total time =    2940.67 ms /   625 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 4925 | stop processing: n_tokens = 12584, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.976 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5005 | processing task, is_child = 0
slot update_slots: id  3 | task 5005 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 12810
slot update_slots: id  3 | task 5005 | n_tokens = 12507, memory_seq_rm [12507, end)
slot update_slots: id  3 | task 5005 | prompt processing progress, n_tokens = 12746, batch.n_tokens = 239, progress = 0.995004
slot update_slots: id  3 | task 5005 | n_tokens = 12746, memory_seq_rm [12746, end)
slot update_slots: id  3 | task 5005 | prompt processing progress, n_tokens = 12810, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5005 | prompt done, n_tokens = 12810, batch.n_tokens = 64
slot init_sampler: id  3 | task 5005 | init sampler, took 4.07 ms, tokens: text = 12810, total = 12810
slot update_slots: id  3 | task 5005 | erasing old context checkpoint (pos_min = 8782, pos_max = 9692, size = 21.362 MiB)
slot update_slots: id  3 | task 5005 | created context checkpoint 8 of 8 (pos_min = 11722, pos_max = 12745, size = 24.012 MiB)
slot print_timing: id  3 | task 5005 | 
prompt eval time =     565.45 ms /   303 tokens (    1.87 ms per token,   535.85 tokens per second)
       eval time =   14024.03 ms /   539 tokens (   26.02 ms per token,    38.43 tokens per second)
      total time =   14589.48 ms /   842 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 5005 | stop processing: n_tokens = 13348, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.960
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5546 | processing task, is_child = 0
slot update_slots: id  3 | task 5546 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13083
slot update_slots: id  3 | task 5546 | n_tokens = 12810, memory_seq_rm [12810, end)
slot update_slots: id  3 | task 5546 | prompt processing progress, n_tokens = 13019, batch.n_tokens = 209, progress = 0.995108
slot update_slots: id  3 | task 5546 | n_tokens = 13019, memory_seq_rm [13019, end)
slot update_slots: id  3 | task 5546 | prompt processing progress, n_tokens = 13083, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5546 | prompt done, n_tokens = 13083, batch.n_tokens = 64
slot init_sampler: id  3 | task 5546 | init sampler, took 2.59 ms, tokens: text = 13083, total = 13083
slot update_slots: id  3 | task 5546 | erasing old context checkpoint (pos_min = 8972, pos_max = 9995, size = 24.012 MiB)
slot update_slots: id  3 | task 5546 | created context checkpoint 8 of 8 (pos_min = 12324, pos_max = 13018, size = 16.297 MiB)
slot print_timing: id  3 | task 5546 | 
prompt eval time =     560.10 ms /   273 tokens (    2.05 ms per token,   487.42 tokens per second)
       eval time =    1357.84 ms /    52 tokens (   26.11 ms per token,    38.30 tokens per second)
      total time =    1917.93 ms /   325 tokens
slot      release: id  3 | task 5546 | stop processing: n_tokens = 13134, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.976 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5600 | processing task, is_child = 0
slot update_slots: id  3 | task 5600 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13401
slot update_slots: id  3 | task 5600 | n_tokens = 13083, memory_seq_rm [13083, end)
slot update_slots: id  3 | task 5600 | prompt processing progress, n_tokens = 13337, batch.n_tokens = 254, progress = 0.995224
slot update_slots: id  3 | task 5600 | n_tokens = 13337, memory_seq_rm [13337, end)
slot update_slots: id  3 | task 5600 | prompt processing progress, n_tokens = 13401, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5600 | prompt done, n_tokens = 13401, batch.n_tokens = 64
slot init_sampler: id  3 | task 5600 | init sampler, took 2.23 ms, tokens: text = 13401, total = 13401
slot update_slots: id  3 | task 5600 | erasing old context checkpoint (pos_min = 9426, pos_max = 10319, size = 20.964 MiB)
slot update_slots: id  3 | task 5600 | created context checkpoint 8 of 8 (pos_min = 12635, pos_max = 13336, size = 16.461 MiB)
slot print_timing: id  3 | task 5600 | 
prompt eval time =     576.37 ms /   318 tokens (    1.81 ms per token,   551.73 tokens per second)
       eval time =    1541.76 ms /    59 tokens (   26.13 ms per token,    38.27 tokens per second)
      total time =    2118.13 ms /   377 tokens
slot      release: id  3 | task 5600 | stop processing: n_tokens = 13459, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.978 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5661 | processing task, is_child = 0
slot update_slots: id  3 | task 5661 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 13704
slot update_slots: id  3 | task 5661 | n_tokens = 13401, memory_seq_rm [13401, end)
slot update_slots: id  3 | task 5661 | prompt processing progress, n_tokens = 13640, batch.n_tokens = 239, progress = 0.995330
slot update_slots: id  3 | task 5661 | n_tokens = 13640, memory_seq_rm [13640, end)
slot update_slots: id  3 | task 5661 | prompt processing progress, n_tokens = 13704, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5661 | prompt done, n_tokens = 13704, batch.n_tokens = 64
slot init_sampler: id  3 | task 5661 | init sampler, took 2.47 ms, tokens: text = 13704, total = 13704
slot update_slots: id  3 | task 5661 | erasing old context checkpoint (pos_min = 9622, pos_max = 10532, size = 21.362 MiB)
slot update_slots: id  3 | task 5661 | created context checkpoint 8 of 8 (pos_min = 12810, pos_max = 13639, size = 19.463 MiB)
slot print_timing: id  3 | task 5661 | 
prompt eval time =     556.15 ms /   303 tokens (    1.84 ms per token,   544.82 tokens per second)
       eval time =    1284.70 ms /    49 tokens (   26.22 ms per token,    38.14 tokens per second)
      total time =    1840.85 ms /   352 tokens
slot      release: id  3 | task 5661 | stop processing: n_tokens = 13752, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.914 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5712 | processing task, is_child = 0
slot update_slots: id  3 | task 5712 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15001
slot update_slots: id  3 | task 5712 | n_tokens = 13704, memory_seq_rm [13704, end)
slot update_slots: id  3 | task 5712 | prompt processing progress, n_tokens = 14937, batch.n_tokens = 1233, progress = 0.995734
slot update_slots: id  3 | task 5712 | n_tokens = 14937, memory_seq_rm [14937, end)
slot update_slots: id  3 | task 5712 | prompt processing progress, n_tokens = 15001, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5712 | prompt done, n_tokens = 15001, batch.n_tokens = 64
slot init_sampler: id  3 | task 5712 | init sampler, took 3.20 ms, tokens: text = 15001, total = 15001
slot update_slots: id  3 | task 5712 | erasing old context checkpoint (pos_min = 10060, pos_max = 11051, size = 23.262 MiB)
slot update_slots: id  3 | task 5712 | created context checkpoint 8 of 8 (pos_min = 13913, pos_max = 14936, size = 24.012 MiB)
slot print_timing: id  3 | task 5712 | 
prompt eval time =    1682.94 ms /  1297 tokens (    1.30 ms per token,   770.67 tokens per second)
       eval time =    5354.99 ms /   198 tokens (   27.05 ms per token,    36.97 tokens per second)
      total time =    7037.93 ms /  1495 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 5712 | stop processing: n_tokens = 15198, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5912 | processing task, is_child = 0
slot update_slots: id  3 | task 5912 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15069
slot update_slots: id  3 | task 5912 | n_tokens = 15001, memory_seq_rm [15001, end)
slot update_slots: id  3 | task 5912 | prompt processing progress, n_tokens = 15005, batch.n_tokens = 4, progress = 0.995753
slot update_slots: id  3 | task 5912 | n_tokens = 15005, memory_seq_rm [15005, end)
slot update_slots: id  3 | task 5912 | prompt processing progress, n_tokens = 15069, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5912 | prompt done, n_tokens = 15069, batch.n_tokens = 64
slot init_sampler: id  3 | task 5912 | init sampler, took 3.37 ms, tokens: text = 15069, total = 15069
slot update_slots: id  3 | task 5912 | erasing old context checkpoint (pos_min = 10569, pos_max = 11592, size = 24.012 MiB)
slot update_slots: id  3 | task 5912 | created context checkpoint 8 of 8 (pos_min = 14174, pos_max = 15004, size = 19.486 MiB)
slot print_timing: id  3 | task 5912 | 
prompt eval time =     242.52 ms /    68 tokens (    3.57 ms per token,   280.39 tokens per second)
       eval time =    1423.56 ms /    54 tokens (   26.36 ms per token,    37.93 tokens per second)
      total time =    1666.07 ms /   122 tokens
slot      release: id  3 | task 5912 | stop processing: n_tokens = 15122, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.977 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 5968 | processing task, is_child = 0
slot update_slots: id  3 | task 5968 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15425
slot update_slots: id  3 | task 5968 | n_tokens = 15069, memory_seq_rm [15069, end)
slot update_slots: id  3 | task 5968 | prompt processing progress, n_tokens = 15361, batch.n_tokens = 292, progress = 0.995851
slot update_slots: id  3 | task 5968 | n_tokens = 15361, memory_seq_rm [15361, end)
slot update_slots: id  3 | task 5968 | prompt processing progress, n_tokens = 15425, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 5968 | prompt done, n_tokens = 15425, batch.n_tokens = 64
slot init_sampler: id  3 | task 5968 | init sampler, took 3.48 ms, tokens: text = 15425, total = 15425
slot update_slots: id  3 | task 5968 | erasing old context checkpoint (pos_min = 10872, pos_max = 11895, size = 24.012 MiB)
slot update_slots: id  3 | task 5968 | created context checkpoint 8 of 8 (pos_min = 14337, pos_max = 15360, size = 24.012 MiB)
slot print_timing: id  3 | task 5968 | 
prompt eval time =     590.77 ms /   356 tokens (    1.66 ms per token,   602.61 tokens per second)
       eval time =    8891.02 ms /   338 tokens (   26.30 ms per token,    38.02 tokens per second)
      total time =    9481.79 ms /   694 tokens
slot      release: id  3 | task 5968 | stop processing: n_tokens = 15762, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.979
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6308 | processing task, is_child = 0
slot update_slots: id  3 | task 6308 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15754
slot update_slots: id  3 | task 6308 | n_tokens = 15425, memory_seq_rm [15425, end)
slot update_slots: id  3 | task 6308 | prompt processing progress, n_tokens = 15690, batch.n_tokens = 265, progress = 0.995938
slot update_slots: id  3 | task 6308 | n_tokens = 15690, memory_seq_rm [15690, end)
slot update_slots: id  3 | task 6308 | prompt processing progress, n_tokens = 15754, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 6308 | prompt done, n_tokens = 15754, batch.n_tokens = 64
slot init_sampler: id  3 | task 6308 | init sampler, took 3.58 ms, tokens: text = 15754, total = 15754
slot update_slots: id  3 | task 6308 | erasing old context checkpoint (pos_min = 11419, pos_max = 12442, size = 24.012 MiB)
slot update_slots: id  3 | task 6308 | created context checkpoint 8 of 8 (pos_min = 14738, pos_max = 15689, size = 22.324 MiB)
slot print_timing: id  3 | task 6308 | 
prompt eval time =     616.22 ms /   329 tokens (    1.87 ms per token,   533.90 tokens per second)
       eval time =    1592.86 ms /    58 tokens (   27.46 ms per token,    36.41 tokens per second)
      total time =    2209.07 ms /   387 tokens
slot      release: id  3 | task 6308 | stop processing: n_tokens = 15811, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6368 | processing task, is_child = 0
slot update_slots: id  3 | task 6368 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15988
slot update_slots: id  3 | task 6368 | n_tokens = 15754, memory_seq_rm [15754, end)
slot update_slots: id  3 | task 6368 | prompt processing progress, n_tokens = 15924, batch.n_tokens = 170, progress = 0.995997
slot update_slots: id  3 | task 6368 | n_tokens = 15924, memory_seq_rm [15924, end)
slot update_slots: id  3 | task 6368 | prompt processing progress, n_tokens = 15988, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 6368 | prompt done, n_tokens = 15988, batch.n_tokens = 64
slot init_sampler: id  3 | task 6368 | init sampler, took 3.21 ms, tokens: text = 15988, total = 15988
slot update_slots: id  3 | task 6368 | erasing old context checkpoint (pos_min = 11722, pos_max = 12745, size = 24.012 MiB)
slot update_slots: id  3 | task 6368 | created context checkpoint 8 of 8 (pos_min = 14900, pos_max = 15923, size = 24.012 MiB)
slot print_timing: id  3 | task 6368 | 
prompt eval time =     482.14 ms /   234 tokens (    2.06 ms per token,   485.33 tokens per second)
       eval time =    1356.97 ms /    51 tokens (   26.61 ms per token,    37.58 tokens per second)
      total time =    1839.11 ms /   285 tokens
slot      release: id  3 | task 6368 | stop processing: n_tokens = 16038, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6421 | processing task, is_child = 0
slot update_slots: id  3 | task 6421 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16219
slot update_slots: id  3 | task 6421 | n_tokens = 15988, memory_seq_rm [15988, end)
slot update_slots: id  3 | task 6421 | prompt processing progress, n_tokens = 16155, batch.n_tokens = 167, progress = 0.996054
slot update_slots: id  3 | task 6421 | n_tokens = 16155, memory_seq_rm [16155, end)
slot update_slots: id  3 | task 6421 | prompt processing progress, n_tokens = 16219, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 6421 | prompt done, n_tokens = 16219, batch.n_tokens = 64
slot init_sampler: id  3 | task 6421 | init sampler, took 3.49 ms, tokens: text = 16219, total = 16219
slot update_slots: id  3 | task 6421 | erasing old context checkpoint (pos_min = 12324, pos_max = 13018, size = 16.297 MiB)
slot update_slots: id  3 | task 6421 | created context checkpoint 8 of 8 (pos_min = 15131, pos_max = 16154, size = 24.012 MiB)
slot print_timing: id  3 | task 6421 | 
prompt eval time =     496.11 ms /   231 tokens (    2.15 ms per token,   465.62 tokens per second)
       eval time =    5682.20 ms /   217 tokens (   26.19 ms per token,    38.19 tokens per second)
      total time =    6178.31 ms /   448 tokens
slot      release: id  3 | task 6421 | stop processing: n_tokens = 16435, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.938 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 6640 | processing task, is_child = 0
slot update_slots: id  3 | task 6640 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 17296
slot update_slots: id  3 | task 6640 | n_tokens = 16219, memory_seq_rm [16219, end)
slot update_slots: id  3 | task 6640 | prompt processing progress, n_tokens = 17232, batch.n_tokens = 1013, progress = 0.996300
slot update_slots: id  3 | task 6640 | n_tokens = 17232, memory_seq_rm [17232, end)
slot update_slots: id  3 | task 6640 | prompt processing progress, n_tokens = 17296, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 6640 | prompt done, n_tokens = 17296, batch.n_tokens = 64
slot init_sampler: id  3 | task 6640 | init sampler, took 3.44 ms, tokens: text = 17296, total = 17296
slot update_slots: id  3 | task 6640 | erasing old context checkpoint (pos_min = 12635, pos_max = 13336, size = 16.461 MiB)
slot update_slots: id  3 | task 6640 | created context checkpoint 8 of 8 (pos_min = 16208, pos_max = 17231, size = 24.012 MiB)
slot print_timing: id  3 | task 6640 | 
prompt eval time =    1463.18 ms /  1077 tokens (    1.36 ms per token,   736.07 tokens per second)
       eval time =   11137.85 ms /   417 tokens (   26.71 ms per token,    37.44 tokens per second)
      total time =   12601.03 ms /  1494 tokens
slot      release: id  3 | task 6640 | stop processing: n_tokens = 17712, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.977
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 7059 | processing task, is_child = 0
slot update_slots: id  3 | task 7059 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 17583
slot update_slots: id  3 | task 7059 | n_tokens = 17296, memory_seq_rm [17296, end)
slot update_slots: id  3 | task 7059 | prompt processing progress, n_tokens = 17519, batch.n_tokens = 223, progress = 0.996360
slot update_slots: id  3 | task 7059 | n_tokens = 17519, memory_seq_rm [17519, end)
slot update_slots: id  3 | task 7059 | prompt processing progress, n_tokens = 17583, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 7059 | prompt done, n_tokens = 17583, batch.n_tokens = 64
slot init_sampler: id  3 | task 7059 | init sampler, took 2.81 ms, tokens: text = 17583, total = 17583
slot update_slots: id  3 | task 7059 | erasing old context checkpoint (pos_min = 12810, pos_max = 13639, size = 19.463 MiB)
slot update_slots: id  3 | task 7059 | created context checkpoint 8 of 8 (pos_min = 16688, pos_max = 17518, size = 19.486 MiB)
slot print_timing: id  3 | task 7059 | 
prompt eval time =     555.38 ms /   287 tokens (    1.94 ms per token,   516.76 tokens per second)
       eval time =    4275.77 ms /   157 tokens (   27.23 ms per token,    36.72 tokens per second)
      total time =    4831.15 ms /   444 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 7059 | stop processing: n_tokens = 17739, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.980 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 7218 | processing task, is_child = 0
slot update_slots: id  3 | task 7218 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 17939
slot update_slots: id  3 | task 7218 | n_tokens = 17583, memory_seq_rm [17583, end)
slot update_slots: id  3 | task 7218 | prompt processing progress, n_tokens = 17875, batch.n_tokens = 292, progress = 0.996432
slot update_slots: id  3 | task 7218 | n_tokens = 17875, memory_seq_rm [17875, end)
slot update_slots: id  3 | task 7218 | prompt processing progress, n_tokens = 17939, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 7218 | prompt done, n_tokens = 17939, batch.n_tokens = 64
slot init_sampler: id  3 | task 7218 | init sampler, took 4.87 ms, tokens: text = 17939, total = 17939
slot update_slots: id  3 | task 7218 | erasing old context checkpoint (pos_min = 13913, pos_max = 14936, size = 24.012 MiB)
slot update_slots: id  3 | task 7218 | created context checkpoint 8 of 8 (pos_min = 16851, pos_max = 17874, size = 24.012 MiB)
slot print_timing: id  3 | task 7218 | 
prompt eval time =     612.13 ms /   356 tokens (    1.72 ms per token,   581.57 tokens per second)
       eval time =    1405.36 ms /    53 tokens (   26.52 ms per token,    37.71 tokens per second)
      total time =    2017.49 ms /   409 tokens
slot      release: id  3 | task 7218 | stop processing: n_tokens = 17991, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.958 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 7273 | processing task, is_child = 0
slot update_slots: id  3 | task 7273 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 18718
slot update_slots: id  3 | task 7273 | n_tokens = 17939, memory_seq_rm [17939, end)
slot update_slots: id  3 | task 7273 | prompt processing progress, n_tokens = 18654, batch.n_tokens = 715, progress = 0.996581
slot update_slots: id  3 | task 7273 | n_tokens = 18654, memory_seq_rm [18654, end)
slot update_slots: id  3 | task 7273 | prompt processing progress, n_tokens = 18718, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 7273 | prompt done, n_tokens = 18718, batch.n_tokens = 64
slot init_sampler: id  3 | task 7273 | init sampler, took 3.38 ms, tokens: text = 18718, total = 18718
slot update_slots: id  3 | task 7273 | erasing old context checkpoint (pos_min = 14174, pos_max = 15004, size = 19.486 MiB)
slot update_slots: id  3 | task 7273 | created context checkpoint 8 of 8 (pos_min = 17630, pos_max = 18653, size = 24.012 MiB)
slot print_timing: id  3 | task 7273 | 
prompt eval time =    1154.90 ms /   779 tokens (    1.48 ms per token,   674.52 tokens per second)
       eval time =    1998.42 ms /    76 tokens (   26.30 ms per token,    38.03 tokens per second)
      total time =    3153.32 ms /   855 tokens
slot      release: id  3 | task 7273 | stop processing: n_tokens = 18793, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.980 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 7351 | processing task, is_child = 0
slot update_slots: id  3 | task 7351 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 19097
slot update_slots: id  3 | task 7351 | n_tokens = 18718, memory_seq_rm [18718, end)
slot update_slots: id  3 | task 7351 | prompt processing progress, n_tokens = 19033, batch.n_tokens = 315, progress = 0.996649
slot update_slots: id  3 | task 7351 | n_tokens = 19033, memory_seq_rm [19033, end)
slot update_slots: id  3 | task 7351 | prompt processing progress, n_tokens = 19097, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 7351 | prompt done, n_tokens = 19097, batch.n_tokens = 64
slot init_sampler: id  3 | task 7351 | init sampler, took 3.56 ms, tokens: text = 19097, total = 19097
slot update_slots: id  3 | task 7351 | erasing old context checkpoint (pos_min = 14337, pos_max = 15360, size = 24.012 MiB)
slot update_slots: id  3 | task 7351 | created context checkpoint 8 of 8 (pos_min = 18009, pos_max = 19032, size = 24.012 MiB)
slot print_timing: id  3 | task 7351 | 
prompt eval time =     633.73 ms /   379 tokens (    1.67 ms per token,   598.05 tokens per second)
       eval time =    3019.47 ms /   113 tokens (   26.72 ms per token,    37.42 tokens per second)
      total time =    3653.20 ms /   492 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 7351 | stop processing: n_tokens = 19209, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 7466 | processing task, is_child = 0
slot update_slots: id  3 | task 7466 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 19309
slot update_slots: id  3 | task 7466 | n_tokens = 19097, memory_seq_rm [19097, end)
slot update_slots: id  3 | task 7466 | prompt processing progress, n_tokens = 19245, batch.n_tokens = 148, progress = 0.996686
slot update_slots: id  3 | task 7466 | n_tokens = 19245, memory_seq_rm [19245, end)
slot update_slots: id  3 | task 7466 | prompt processing progress, n_tokens = 19309, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 7466 | prompt done, n_tokens = 19309, batch.n_tokens = 64
slot init_sampler: id  3 | task 7466 | init sampler, took 7.06 ms, tokens: text = 19309, total = 19309
slot update_slots: id  3 | task 7466 | erasing old context checkpoint (pos_min = 14738, pos_max = 15689, size = 22.324 MiB)
slot update_slots: id  3 | task 7466 | created context checkpoint 8 of 8 (pos_min = 18221, pos_max = 19244, size = 24.012 MiB)
slot print_timing: id  3 | task 7466 | 
prompt eval time =     490.69 ms /   212 tokens (    2.31 ms per token,   432.04 tokens per second)
       eval time =   16427.01 ms /   614 tokens (   26.75 ms per token,    37.38 tokens per second)
      total time =   16917.70 ms /   826 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 7466 | stop processing: n_tokens = 19922, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.969
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8082 | processing task, is_child = 0
slot update_slots: id  3 | task 8082 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 19581
slot update_slots: id  3 | task 8082 | n_tokens = 19309, memory_seq_rm [19309, end)
slot update_slots: id  3 | task 8082 | prompt processing progress, n_tokens = 19517, batch.n_tokens = 208, progress = 0.996732
slot update_slots: id  3 | task 8082 | n_tokens = 19517, memory_seq_rm [19517, end)
slot update_slots: id  3 | task 8082 | prompt processing progress, n_tokens = 19581, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 8082 | prompt done, n_tokens = 19581, batch.n_tokens = 64
slot init_sampler: id  3 | task 8082 | init sampler, took 4.36 ms, tokens: text = 19581, total = 19581
slot update_slots: id  3 | task 8082 | erasing old context checkpoint (pos_min = 14900, pos_max = 15923, size = 24.012 MiB)
slot update_slots: id  3 | task 8082 | created context checkpoint 8 of 8 (pos_min = 18898, pos_max = 19516, size = 14.515 MiB)
slot print_timing: id  3 | task 8082 | 
prompt eval time =     598.12 ms /   272 tokens (    2.20 ms per token,   454.76 tokens per second)
       eval time =    1418.10 ms /    53 tokens (   26.76 ms per token,    37.37 tokens per second)
      total time =    2016.23 ms /   325 tokens
slot      release: id  3 | task 8082 | stop processing: n_tokens = 19633, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.978 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8137 | processing task, is_child = 0
slot update_slots: id  3 | task 8137 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20027
slot update_slots: id  3 | task 8137 | n_tokens = 19581, memory_seq_rm [19581, end)
slot update_slots: id  3 | task 8137 | prompt processing progress, n_tokens = 19963, batch.n_tokens = 382, progress = 0.996804
slot update_slots: id  3 | task 8137 | n_tokens = 19963, memory_seq_rm [19963, end)
slot update_slots: id  3 | task 8137 | prompt processing progress, n_tokens = 20027, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 8137 | prompt done, n_tokens = 20027, batch.n_tokens = 64
slot init_sampler: id  3 | task 8137 | init sampler, took 3.04 ms, tokens: text = 20027, total = 20027
slot update_slots: id  3 | task 8137 | erasing old context checkpoint (pos_min = 15131, pos_max = 16154, size = 24.012 MiB)
slot update_slots: id  3 | task 8137 | created context checkpoint 8 of 8 (pos_min = 18939, pos_max = 19962, size = 24.012 MiB)
slot print_timing: id  3 | task 8137 | 
prompt eval time =     723.18 ms /   446 tokens (    1.62 ms per token,   616.72 tokens per second)
       eval time =    2355.48 ms /    89 tokens (   26.47 ms per token,    37.78 tokens per second)
      total time =    3078.66 ms /   535 tokens
slot      release: id  3 | task 8137 | stop processing: n_tokens = 20115, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8228 | processing task, is_child = 0
slot update_slots: id  3 | task 8228 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20212
slot update_slots: id  3 | task 8228 | n_tokens = 20027, memory_seq_rm [20027, end)
slot update_slots: id  3 | task 8228 | prompt processing progress, n_tokens = 20148, batch.n_tokens = 121, progress = 0.996834
slot update_slots: id  3 | task 8228 | n_tokens = 20148, memory_seq_rm [20148, end)
slot update_slots: id  3 | task 8228 | prompt processing progress, n_tokens = 20212, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 8228 | prompt done, n_tokens = 20212, batch.n_tokens = 64
slot init_sampler: id  3 | task 8228 | init sampler, took 3.21 ms, tokens: text = 20212, total = 20212
slot update_slots: id  3 | task 8228 | erasing old context checkpoint (pos_min = 16208, pos_max = 17231, size = 24.012 MiB)
slot update_slots: id  3 | task 8228 | created context checkpoint 8 of 8 (pos_min = 19124, pos_max = 20147, size = 24.012 MiB)
slot print_timing: id  3 | task 8228 | 
prompt eval time =     559.55 ms /   185 tokens (    3.02 ms per token,   330.62 tokens per second)
       eval time =    3689.05 ms /   139 tokens (   26.54 ms per token,    37.68 tokens per second)
      total time =    4248.60 ms /   324 tokens
slot      release: id  3 | task 8228 | stop processing: n_tokens = 20350, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.982 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8369 | processing task, is_child = 0
slot update_slots: id  3 | task 8369 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20589
slot update_slots: id  3 | task 8369 | n_tokens = 20212, memory_seq_rm [20212, end)
slot update_slots: id  3 | task 8369 | prompt processing progress, n_tokens = 20525, batch.n_tokens = 313, progress = 0.996892
slot update_slots: id  3 | task 8369 | n_tokens = 20525, memory_seq_rm [20525, end)
slot update_slots: id  3 | task 8369 | prompt processing progress, n_tokens = 20589, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 8369 | prompt done, n_tokens = 20589, batch.n_tokens = 64
slot init_sampler: id  3 | task 8369 | init sampler, took 4.28 ms, tokens: text = 20589, total = 20589
slot update_slots: id  3 | task 8369 | erasing old context checkpoint (pos_min = 16688, pos_max = 17518, size = 19.486 MiB)
slot update_slots: id  3 | task 8369 | created context checkpoint 8 of 8 (pos_min = 19501, pos_max = 20524, size = 24.012 MiB)
slot print_timing: id  3 | task 8369 | 
prompt eval time =     655.34 ms /   377 tokens (    1.74 ms per token,   575.27 tokens per second)
       eval time =   13211.10 ms /   498 tokens (   26.53 ms per token,    37.70 tokens per second)
      total time =   13866.44 ms /   875 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 8369 | stop processing: n_tokens = 21086, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.976
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8869 | processing task, is_child = 0
slot update_slots: id  3 | task 8869 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20848
slot update_slots: id  3 | task 8869 | n_tokens = 20589, memory_seq_rm [20589, end)
slot update_slots: id  3 | task 8869 | prompt processing progress, n_tokens = 20784, batch.n_tokens = 195, progress = 0.996930
slot update_slots: id  3 | task 8869 | n_tokens = 20784, memory_seq_rm [20784, end)
slot update_slots: id  3 | task 8869 | prompt processing progress, n_tokens = 20848, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 8869 | prompt done, n_tokens = 20848, batch.n_tokens = 64
slot init_sampler: id  3 | task 8869 | init sampler, took 4.45 ms, tokens: text = 20848, total = 20848
slot update_slots: id  3 | task 8869 | erasing old context checkpoint (pos_min = 16851, pos_max = 17874, size = 24.012 MiB)
slot update_slots: id  3 | task 8869 | created context checkpoint 8 of 8 (pos_min = 20173, pos_max = 20783, size = 14.328 MiB)
slot print_timing: id  3 | task 8869 | 
prompt eval time =     593.50 ms /   259 tokens (    2.29 ms per token,   436.40 tokens per second)
       eval time =    2110.64 ms /    78 tokens (   27.06 ms per token,    36.96 tokens per second)
      total time =    2704.14 ms /   337 tokens
slot      release: id  3 | task 8869 | stop processing: n_tokens = 20925, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 8949 | processing task, is_child = 0
slot update_slots: id  3 | task 8949 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21079
slot update_slots: id  3 | task 8949 | n_tokens = 20848, memory_seq_rm [20848, end)
slot update_slots: id  3 | task 8949 | prompt processing progress, n_tokens = 21015, batch.n_tokens = 167, progress = 0.996964
slot update_slots: id  3 | task 8949 | n_tokens = 21015, memory_seq_rm [21015, end)
slot update_slots: id  3 | task 8949 | prompt processing progress, n_tokens = 21079, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 8949 | prompt done, n_tokens = 21079, batch.n_tokens = 64
slot init_sampler: id  3 | task 8949 | init sampler, took 3.19 ms, tokens: text = 21079, total = 21079
slot update_slots: id  3 | task 8949 | erasing old context checkpoint (pos_min = 17630, pos_max = 18653, size = 24.012 MiB)
slot update_slots: id  3 | task 8949 | created context checkpoint 8 of 8 (pos_min = 20404, pos_max = 21014, size = 14.328 MiB)
slot print_timing: id  3 | task 8949 | 
prompt eval time =     517.20 ms /   231 tokens (    2.24 ms per token,   446.64 tokens per second)
       eval time =    1549.77 ms /    58 tokens (   26.72 ms per token,    37.42 tokens per second)
      total time =    2066.97 ms /   289 tokens
slot      release: id  3 | task 8949 | stop processing: n_tokens = 21136, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.977 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9009 | processing task, is_child = 0
slot update_slots: id  3 | task 9009 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21565
slot update_slots: id  3 | task 9009 | n_tokens = 21079, memory_seq_rm [21079, end)
slot update_slots: id  3 | task 9009 | prompt processing progress, n_tokens = 21501, batch.n_tokens = 422, progress = 0.997032
slot update_slots: id  3 | task 9009 | n_tokens = 21501, memory_seq_rm [21501, end)
slot update_slots: id  3 | task 9009 | prompt processing progress, n_tokens = 21565, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9009 | prompt done, n_tokens = 21565, batch.n_tokens = 64
slot init_sampler: id  3 | task 9009 | init sampler, took 3.21 ms, tokens: text = 21565, total = 21565
slot update_slots: id  3 | task 9009 | erasing old context checkpoint (pos_min = 18009, pos_max = 19032, size = 24.012 MiB)
slot update_slots: id  3 | task 9009 | created context checkpoint 8 of 8 (pos_min = 20589, pos_max = 21500, size = 21.386 MiB)
slot print_timing: id  3 | task 9009 | 
prompt eval time =     752.63 ms /   486 tokens (    1.55 ms per token,   645.74 tokens per second)
       eval time =    1984.01 ms /    75 tokens (   26.45 ms per token,    37.80 tokens per second)
      total time =    2736.64 ms /   561 tokens
slot      release: id  3 | task 9009 | stop processing: n_tokens = 21639, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.973 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9086 | processing task, is_child = 0
slot update_slots: id  3 | task 9086 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 22170
slot update_slots: id  3 | task 9086 | n_tokens = 21565, memory_seq_rm [21565, end)
slot update_slots: id  3 | task 9086 | prompt processing progress, n_tokens = 22106, batch.n_tokens = 541, progress = 0.997113
slot update_slots: id  3 | task 9086 | n_tokens = 22106, memory_seq_rm [22106, end)
slot update_slots: id  3 | task 9086 | prompt processing progress, n_tokens = 22170, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9086 | prompt done, n_tokens = 22170, batch.n_tokens = 64
slot init_sampler: id  3 | task 9086 | init sampler, took 3.31 ms, tokens: text = 22170, total = 22170
slot update_slots: id  3 | task 9086 | erasing old context checkpoint (pos_min = 18221, pos_max = 19244, size = 24.012 MiB)
slot update_slots: id  3 | task 9086 | created context checkpoint 8 of 8 (pos_min = 21130, pos_max = 22105, size = 22.886 MiB)
slot print_timing: id  3 | task 9086 | 
prompt eval time =    1001.28 ms /   605 tokens (    1.66 ms per token,   604.23 tokens per second)
       eval time =    1996.06 ms /    75 tokens (   26.61 ms per token,    37.57 tokens per second)
      total time =    2997.34 ms /   680 tokens
slot      release: id  3 | task 9086 | stop processing: n_tokens = 22244, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.970 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9163 | processing task, is_child = 0
slot update_slots: id  3 | task 9163 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 22865
slot update_slots: id  3 | task 9163 | n_tokens = 22170, memory_seq_rm [22170, end)
slot update_slots: id  3 | task 9163 | prompt processing progress, n_tokens = 22801, batch.n_tokens = 631, progress = 0.997201
slot update_slots: id  3 | task 9163 | n_tokens = 22801, memory_seq_rm [22801, end)
slot update_slots: id  3 | task 9163 | prompt processing progress, n_tokens = 22865, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9163 | prompt done, n_tokens = 22865, batch.n_tokens = 64
slot init_sampler: id  3 | task 9163 | init sampler, took 5.24 ms, tokens: text = 22865, total = 22865
slot update_slots: id  3 | task 9163 | erasing old context checkpoint (pos_min = 18898, pos_max = 19516, size = 14.515 MiB)
slot update_slots: id  3 | task 9163 | created context checkpoint 8 of 8 (pos_min = 21777, pos_max = 22800, size = 24.012 MiB)
slot print_timing: id  3 | task 9163 | 
prompt eval time =    1171.63 ms /   695 tokens (    1.69 ms per token,   593.19 tokens per second)
       eval time =    2226.16 ms /    82 tokens (   27.15 ms per token,    36.83 tokens per second)
      total time =    3397.79 ms /   777 tokens
slot      release: id  3 | task 9163 | stop processing: n_tokens = 22946, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9247 | processing task, is_child = 0
slot update_slots: id  3 | task 9247 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23316
slot update_slots: id  3 | task 9247 | n_tokens = 22865, memory_seq_rm [22865, end)
slot update_slots: id  3 | task 9247 | prompt processing progress, n_tokens = 23252, batch.n_tokens = 387, progress = 0.997255
slot update_slots: id  3 | task 9247 | n_tokens = 23252, memory_seq_rm [23252, end)
slot update_slots: id  3 | task 9247 | prompt processing progress, n_tokens = 23316, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9247 | prompt done, n_tokens = 23316, batch.n_tokens = 64
slot init_sampler: id  3 | task 9247 | init sampler, took 3.72 ms, tokens: text = 23316, total = 23316
slot update_slots: id  3 | task 9247 | erasing old context checkpoint (pos_min = 18939, pos_max = 19962, size = 24.012 MiB)
slot update_slots: id  3 | task 9247 | created context checkpoint 8 of 8 (pos_min = 22228, pos_max = 23251, size = 24.012 MiB)
slot print_timing: id  3 | task 9247 | 
prompt eval time =     744.16 ms /   451 tokens (    1.65 ms per token,   606.05 tokens per second)
       eval time =    1723.41 ms /    64 tokens (   26.93 ms per token,    37.14 tokens per second)
      total time =    2467.57 ms /   515 tokens
slot      release: id  3 | task 9247 | stop processing: n_tokens = 23379, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9313 | processing task, is_child = 0
slot update_slots: id  3 | task 9313 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23528
slot update_slots: id  3 | task 9313 | n_tokens = 23316, memory_seq_rm [23316, end)
slot update_slots: id  3 | task 9313 | prompt processing progress, n_tokens = 23464, batch.n_tokens = 148, progress = 0.997280
slot update_slots: id  3 | task 9313 | n_tokens = 23464, memory_seq_rm [23464, end)
slot update_slots: id  3 | task 9313 | prompt processing progress, n_tokens = 23528, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9313 | prompt done, n_tokens = 23528, batch.n_tokens = 64
slot init_sampler: id  3 | task 9313 | init sampler, took 4.59 ms, tokens: text = 23528, total = 23528
slot update_slots: id  3 | task 9313 | erasing old context checkpoint (pos_min = 19124, pos_max = 20147, size = 24.012 MiB)
slot update_slots: id  3 | task 9313 | created context checkpoint 8 of 8 (pos_min = 22440, pos_max = 23463, size = 24.012 MiB)
slot print_timing: id  3 | task 9313 | 
prompt eval time =     482.12 ms /   212 tokens (    2.27 ms per token,   439.72 tokens per second)
       eval time =    3955.24 ms /   148 tokens (   26.72 ms per token,    37.42 tokens per second)
      total time =    4437.36 ms /   360 tokens
slot      release: id  3 | task 9313 | stop processing: n_tokens = 23675, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9463 | processing task, is_child = 0
slot update_slots: id  3 | task 9463 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23601
slot update_slots: id  3 | task 9463 | n_tokens = 23528, memory_seq_rm [23528, end)
slot update_slots: id  3 | task 9463 | prompt processing progress, n_tokens = 23537, batch.n_tokens = 9, progress = 0.997288
slot update_slots: id  3 | task 9463 | n_tokens = 23537, memory_seq_rm [23537, end)
slot update_slots: id  3 | task 9463 | prompt processing progress, n_tokens = 23601, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 9463 | prompt done, n_tokens = 23601, batch.n_tokens = 64
slot init_sampler: id  3 | task 9463 | init sampler, took 3.71 ms, tokens: text = 23601, total = 23601
slot update_slots: id  3 | task 9463 | erasing old context checkpoint (pos_min = 19501, pos_max = 20524, size = 24.012 MiB)
slot update_slots: id  3 | task 9463 | created context checkpoint 8 of 8 (pos_min = 22651, pos_max = 23536, size = 20.776 MiB)
slot print_timing: id  3 | task 9463 | 
prompt eval time =     297.64 ms /    73 tokens (    4.08 ms per token,   245.26 tokens per second)
       eval time =    2039.28 ms /    76 tokens (   26.83 ms per token,    37.27 tokens per second)
      total time =    2336.92 ms /   149 tokens
slot      release: id  3 | task 9463 | stop processing: n_tokens = 23676, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 9541 | processing task, is_child = 0
slot update_slots: id  3 | task 9541 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23653
slot update_slots: id  3 | task 9541 | n_tokens = 23601, memory_seq_rm [23601, end)
slot update_slots: id  3 | task 9541 | prompt processing progress, n_tokens = 23653, batch.n_tokens = 52, progress = 1.000000
slot update_slots: id  3 | task 9541 | prompt done, n_tokens = 23653, batch.n_tokens = 52
slot init_sampler: id  3 | task 9541 | init sampler, took 4.89 ms, tokens: text = 23653, total = 23653
slot print_timing: id  3 | task 9541 | 
prompt eval time =     179.16 ms /    52 tokens (    3.45 ms per token,   290.24 tokens per second)
       eval time =   70804.06 ms /  2619 tokens (   27.03 ms per token,    36.99 tokens per second)
      total time =   70983.22 ms /  2671 tokens
slot      release: id  3 | task 9541 | stop processing: n_tokens = 26271, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.904 (> 0.100 thold), f_keep = 0.900
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12161 | processing task, is_child = 0
slot update_slots: id  3 | task 12161 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 26171
slot update_slots: id  3 | task 12161 | n_past = 23653, slot.prompt.tokens.size() = 26271, seq_id = 3, pos_min = 25247, n_swa = 128
slot update_slots: id  3 | task 12161 | restored context checkpoint (pos_min = 22651, pos_max = 23536, size = 20.776 MiB)
slot update_slots: id  3 | task 12161 | n_tokens = 23536, memory_seq_rm [23536, end)
slot update_slots: id  3 | task 12161 | prompt processing progress, n_tokens = 25584, batch.n_tokens = 2048, progress = 0.977571
slot update_slots: id  3 | task 12161 | n_tokens = 25584, memory_seq_rm [25584, end)
slot update_slots: id  3 | task 12161 | prompt processing progress, n_tokens = 26107, batch.n_tokens = 523, progress = 0.997555
slot update_slots: id  3 | task 12161 | n_tokens = 26107, memory_seq_rm [26107, end)
slot update_slots: id  3 | task 12161 | prompt processing progress, n_tokens = 26171, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12161 | prompt done, n_tokens = 26171, batch.n_tokens = 64
slot init_sampler: id  3 | task 12161 | init sampler, took 3.88 ms, tokens: text = 26171, total = 26171
slot update_slots: id  3 | task 12161 | erasing old context checkpoint (pos_min = 20173, pos_max = 20783, size = 14.328 MiB)
slot update_slots: id  3 | task 12161 | created context checkpoint 8 of 8 (pos_min = 25083, pos_max = 26106, size = 24.012 MiB)
slot print_timing: id  3 | task 12161 | 
prompt eval time =    3719.90 ms /  2635 tokens (    1.41 ms per token,   708.35 tokens per second)
       eval time =    2476.56 ms /    92 tokens (   26.92 ms per token,    37.15 tokens per second)
      total time =    6196.46 ms /  2727 tokens
slot      release: id  3 | task 12161 | stop processing: n_tokens = 26262, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12256 | processing task, is_child = 0
slot update_slots: id  3 | task 12256 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 26528
slot update_slots: id  3 | task 12256 | n_tokens = 26171, memory_seq_rm [26171, end)
slot update_slots: id  3 | task 12256 | prompt processing progress, n_tokens = 26464, batch.n_tokens = 293, progress = 0.997587
slot update_slots: id  3 | task 12256 | n_tokens = 26464, memory_seq_rm [26464, end)
slot update_slots: id  3 | task 12256 | prompt processing progress, n_tokens = 26528, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12256 | prompt done, n_tokens = 26528, batch.n_tokens = 64
slot init_sampler: id  3 | task 12256 | init sampler, took 3.89 ms, tokens: text = 26528, total = 26528
slot update_slots: id  3 | task 12256 | erasing old context checkpoint (pos_min = 20404, pos_max = 21014, size = 14.328 MiB)
slot update_slots: id  3 | task 12256 | created context checkpoint 8 of 8 (pos_min = 25440, pos_max = 26463, size = 24.012 MiB)
slot print_timing: id  3 | task 12256 | 
prompt eval time =     675.55 ms /   357 tokens (    1.89 ms per token,   528.46 tokens per second)
       eval time =    2457.18 ms /    89 tokens (   27.61 ms per token,    36.22 tokens per second)
      total time =    3132.73 ms /   446 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  3 | task 12256 | stop processing: n_tokens = 26616, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12347 | processing task, is_child = 0
slot update_slots: id  3 | task 12347 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 26593
slot update_slots: id  3 | task 12347 | n_tokens = 26528, memory_seq_rm [26528, end)
slot update_slots: id  3 | task 12347 | prompt processing progress, n_tokens = 26529, batch.n_tokens = 1, progress = 0.997593
slot update_slots: id  3 | task 12347 | n_tokens = 26529, memory_seq_rm [26529, end)
slot update_slots: id  3 | task 12347 | prompt processing progress, n_tokens = 26593, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12347 | prompt done, n_tokens = 26593, batch.n_tokens = 64
slot init_sampler: id  3 | task 12347 | init sampler, took 3.97 ms, tokens: text = 26593, total = 26593
slot update_slots: id  3 | task 12347 | erasing old context checkpoint (pos_min = 20589, pos_max = 21500, size = 21.386 MiB)
slot update_slots: id  3 | task 12347 | created context checkpoint 8 of 8 (pos_min = 25592, pos_max = 26528, size = 21.972 MiB)
slot print_timing: id  3 | task 12347 | 
prompt eval time =     304.76 ms /    65 tokens (    4.69 ms per token,   213.28 tokens per second)
       eval time =    1928.88 ms /    73 tokens (   26.42 ms per token,    37.85 tokens per second)
      total time =    2233.64 ms /   138 tokens
slot      release: id  3 | task 12347 | stop processing: n_tokens = 26665, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.015
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 26665, total state size = 647.590 MiB
srv          load:  - looking for better prompt, base f_keep = 0.015, sim = 0.985
srv        update:  - cache state: 2 prompts, 889.797 MiB (limits: 8192.000 MiB, 64000 tokens, 255086 est)
srv        update:    - prompt 0x5b74dc0d5ef0:    1042 tokens, checkpoints:  1,    56.513 MiB
srv        update:    - prompt 0x5b74e55a53f0:   26665 tokens, checkpoints:  8,   833.285 MiB
srv  get_availabl: prompt cache update took 1021.77 ms
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12422 | processing task, is_child = 0
slot update_slots: id  3 | task 12422 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 407
slot update_slots: id  3 | task 12422 | n_past = 401, slot.prompt.tokens.size() = 26665, seq_id = 3, pos_min = 25713, n_swa = 128
slot update_slots: id  3 | task 12422 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  3 | task 12422 | erased invalidated context checkpoint (pos_min = 21130, pos_max = 22105, n_swa = 128, size = 22.886 MiB)
slot update_slots: id  3 | task 12422 | erased invalidated context checkpoint (pos_min = 21777, pos_max = 22800, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 12422 | erased invalidated context checkpoint (pos_min = 22228, pos_max = 23251, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 12422 | erased invalidated context checkpoint (pos_min = 22440, pos_max = 23463, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 12422 | erased invalidated context checkpoint (pos_min = 22651, pos_max = 23536, n_swa = 128, size = 20.776 MiB)
slot update_slots: id  3 | task 12422 | erased invalidated context checkpoint (pos_min = 25083, pos_max = 26106, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 12422 | erased invalidated context checkpoint (pos_min = 25440, pos_max = 26463, n_swa = 128, size = 24.012 MiB)
slot update_slots: id  3 | task 12422 | erased invalidated context checkpoint (pos_min = 25592, pos_max = 26528, n_swa = 128, size = 21.972 MiB)
slot update_slots: id  3 | task 12422 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  3 | task 12422 | prompt processing progress, n_tokens = 343, batch.n_tokens = 343, progress = 0.842752
slot update_slots: id  3 | task 12422 | n_tokens = 343, memory_seq_rm [343, end)
slot update_slots: id  3 | task 12422 | prompt processing progress, n_tokens = 407, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  3 | task 12422 | prompt done, n_tokens = 407, batch.n_tokens = 64
slot init_sampler: id  3 | task 12422 | init sampler, took 0.09 ms, tokens: text = 407, total = 407
slot update_slots: id  3 | task 12422 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 342, size = 8.043 MiB)
slot print_timing: id  3 | task 12422 | 
prompt eval time =     657.98 ms /   407 tokens (    1.62 ms per token,   618.56 tokens per second)
       eval time =     818.42 ms /    35 tokens (   23.38 ms per token,    42.77 tokens per second)
      total time =    1476.40 ms /   442 tokens
slot      release: id  3 | task 12422 | stop processing: n_tokens = 441, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.909
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12459 | processing task, is_child = 0
slot update_slots: id  3 | task 12459 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 407
slot update_slots: id  3 | task 12459 | n_tokens = 401, memory_seq_rm [401, end)
slot update_slots: id  3 | task 12459 | prompt processing progress, n_tokens = 407, batch.n_tokens = 6, progress = 1.000000
slot update_slots: id  3 | task 12459 | prompt done, n_tokens = 407, batch.n_tokens = 6
slot init_sampler: id  3 | task 12459 | init sampler, took 0.09 ms, tokens: text = 407, total = 407
slot print_timing: id  3 | task 12459 | 
prompt eval time =      93.61 ms /     6 tokens (   15.60 ms per token,    64.10 tokens per second)
       eval time =     872.19 ms /    37 tokens (   23.57 ms per token,    42.42 tokens per second)
      total time =     965.79 ms /    43 tokens
slot      release: id  3 | task 12459 | stop processing: n_tokens = 443, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  3 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.905
slot launch_slot_: id  3 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  3 | task 12497 | processing task, is_child = 0
slot update_slots: id  3 | task 12497 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 406
slot update_slots: id  3 | task 12497 | n_tokens = 401, memory_seq_rm [401, end)
slot update_slots: id  3 | task 12497 | prompt processing progress, n_tokens = 406, batch.n_tokens = 5, progress = 1.000000
slot update_slots: id  3 | task 12497 | prompt done, n_tokens = 406, batch.n_tokens = 5
slot init_sampler: id  3 | task 12497 | init sampler, took 0.08 ms, tokens: text = 406, total = 406
slot print_timing: id  3 | task 12497 | 
prompt eval time =      94.85 ms /     5 tokens (   18.97 ms per token,    52.72 tokens per second)
       eval time =    6736.91 ms /   276 tokens (   24.41 ms per token,    40.97 tokens per second)
      total time =    6831.76 ms /   281 tokens
slot      release: id  3 | task 12497 | stop processing: n_tokens = 681, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LRU, t_last = -1
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 12774 | processing task, is_child = 0
slot update_slots: id  2 | task 12774 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 27151
slot update_slots: id  2 | task 12774 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 2048, batch.n_tokens = 2048, progress = 0.075430
slot update_slots: id  2 | task 12774 | n_tokens = 2048, memory_seq_rm [2048, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 4096, batch.n_tokens = 2048, progress = 0.150860
slot update_slots: id  2 | task 12774 | n_tokens = 4096, memory_seq_rm [4096, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 6144, batch.n_tokens = 2048, progress = 0.226290
slot update_slots: id  2 | task 12774 | n_tokens = 6144, memory_seq_rm [6144, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 8192, batch.n_tokens = 2048, progress = 0.301720
slot update_slots: id  2 | task 12774 | n_tokens = 8192, memory_seq_rm [8192, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 10240, batch.n_tokens = 2048, progress = 0.377150
slot update_slots: id  2 | task 12774 | n_tokens = 10240, memory_seq_rm [10240, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 12288, batch.n_tokens = 2048, progress = 0.452580
slot update_slots: id  2 | task 12774 | n_tokens = 12288, memory_seq_rm [12288, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 14336, batch.n_tokens = 2048, progress = 0.528010
slot update_slots: id  2 | task 12774 | n_tokens = 14336, memory_seq_rm [14336, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 16384, batch.n_tokens = 2048, progress = 0.603440
slot update_slots: id  2 | task 12774 | n_tokens = 16384, memory_seq_rm [16384, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 18432, batch.n_tokens = 2048, progress = 0.678870
slot update_slots: id  2 | task 12774 | n_tokens = 18432, memory_seq_rm [18432, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 20480, batch.n_tokens = 2048, progress = 0.754300
slot update_slots: id  2 | task 12774 | n_tokens = 20480, memory_seq_rm [20480, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 22528, batch.n_tokens = 2048, progress = 0.829730
slot update_slots: id  2 | task 12774 | n_tokens = 22528, memory_seq_rm [22528, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 24576, batch.n_tokens = 2048, progress = 0.905160
slot update_slots: id  2 | task 12774 | n_tokens = 24576, memory_seq_rm [24576, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 26624, batch.n_tokens = 2048, progress = 0.980590
slot update_slots: id  2 | task 12774 | n_tokens = 26624, memory_seq_rm [26624, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 27087, batch.n_tokens = 463, progress = 0.997643
slot update_slots: id  2 | task 12774 | n_tokens = 27087, memory_seq_rm [27087, end)
slot update_slots: id  2 | task 12774 | prompt processing progress, n_tokens = 27151, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 12774 | prompt done, n_tokens = 27151, batch.n_tokens = 64
slot init_sampler: id  2 | task 12774 | init sampler, took 4.19 ms, tokens: text = 27151, total = 27151
slot update_slots: id  2 | task 12774 | created context checkpoint 1 of 8 (pos_min = 26190, pos_max = 27086, size = 21.034 MiB)
slot print_timing: id  2 | task 12774 | 
prompt eval time =   34074.67 ms / 27151 tokens (    1.26 ms per token,   796.81 tokens per second)
       eval time =   36822.91 ms /  1358 tokens (   27.12 ms per token,    36.88 tokens per second)
      total time =   70897.58 ms / 28509 tokens
slot      release: id  2 | task 12774 | stop processing: n_tokens = 28508, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.952
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 14147 | processing task, is_child = 0
slot update_slots: id  2 | task 14147 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 27335
slot update_slots: id  2 | task 14147 | n_past = 27151, slot.prompt.tokens.size() = 28508, seq_id = 2, pos_min = 27611, n_swa = 128
slot update_slots: id  2 | task 14147 | restored context checkpoint (pos_min = 26190, pos_max = 27086, size = 21.034 MiB)
slot update_slots: id  2 | task 14147 | n_tokens = 27086, memory_seq_rm [27086, end)
slot update_slots: id  2 | task 14147 | prompt processing progress, n_tokens = 27271, batch.n_tokens = 185, progress = 0.997659
slot update_slots: id  2 | task 14147 | n_tokens = 27271, memory_seq_rm [27271, end)
slot update_slots: id  2 | task 14147 | prompt processing progress, n_tokens = 27335, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 14147 | prompt done, n_tokens = 27335, batch.n_tokens = 64
slot init_sampler: id  2 | task 14147 | init sampler, took 3.85 ms, tokens: text = 27335, total = 27335
slot update_slots: id  2 | task 14147 | created context checkpoint 2 of 8 (pos_min = 26374, pos_max = 27270, size = 21.034 MiB)
slot print_timing: id  2 | task 14147 | 
prompt eval time =     728.28 ms /   249 tokens (    2.92 ms per token,   341.90 tokens per second)
       eval time =    1115.20 ms /    41 tokens (   27.20 ms per token,    36.76 tokens per second)
      total time =    1843.48 ms /   290 tokens
slot      release: id  2 | task 14147 | stop processing: n_tokens = 27375, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.980 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 14190 | processing task, is_child = 0
slot update_slots: id  2 | task 14190 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 27889
slot update_slots: id  2 | task 14190 | n_tokens = 27335, memory_seq_rm [27335, end)
slot update_slots: id  2 | task 14190 | prompt processing progress, n_tokens = 27825, batch.n_tokens = 490, progress = 0.997705
slot update_slots: id  2 | task 14190 | n_tokens = 27825, memory_seq_rm [27825, end)
slot update_slots: id  2 | task 14190 | prompt processing progress, n_tokens = 27889, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 14190 | prompt done, n_tokens = 27889, batch.n_tokens = 64
slot init_sampler: id  2 | task 14190 | init sampler, took 4.08 ms, tokens: text = 27889, total = 27889
slot update_slots: id  2 | task 14190 | created context checkpoint 3 of 8 (pos_min = 26928, pos_max = 27824, size = 21.034 MiB)
slot print_timing: id  2 | task 14190 | 
prompt eval time =     922.95 ms /   554 tokens (    1.67 ms per token,   600.25 tokens per second)
       eval time =   15341.75 ms /   559 tokens (   27.44 ms per token,    36.44 tokens per second)
      total time =   16264.69 ms /  1113 tokens
slot      release: id  2 | task 14190 | stop processing: n_tokens = 28447, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 14751 | processing task, is_child = 0
slot update_slots: id  2 | task 14751 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 28142
slot update_slots: id  2 | task 14751 | n_tokens = 27889, memory_seq_rm [27889, end)
slot update_slots: id  2 | task 14751 | prompt processing progress, n_tokens = 28078, batch.n_tokens = 189, progress = 0.997726
slot update_slots: id  2 | task 14751 | n_tokens = 28078, memory_seq_rm [28078, end)
slot update_slots: id  2 | task 14751 | prompt processing progress, n_tokens = 28142, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 14751 | prompt done, n_tokens = 28142, batch.n_tokens = 64
slot init_sampler: id  2 | task 14751 | init sampler, took 4.33 ms, tokens: text = 28142, total = 28142
slot update_slots: id  2 | task 14751 | created context checkpoint 4 of 8 (pos_min = 27550, pos_max = 28077, size = 12.381 MiB)
slot print_timing: id  2 | task 14751 | 
prompt eval time =     599.48 ms /   253 tokens (    2.37 ms per token,   422.03 tokens per second)
       eval time =   11447.03 ms /   407 tokens (   28.13 ms per token,    35.56 tokens per second)
      total time =   12046.52 ms /   660 tokens
slot      release: id  2 | task 14751 | stop processing: n_tokens = 28548, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.986
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 15160 | processing task, is_child = 0
slot update_slots: id  2 | task 15160 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 28484
slot update_slots: id  2 | task 15160 | n_tokens = 28142, memory_seq_rm [28142, end)
slot update_slots: id  2 | task 15160 | prompt processing progress, n_tokens = 28420, batch.n_tokens = 278, progress = 0.997753
slot update_slots: id  2 | task 15160 | n_tokens = 28420, memory_seq_rm [28420, end)
slot update_slots: id  2 | task 15160 | prompt processing progress, n_tokens = 28484, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 15160 | prompt done, n_tokens = 28484, batch.n_tokens = 64
slot init_sampler: id  2 | task 15160 | init sampler, took 4.48 ms, tokens: text = 28484, total = 28484
slot update_slots: id  2 | task 15160 | created context checkpoint 5 of 8 (pos_min = 27889, pos_max = 28419, size = 12.452 MiB)
slot print_timing: id  2 | task 15160 | 
prompt eval time =     675.44 ms /   342 tokens (    1.97 ms per token,   506.34 tokens per second)
       eval time =    8886.48 ms /   319 tokens (   27.86 ms per token,    35.90 tokens per second)
      total time =    9561.92 ms /   661 tokens
slot      release: id  2 | task 15160 | stop processing: n_tokens = 28802, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.989
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 15481 | processing task, is_child = 0
slot update_slots: id  2 | task 15481 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 28817
slot update_slots: id  2 | task 15481 | n_tokens = 28484, memory_seq_rm [28484, end)
slot update_slots: id  2 | task 15481 | prompt processing progress, n_tokens = 28753, batch.n_tokens = 269, progress = 0.997779
slot update_slots: id  2 | task 15481 | n_tokens = 28753, memory_seq_rm [28753, end)
slot update_slots: id  2 | task 15481 | prompt processing progress, n_tokens = 28817, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 15481 | prompt done, n_tokens = 28817, batch.n_tokens = 64
slot init_sampler: id  2 | task 15481 | init sampler, took 4.25 ms, tokens: text = 28817, total = 28817
slot update_slots: id  2 | task 15481 | created context checkpoint 6 of 8 (pos_min = 28158, pos_max = 28752, size = 13.952 MiB)
slot print_timing: id  2 | task 15481 | 
prompt eval time =     674.79 ms /   333 tokens (    2.03 ms per token,   493.49 tokens per second)
       eval time =    1324.45 ms /    48 tokens (   27.59 ms per token,    36.24 tokens per second)
      total time =    1999.25 ms /   381 tokens
slot      release: id  2 | task 15481 | stop processing: n_tokens = 28864, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 15531 | processing task, is_child = 0
slot update_slots: id  2 | task 15531 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 29271
slot update_slots: id  2 | task 15531 | n_tokens = 28817, memory_seq_rm [28817, end)
slot update_slots: id  2 | task 15531 | prompt processing progress, n_tokens = 29207, batch.n_tokens = 390, progress = 0.997814
slot update_slots: id  2 | task 15531 | n_tokens = 29207, memory_seq_rm [29207, end)
slot update_slots: id  2 | task 15531 | prompt processing progress, n_tokens = 29271, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 15531 | prompt done, n_tokens = 29271, batch.n_tokens = 64
slot init_sampler: id  2 | task 15531 | init sampler, took 4.57 ms, tokens: text = 29271, total = 29271
slot update_slots: id  2 | task 15531 | created context checkpoint 7 of 8 (pos_min = 28484, pos_max = 29206, size = 16.954 MiB)
slot print_timing: id  2 | task 15531 | 
prompt eval time =     790.87 ms /   454 tokens (    1.74 ms per token,   574.05 tokens per second)
       eval time =    6933.74 ms /   252 tokens (   27.51 ms per token,    36.34 tokens per second)
      total time =    7724.60 ms /   706 tokens
slot      release: id  2 | task 15531 | stop processing: n_tokens = 29522, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 15785 | processing task, is_child = 0
slot update_slots: id  2 | task 15785 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 29532
slot update_slots: id  2 | task 15785 | n_tokens = 29271, memory_seq_rm [29271, end)
slot update_slots: id  2 | task 15785 | prompt processing progress, n_tokens = 29468, batch.n_tokens = 197, progress = 0.997833
slot update_slots: id  2 | task 15785 | n_tokens = 29468, memory_seq_rm [29468, end)
slot update_slots: id  2 | task 15785 | prompt processing progress, n_tokens = 29532, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 15785 | prompt done, n_tokens = 29532, batch.n_tokens = 64
slot init_sampler: id  2 | task 15785 | init sampler, took 4.47 ms, tokens: text = 29532, total = 29532
slot update_slots: id  2 | task 15785 | created context checkpoint 8 of 8 (pos_min = 28681, pos_max = 29467, size = 18.455 MiB)
slot print_timing: id  2 | task 15785 | 
prompt eval time =     627.61 ms /   261 tokens (    2.40 ms per token,   415.86 tokens per second)
       eval time =    1522.48 ms /    55 tokens (   27.68 ms per token,    36.13 tokens per second)
      total time =    2150.09 ms /   316 tokens
slot      release: id  2 | task 15785 | stop processing: n_tokens = 29586, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 15842 | processing task, is_child = 0
slot update_slots: id  2 | task 15842 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 30154
slot update_slots: id  2 | task 15842 | n_tokens = 29532, memory_seq_rm [29532, end)
slot update_slots: id  2 | task 15842 | prompt processing progress, n_tokens = 30090, batch.n_tokens = 558, progress = 0.997878
slot update_slots: id  2 | task 15842 | n_tokens = 30090, memory_seq_rm [30090, end)
slot update_slots: id  2 | task 15842 | prompt processing progress, n_tokens = 30154, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 15842 | prompt done, n_tokens = 30154, batch.n_tokens = 64
slot init_sampler: id  2 | task 15842 | init sampler, took 4.38 ms, tokens: text = 30154, total = 30154
slot update_slots: id  2 | task 15842 | erasing old context checkpoint (pos_min = 26190, pos_max = 27086, size = 21.034 MiB)
slot update_slots: id  2 | task 15842 | created context checkpoint 8 of 8 (pos_min = 29271, pos_max = 30089, size = 19.205 MiB)
slot print_timing: id  2 | task 15842 | 
prompt eval time =    1117.38 ms /   622 tokens (    1.80 ms per token,   556.66 tokens per second)
       eval time =   12899.38 ms /   467 tokens (   27.62 ms per token,    36.20 tokens per second)
      total time =   14016.76 ms /  1089 tokens
slot      release: id  2 | task 15842 | stop processing: n_tokens = 30620, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 16311 | processing task, is_child = 0
slot update_slots: id  2 | task 16311 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 30389
slot update_slots: id  2 | task 16311 | n_tokens = 30154, memory_seq_rm [30154, end)
slot update_slots: id  2 | task 16311 | prompt processing progress, n_tokens = 30325, batch.n_tokens = 171, progress = 0.997894
slot update_slots: id  2 | task 16311 | n_tokens = 30325, memory_seq_rm [30325, end)
slot update_slots: id  2 | task 16311 | prompt processing progress, n_tokens = 30389, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 16311 | prompt done, n_tokens = 30389, batch.n_tokens = 64
slot init_sampler: id  2 | task 16311 | init sampler, took 4.72 ms, tokens: text = 30389, total = 30389
slot update_slots: id  2 | task 16311 | erasing old context checkpoint (pos_min = 26374, pos_max = 27270, size = 21.034 MiB)
slot update_slots: id  2 | task 16311 | created context checkpoint 8 of 8 (pos_min = 29723, pos_max = 30324, size = 14.117 MiB)
slot print_timing: id  2 | task 16311 | 
prompt eval time =     577.40 ms /   235 tokens (    2.46 ms per token,   407.00 tokens per second)
       eval time =    1358.06 ms /    49 tokens (   27.72 ms per token,    36.08 tokens per second)
      total time =    1935.46 ms /   284 tokens
slot      release: id  2 | task 16311 | stop processing: n_tokens = 30437, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 16362 | processing task, is_child = 0
slot update_slots: id  2 | task 16362 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 30598
slot update_slots: id  2 | task 16362 | n_tokens = 30389, memory_seq_rm [30389, end)
slot update_slots: id  2 | task 16362 | prompt processing progress, n_tokens = 30534, batch.n_tokens = 145, progress = 0.997908
slot update_slots: id  2 | task 16362 | n_tokens = 30534, memory_seq_rm [30534, end)
slot update_slots: id  2 | task 16362 | prompt processing progress, n_tokens = 30598, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 16362 | prompt done, n_tokens = 30598, batch.n_tokens = 64
slot init_sampler: id  2 | task 16362 | init sampler, took 4.80 ms, tokens: text = 30598, total = 30598
slot update_slots: id  2 | task 16362 | erasing old context checkpoint (pos_min = 26928, pos_max = 27824, size = 21.034 MiB)
slot update_slots: id  2 | task 16362 | created context checkpoint 8 of 8 (pos_min = 29723, pos_max = 30533, size = 19.017 MiB)
slot print_timing: id  2 | task 16362 | 
prompt eval time =     520.27 ms /   209 tokens (    2.49 ms per token,   401.72 tokens per second)
       eval time =    1658.09 ms /    60 tokens (   27.63 ms per token,    36.19 tokens per second)
      total time =    2178.35 ms /   269 tokens
slot      release: id  2 | task 16362 | stop processing: n_tokens = 30657, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 16424 | processing task, is_child = 0
slot update_slots: id  2 | task 16424 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 30871
slot update_slots: id  2 | task 16424 | n_tokens = 30598, memory_seq_rm [30598, end)
slot update_slots: id  2 | task 16424 | prompt processing progress, n_tokens = 30807, batch.n_tokens = 209, progress = 0.997927
slot update_slots: id  2 | task 16424 | n_tokens = 30807, memory_seq_rm [30807, end)
slot update_slots: id  2 | task 16424 | prompt processing progress, n_tokens = 30871, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 16424 | prompt done, n_tokens = 30871, batch.n_tokens = 64
slot init_sampler: id  2 | task 16424 | init sampler, took 9.36 ms, tokens: text = 30871, total = 30871
slot update_slots: id  2 | task 16424 | erasing old context checkpoint (pos_min = 27550, pos_max = 28077, size = 12.381 MiB)
slot update_slots: id  2 | task 16424 | created context checkpoint 8 of 8 (pos_min = 29924, pos_max = 30806, size = 20.706 MiB)
slot print_timing: id  2 | task 16424 | 
prompt eval time =     621.43 ms /   273 tokens (    2.28 ms per token,   439.31 tokens per second)
       eval time =    6904.79 ms /   249 tokens (   27.73 ms per token,    36.06 tokens per second)
      total time =    7526.22 ms /   522 tokens
slot      release: id  2 | task 16424 | stop processing: n_tokens = 31119, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 16675 | processing task, is_child = 0
slot update_slots: id  2 | task 16675 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31132
slot update_slots: id  2 | task 16675 | n_tokens = 30871, memory_seq_rm [30871, end)
slot update_slots: id  2 | task 16675 | prompt processing progress, n_tokens = 31068, batch.n_tokens = 197, progress = 0.997944
slot update_slots: id  2 | task 16675 | n_tokens = 31068, memory_seq_rm [31068, end)
slot update_slots: id  2 | task 16675 | prompt processing progress, n_tokens = 31132, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 16675 | prompt done, n_tokens = 31132, batch.n_tokens = 64
slot init_sampler: id  2 | task 16675 | init sampler, took 4.68 ms, tokens: text = 31132, total = 31132
slot update_slots: id  2 | task 16675 | erasing old context checkpoint (pos_min = 27889, pos_max = 28419, size = 12.452 MiB)
slot update_slots: id  2 | task 16675 | created context checkpoint 8 of 8 (pos_min = 30351, pos_max = 31067, size = 16.813 MiB)
slot print_timing: id  2 | task 16675 | 
prompt eval time =     636.44 ms /   261 tokens (    2.44 ms per token,   410.10 tokens per second)
       eval time =    1724.95 ms /    62 tokens (   27.82 ms per token,    35.94 tokens per second)
      total time =    2361.39 ms /   323 tokens
slot      release: id  2 | task 16675 | stop processing: n_tokens = 31193, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 16739 | processing task, is_child = 0
slot update_slots: id  2 | task 16739 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31297
slot update_slots: id  2 | task 16739 | n_tokens = 31132, memory_seq_rm [31132, end)
slot update_slots: id  2 | task 16739 | prompt processing progress, n_tokens = 31233, batch.n_tokens = 101, progress = 0.997955
slot update_slots: id  2 | task 16739 | n_tokens = 31233, memory_seq_rm [31233, end)
slot update_slots: id  2 | task 16739 | prompt processing progress, n_tokens = 31297, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 16739 | prompt done, n_tokens = 31297, batch.n_tokens = 64
slot init_sampler: id  2 | task 16739 | init sampler, took 4.53 ms, tokens: text = 31297, total = 31297
slot update_slots: id  2 | task 16739 | erasing old context checkpoint (pos_min = 28158, pos_max = 28752, size = 13.952 MiB)
slot update_slots: id  2 | task 16739 | created context checkpoint 8 of 8 (pos_min = 30516, pos_max = 31232, size = 16.813 MiB)
slot print_timing: id  2 | task 16739 | 
prompt eval time =     513.09 ms /   165 tokens (    3.11 ms per token,   321.58 tokens per second)
       eval time =    7013.13 ms /   250 tokens (   28.05 ms per token,    35.65 tokens per second)
      total time =    7526.22 ms /   415 tokens
slot      release: id  2 | task 16739 | stop processing: n_tokens = 31546, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 16991 | processing task, is_child = 0
slot update_slots: id  2 | task 16991 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31556
slot update_slots: id  2 | task 16991 | n_tokens = 31297, memory_seq_rm [31297, end)
slot update_slots: id  2 | task 16991 | prompt processing progress, n_tokens = 31492, batch.n_tokens = 195, progress = 0.997972
slot update_slots: id  2 | task 16991 | n_tokens = 31492, memory_seq_rm [31492, end)
slot update_slots: id  2 | task 16991 | prompt processing progress, n_tokens = 31556, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 16991 | prompt done, n_tokens = 31556, batch.n_tokens = 64
slot init_sampler: id  2 | task 16991 | init sampler, took 4.63 ms, tokens: text = 31556, total = 31556
slot update_slots: id  2 | task 16991 | erasing old context checkpoint (pos_min = 28484, pos_max = 29206, size = 16.954 MiB)
slot update_slots: id  2 | task 16991 | created context checkpoint 8 of 8 (pos_min = 30829, pos_max = 31491, size = 15.547 MiB)
slot print_timing: id  2 | task 16991 | 
prompt eval time =     642.43 ms /   259 tokens (    2.48 ms per token,   403.15 tokens per second)
       eval time =   32885.19 ms /  1171 tokens (   28.08 ms per token,    35.61 tokens per second)
      total time =   33527.62 ms /  1430 tokens
slot      release: id  2 | task 16991 | stop processing: n_tokens = 32726, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.964
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 18164 | processing task, is_child = 0
slot update_slots: id  2 | task 18164 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31817
slot update_slots: id  2 | task 18164 | n_past = 31556, slot.prompt.tokens.size() = 32726, seq_id = 2, pos_min = 31829, n_swa = 128
slot update_slots: id  2 | task 18164 | restored context checkpoint (pos_min = 30829, pos_max = 31491, size = 15.547 MiB)
slot update_slots: id  2 | task 18164 | n_tokens = 31491, memory_seq_rm [31491, end)
slot update_slots: id  2 | task 18164 | prompt processing progress, n_tokens = 31753, batch.n_tokens = 262, progress = 0.997989
slot update_slots: id  2 | task 18164 | n_tokens = 31753, memory_seq_rm [31753, end)
slot update_slots: id  2 | task 18164 | prompt processing progress, n_tokens = 31817, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 18164 | prompt done, n_tokens = 31817, batch.n_tokens = 64
slot init_sampler: id  2 | task 18164 | init sampler, took 6.24 ms, tokens: text = 31817, total = 31817
slot update_slots: id  2 | task 18164 | erasing old context checkpoint (pos_min = 28681, pos_max = 29467, size = 18.455 MiB)
slot update_slots: id  2 | task 18164 | created context checkpoint 8 of 8 (pos_min = 30871, pos_max = 31752, size = 20.682 MiB)
slot print_timing: id  2 | task 18164 | 
prompt eval time =     826.70 ms /   326 tokens (    2.54 ms per token,   394.34 tokens per second)
       eval time =   10958.33 ms /   393 tokens (   27.88 ms per token,    35.86 tokens per second)
      total time =   11785.02 ms /   719 tokens
slot      release: id  2 | task 18164 | stop processing: n_tokens = 32209, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 18559 | processing task, is_child = 0
slot update_slots: id  2 | task 18559 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32078
slot update_slots: id  2 | task 18559 | n_tokens = 31817, memory_seq_rm [31817, end)
slot update_slots: id  2 | task 18559 | prompt processing progress, n_tokens = 32014, batch.n_tokens = 197, progress = 0.998005
slot update_slots: id  2 | task 18559 | n_tokens = 32014, memory_seq_rm [32014, end)
slot update_slots: id  2 | task 18559 | prompt processing progress, n_tokens = 32078, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 18559 | prompt done, n_tokens = 32078, batch.n_tokens = 64
slot init_sampler: id  2 | task 18559 | init sampler, took 6.03 ms, tokens: text = 32078, total = 32078
slot update_slots: id  2 | task 18559 | erasing old context checkpoint (pos_min = 29271, pos_max = 30089, size = 19.205 MiB)
slot update_slots: id  2 | task 18559 | created context checkpoint 8 of 8 (pos_min = 31312, pos_max = 32013, size = 16.461 MiB)
slot print_timing: id  2 | task 18559 | 
prompt eval time =     634.08 ms /   261 tokens (    2.43 ms per token,   411.62 tokens per second)
       eval time =    2713.09 ms /    96 tokens (   28.26 ms per token,    35.38 tokens per second)
      total time =    3347.17 ms /   357 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 18559 | stop processing: n_tokens = 32173, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 18657 | processing task, is_child = 0
slot update_slots: id  2 | task 18657 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32157
slot update_slots: id  2 | task 18657 | n_tokens = 32078, memory_seq_rm [32078, end)
slot update_slots: id  2 | task 18657 | prompt processing progress, n_tokens = 32093, batch.n_tokens = 15, progress = 0.998010
slot update_slots: id  2 | task 18657 | n_tokens = 32093, memory_seq_rm [32093, end)
slot update_slots: id  2 | task 18657 | prompt processing progress, n_tokens = 32157, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 18657 | prompt done, n_tokens = 32157, batch.n_tokens = 64
slot init_sampler: id  2 | task 18657 | init sampler, took 8.48 ms, tokens: text = 32157, total = 32157
slot update_slots: id  2 | task 18657 | erasing old context checkpoint (pos_min = 29723, pos_max = 30324, size = 14.117 MiB)
slot update_slots: id  2 | task 18657 | created context checkpoint 8 of 8 (pos_min = 31312, pos_max = 32092, size = 18.314 MiB)
slot print_timing: id  2 | task 18657 | 
prompt eval time =     318.69 ms /    79 tokens (    4.03 ms per token,   247.89 tokens per second)
       eval time =    1467.02 ms /    53 tokens (   27.68 ms per token,    36.13 tokens per second)
      total time =    1785.70 ms /   132 tokens
slot      release: id  2 | task 18657 | stop processing: n_tokens = 32209, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 18712 | processing task, is_child = 0
slot update_slots: id  2 | task 18712 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32311
slot update_slots: id  2 | task 18712 | n_tokens = 32157, memory_seq_rm [32157, end)
slot update_slots: id  2 | task 18712 | prompt processing progress, n_tokens = 32247, batch.n_tokens = 90, progress = 0.998019
slot update_slots: id  2 | task 18712 | n_tokens = 32247, memory_seq_rm [32247, end)
slot update_slots: id  2 | task 18712 | prompt processing progress, n_tokens = 32311, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 18712 | prompt done, n_tokens = 32311, batch.n_tokens = 64
slot init_sampler: id  2 | task 18712 | init sampler, took 5.04 ms, tokens: text = 32311, total = 32311
slot update_slots: id  2 | task 18712 | erasing old context checkpoint (pos_min = 29723, pos_max = 30533, size = 19.017 MiB)
slot update_slots: id  2 | task 18712 | created context checkpoint 8 of 8 (pos_min = 31350, pos_max = 32246, size = 21.034 MiB)
slot print_timing: id  2 | task 18712 | 
prompt eval time =     487.41 ms /   154 tokens (    3.16 ms per token,   315.96 tokens per second)
       eval time =    7094.43 ms /   256 tokens (   27.71 ms per token,    36.08 tokens per second)
      total time =    7581.84 ms /   410 tokens
slot      release: id  2 | task 18712 | stop processing: n_tokens = 32566, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 18970 | processing task, is_child = 0
slot update_slots: id  2 | task 18970 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32572
slot update_slots: id  2 | task 18970 | n_tokens = 32311, memory_seq_rm [32311, end)
slot update_slots: id  2 | task 18970 | prompt processing progress, n_tokens = 32508, batch.n_tokens = 197, progress = 0.998035
slot update_slots: id  2 | task 18970 | n_tokens = 32508, memory_seq_rm [32508, end)
slot update_slots: id  2 | task 18970 | prompt processing progress, n_tokens = 32572, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 18970 | prompt done, n_tokens = 32572, batch.n_tokens = 64
slot init_sampler: id  2 | task 18970 | init sampler, took 6.82 ms, tokens: text = 32572, total = 32572
slot update_slots: id  2 | task 18970 | erasing old context checkpoint (pos_min = 29924, pos_max = 30806, size = 20.706 MiB)
slot update_slots: id  2 | task 18970 | created context checkpoint 8 of 8 (pos_min = 31669, pos_max = 32507, size = 19.674 MiB)
slot print_timing: id  2 | task 18970 | 
prompt eval time =     693.13 ms /   261 tokens (    2.66 ms per token,   376.55 tokens per second)
       eval time =    1642.09 ms /    59 tokens (   27.83 ms per token,    35.93 tokens per second)
      total time =    2335.22 ms /   320 tokens
slot      release: id  2 | task 18970 | stop processing: n_tokens = 32630, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19031 | processing task, is_child = 0
slot update_slots: id  2 | task 19031 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32737
slot update_slots: id  2 | task 19031 | n_tokens = 32572, memory_seq_rm [32572, end)
slot update_slots: id  2 | task 19031 | prompt processing progress, n_tokens = 32673, batch.n_tokens = 101, progress = 0.998045
slot update_slots: id  2 | task 19031 | n_tokens = 32673, memory_seq_rm [32673, end)
slot update_slots: id  2 | task 19031 | prompt processing progress, n_tokens = 32737, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 19031 | prompt done, n_tokens = 32737, batch.n_tokens = 64
slot init_sampler: id  2 | task 19031 | init sampler, took 5.15 ms, tokens: text = 32737, total = 32737
slot update_slots: id  2 | task 19031 | erasing old context checkpoint (pos_min = 30351, pos_max = 31067, size = 16.813 MiB)
slot update_slots: id  2 | task 19031 | created context checkpoint 8 of 8 (pos_min = 31776, pos_max = 32672, size = 21.034 MiB)
slot print_timing: id  2 | task 19031 | 
prompt eval time =     519.59 ms /   165 tokens (    3.15 ms per token,   317.56 tokens per second)
       eval time =    1454.79 ms /    52 tokens (   27.98 ms per token,    35.74 tokens per second)
      total time =    1974.38 ms /   217 tokens
slot      release: id  2 | task 19031 | stop processing: n_tokens = 32788, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.955 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19085 | processing task, is_child = 0
slot update_slots: id  2 | task 19085 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 34280
slot update_slots: id  2 | task 19085 | n_tokens = 32737, memory_seq_rm [32737, end)
slot update_slots: id  2 | task 19085 | prompt processing progress, n_tokens = 34216, batch.n_tokens = 1479, progress = 0.998133
slot update_slots: id  2 | task 19085 | n_tokens = 34216, memory_seq_rm [34216, end)
slot update_slots: id  2 | task 19085 | prompt processing progress, n_tokens = 34280, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 19085 | prompt done, n_tokens = 34280, batch.n_tokens = 64
slot init_sampler: id  2 | task 19085 | init sampler, took 5.24 ms, tokens: text = 34280, total = 34280
slot update_slots: id  2 | task 19085 | erasing old context checkpoint (pos_min = 30516, pos_max = 31232, size = 16.813 MiB)
slot update_slots: id  2 | task 19085 | created context checkpoint 8 of 8 (pos_min = 33319, pos_max = 34215, size = 21.034 MiB)
slot print_timing: id  2 | task 19085 | 
prompt eval time =    2476.01 ms /  1543 tokens (    1.60 ms per token,   623.18 tokens per second)
       eval time =   10398.77 ms /   369 tokens (   28.18 ms per token,    35.48 tokens per second)
      total time =   12874.78 ms /  1912 tokens
slot      release: id  2 | task 19085 | stop processing: n_tokens = 34648, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.989
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19456 | processing task, is_child = 0
slot update_slots: id  2 | task 19456 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 34541
slot update_slots: id  2 | task 19456 | n_tokens = 34280, memory_seq_rm [34280, end)
slot update_slots: id  2 | task 19456 | prompt processing progress, n_tokens = 34477, batch.n_tokens = 197, progress = 0.998147
slot update_slots: id  2 | task 19456 | n_tokens = 34477, memory_seq_rm [34477, end)
slot update_slots: id  2 | task 19456 | prompt processing progress, n_tokens = 34541, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 19456 | prompt done, n_tokens = 34541, batch.n_tokens = 64
slot init_sampler: id  2 | task 19456 | init sampler, took 5.56 ms, tokens: text = 34541, total = 34541
slot update_slots: id  2 | task 19456 | erasing old context checkpoint (pos_min = 30829, pos_max = 31491, size = 15.547 MiB)
slot update_slots: id  2 | task 19456 | created context checkpoint 8 of 8 (pos_min = 33759, pos_max = 34476, size = 16.837 MiB)
slot print_timing: id  2 | task 19456 | 
prompt eval time =     664.19 ms /   261 tokens (    2.54 ms per token,   392.96 tokens per second)
       eval time =    2080.72 ms /    73 tokens (   28.50 ms per token,    35.08 tokens per second)
      total time =    2744.91 ms /   334 tokens
slot      release: id  2 | task 19456 | stop processing: n_tokens = 34613, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19531 | processing task, is_child = 0
slot update_slots: id  2 | task 19531 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 34798
slot update_slots: id  2 | task 19531 | n_tokens = 34541, memory_seq_rm [34541, end)
slot update_slots: id  2 | task 19531 | prompt processing progress, n_tokens = 34734, batch.n_tokens = 193, progress = 0.998161
slot update_slots: id  2 | task 19531 | n_tokens = 34734, memory_seq_rm [34734, end)
slot update_slots: id  2 | task 19531 | prompt processing progress, n_tokens = 34798, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 19531 | prompt done, n_tokens = 34798, batch.n_tokens = 64
slot init_sampler: id  2 | task 19531 | init sampler, took 5.86 ms, tokens: text = 34798, total = 34798
slot update_slots: id  2 | task 19531 | erasing old context checkpoint (pos_min = 30871, pos_max = 31752, size = 20.682 MiB)
slot update_slots: id  2 | task 19531 | created context checkpoint 8 of 8 (pos_min = 34016, pos_max = 34733, size = 16.837 MiB)
slot print_timing: id  2 | task 19531 | 
prompt eval time =     625.06 ms /   257 tokens (    2.43 ms per token,   411.16 tokens per second)
       eval time =    2001.56 ms /    69 tokens (   29.01 ms per token,    34.47 tokens per second)
      total time =    2626.62 ms /   326 tokens
slot      release: id  2 | task 19531 | stop processing: n_tokens = 34866, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19602 | processing task, is_child = 0
slot update_slots: id  2 | task 19602 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 35031
slot update_slots: id  2 | task 19602 | n_tokens = 34798, memory_seq_rm [34798, end)
slot update_slots: id  2 | task 19602 | prompt processing progress, n_tokens = 34967, batch.n_tokens = 169, progress = 0.998173
slot update_slots: id  2 | task 19602 | n_tokens = 34967, memory_seq_rm [34967, end)
slot update_slots: id  2 | task 19602 | prompt processing progress, n_tokens = 35031, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 19602 | prompt done, n_tokens = 35031, batch.n_tokens = 64
slot init_sampler: id  2 | task 19602 | init sampler, took 6.64 ms, tokens: text = 35031, total = 35031
slot update_slots: id  2 | task 19602 | erasing old context checkpoint (pos_min = 31312, pos_max = 32013, size = 16.461 MiB)
slot update_slots: id  2 | task 19602 | created context checkpoint 8 of 8 (pos_min = 34249, pos_max = 34966, size = 16.837 MiB)
slot print_timing: id  2 | task 19602 | 
prompt eval time =     688.67 ms /   233 tokens (    2.96 ms per token,   338.33 tokens per second)
       eval time =    7033.32 ms /   248 tokens (   28.36 ms per token,    35.26 tokens per second)
      total time =    7721.99 ms /   481 tokens
slot      release: id  2 | task 19602 | stop processing: n_tokens = 35278, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 19852 | processing task, is_child = 0
slot update_slots: id  2 | task 19852 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 35292
slot update_slots: id  2 | task 19852 | n_tokens = 35031, memory_seq_rm [35031, end)
slot update_slots: id  2 | task 19852 | prompt processing progress, n_tokens = 35228, batch.n_tokens = 197, progress = 0.998187
slot update_slots: id  2 | task 19852 | n_tokens = 35228, memory_seq_rm [35228, end)
slot update_slots: id  2 | task 19852 | prompt processing progress, n_tokens = 35292, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 19852 | prompt done, n_tokens = 35292, batch.n_tokens = 64
slot init_sampler: id  2 | task 19852 | init sampler, took 5.28 ms, tokens: text = 35292, total = 35292
slot update_slots: id  2 | task 19852 | erasing old context checkpoint (pos_min = 31312, pos_max = 32092, size = 18.314 MiB)
slot update_slots: id  2 | task 19852 | created context checkpoint 8 of 8 (pos_min = 34477, pos_max = 35227, size = 17.610 MiB)
slot print_timing: id  2 | task 19852 | 
prompt eval time =     656.94 ms /   261 tokens (    2.52 ms per token,   397.29 tokens per second)
       eval time =   16494.43 ms /   578 tokens (   28.54 ms per token,    35.04 tokens per second)
      total time =   17151.38 ms /   839 tokens
slot      release: id  2 | task 19852 | stop processing: n_tokens = 35869, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.984
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 20432 | processing task, is_child = 0
slot update_slots: id  2 | task 20432 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 35551
slot update_slots: id  2 | task 20432 | n_tokens = 35292, memory_seq_rm [35292, end)
slot update_slots: id  2 | task 20432 | prompt processing progress, n_tokens = 35487, batch.n_tokens = 195, progress = 0.998200
slot update_slots: id  2 | task 20432 | n_tokens = 35487, memory_seq_rm [35487, end)
slot update_slots: id  2 | task 20432 | prompt processing progress, n_tokens = 35551, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 20432 | prompt done, n_tokens = 35551, batch.n_tokens = 64
slot init_sampler: id  2 | task 20432 | init sampler, took 10.73 ms, tokens: text = 35551, total = 35551
slot update_slots: id  2 | task 20432 | erasing old context checkpoint (pos_min = 31350, pos_max = 32246, size = 21.034 MiB)
slot update_slots: id  2 | task 20432 | created context checkpoint 8 of 8 (pos_min = 35031, pos_max = 35486, size = 10.693 MiB)
slot print_timing: id  2 | task 20432 | 
prompt eval time =     709.26 ms /   259 tokens (    2.74 ms per token,   365.17 tokens per second)
       eval time =    1490.29 ms /    53 tokens (   28.12 ms per token,    35.56 tokens per second)
      total time =    2199.56 ms /   312 tokens
slot      release: id  2 | task 20432 | stop processing: n_tokens = 35603, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 20487 | processing task, is_child = 0
slot update_slots: id  2 | task 20487 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 35705
slot update_slots: id  2 | task 20487 | n_tokens = 35551, memory_seq_rm [35551, end)
slot update_slots: id  2 | task 20487 | prompt processing progress, n_tokens = 35641, batch.n_tokens = 90, progress = 0.998208
slot update_slots: id  2 | task 20487 | n_tokens = 35641, memory_seq_rm [35641, end)
slot update_slots: id  2 | task 20487 | prompt processing progress, n_tokens = 35705, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 20487 | prompt done, n_tokens = 35705, batch.n_tokens = 64
slot init_sampler: id  2 | task 20487 | init sampler, took 6.43 ms, tokens: text = 35705, total = 35705
slot update_slots: id  2 | task 20487 | erasing old context checkpoint (pos_min = 31669, pos_max = 32507, size = 19.674 MiB)
slot update_slots: id  2 | task 20487 | created context checkpoint 8 of 8 (pos_min = 35031, pos_max = 35640, size = 14.304 MiB)
slot print_timing: id  2 | task 20487 | 
prompt eval time =     491.07 ms /   154 tokens (    3.19 ms per token,   313.60 tokens per second)
       eval time =    1725.84 ms /    61 tokens (   28.29 ms per token,    35.35 tokens per second)
      total time =    2216.91 ms /   215 tokens
slot      release: id  2 | task 20487 | stop processing: n_tokens = 35765, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 20550 | processing task, is_child = 0
slot update_slots: id  2 | task 20550 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 35970
slot update_slots: id  2 | task 20550 | n_tokens = 35705, memory_seq_rm [35705, end)
slot update_slots: id  2 | task 20550 | prompt processing progress, n_tokens = 35906, batch.n_tokens = 201, progress = 0.998221
slot update_slots: id  2 | task 20550 | n_tokens = 35906, memory_seq_rm [35906, end)
slot update_slots: id  2 | task 20550 | prompt processing progress, n_tokens = 35970, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 20550 | prompt done, n_tokens = 35970, batch.n_tokens = 64
slot init_sampler: id  2 | task 20550 | init sampler, took 5.39 ms, tokens: text = 35970, total = 35970
slot update_slots: id  2 | task 20550 | erasing old context checkpoint (pos_min = 31776, pos_max = 32672, size = 21.034 MiB)
slot update_slots: id  2 | task 20550 | created context checkpoint 8 of 8 (pos_min = 35031, pos_max = 35905, size = 20.518 MiB)
slot print_timing: id  2 | task 20550 | 
prompt eval time =     633.68 ms /   265 tokens (    2.39 ms per token,   418.19 tokens per second)
       eval time =    1700.25 ms /    60 tokens (   28.34 ms per token,    35.29 tokens per second)
      total time =    2333.93 ms /   325 tokens
slot      release: id  2 | task 20550 | stop processing: n_tokens = 36029, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 20612 | processing task, is_child = 0
slot update_slots: id  2 | task 20612 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 36148
slot update_slots: id  2 | task 20612 | n_tokens = 35970, memory_seq_rm [35970, end)
slot update_slots: id  2 | task 20612 | prompt processing progress, n_tokens = 36084, batch.n_tokens = 114, progress = 0.998230
slot update_slots: id  2 | task 20612 | n_tokens = 36084, memory_seq_rm [36084, end)
slot update_slots: id  2 | task 20612 | prompt processing progress, n_tokens = 36148, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 20612 | prompt done, n_tokens = 36148, batch.n_tokens = 64
slot init_sampler: id  2 | task 20612 | init sampler, took 5.80 ms, tokens: text = 36148, total = 36148
slot update_slots: id  2 | task 20612 | erasing old context checkpoint (pos_min = 33319, pos_max = 34215, size = 21.034 MiB)
slot update_slots: id  2 | task 20612 | created context checkpoint 8 of 8 (pos_min = 35187, pos_max = 36083, size = 21.034 MiB)
slot print_timing: id  2 | task 20612 | 
prompt eval time =     575.42 ms /   178 tokens (    3.23 ms per token,   309.34 tokens per second)
       eval time =    2030.72 ms /    70 tokens (   29.01 ms per token,    34.47 tokens per second)
      total time =    2606.14 ms /   248 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 20612 | stop processing: n_tokens = 36217, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 20684 | processing task, is_child = 0
slot update_slots: id  2 | task 20684 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 36432
slot update_slots: id  2 | task 20684 | n_tokens = 36148, memory_seq_rm [36148, end)
slot update_slots: id  2 | task 20684 | prompt processing progress, n_tokens = 36368, batch.n_tokens = 220, progress = 0.998243
slot update_slots: id  2 | task 20684 | n_tokens = 36368, memory_seq_rm [36368, end)
slot update_slots: id  2 | task 20684 | prompt processing progress, n_tokens = 36432, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 20684 | prompt done, n_tokens = 36432, batch.n_tokens = 64
slot init_sampler: id  2 | task 20684 | init sampler, took 5.39 ms, tokens: text = 36432, total = 36432
slot update_slots: id  2 | task 20684 | erasing old context checkpoint (pos_min = 33759, pos_max = 34476, size = 16.837 MiB)
slot update_slots: id  2 | task 20684 | created context checkpoint 8 of 8 (pos_min = 35471, pos_max = 36367, size = 21.034 MiB)
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv          stop: cancel task, id_task = 20684
slot      release: id  2 | task 20684 | stop processing: n_tokens = 36436, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.746 (> 0.100 thold), f_keep = 0.750
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 20692 | processing task, is_child = 0
slot update_slots: id  2 | task 20692 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 36642
slot update_slots: id  2 | task 20692 | n_past = 27335, slot.prompt.tokens.size() = 36436, seq_id = 2, pos_min = 35539, n_swa = 128
slot update_slots: id  2 | task 20692 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  2 | task 20692 | erased invalidated context checkpoint (pos_min = 34016, pos_max = 34733, n_swa = 128, size = 16.837 MiB)
slot update_slots: id  2 | task 20692 | erased invalidated context checkpoint (pos_min = 34249, pos_max = 34966, n_swa = 128, size = 16.837 MiB)
slot update_slots: id  2 | task 20692 | erased invalidated context checkpoint (pos_min = 34477, pos_max = 35227, n_swa = 128, size = 17.610 MiB)
slot update_slots: id  2 | task 20692 | erased invalidated context checkpoint (pos_min = 35031, pos_max = 35486, n_swa = 128, size = 10.693 MiB)
slot update_slots: id  2 | task 20692 | erased invalidated context checkpoint (pos_min = 35031, pos_max = 35640, n_swa = 128, size = 14.304 MiB)
slot update_slots: id  2 | task 20692 | erased invalidated context checkpoint (pos_min = 35031, pos_max = 35905, n_swa = 128, size = 20.518 MiB)
slot update_slots: id  2 | task 20692 | erased invalidated context checkpoint (pos_min = 35187, pos_max = 36083, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 20692 | erased invalidated context checkpoint (pos_min = 35471, pos_max = 36367, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 20692 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 2048, batch.n_tokens = 2048, progress = 0.055892
slot update_slots: id  2 | task 20692 | n_tokens = 2048, memory_seq_rm [2048, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 4096, batch.n_tokens = 2048, progress = 0.111784
slot update_slots: id  2 | task 20692 | n_tokens = 4096, memory_seq_rm [4096, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 6144, batch.n_tokens = 2048, progress = 0.167676
slot update_slots: id  2 | task 20692 | n_tokens = 6144, memory_seq_rm [6144, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 8192, batch.n_tokens = 2048, progress = 0.223569
slot update_slots: id  2 | task 20692 | n_tokens = 8192, memory_seq_rm [8192, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 10240, batch.n_tokens = 2048, progress = 0.279461
slot update_slots: id  2 | task 20692 | n_tokens = 10240, memory_seq_rm [10240, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 12288, batch.n_tokens = 2048, progress = 0.335353
slot update_slots: id  2 | task 20692 | n_tokens = 12288, memory_seq_rm [12288, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 14336, batch.n_tokens = 2048, progress = 0.391245
slot update_slots: id  2 | task 20692 | n_tokens = 14336, memory_seq_rm [14336, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 16384, batch.n_tokens = 2048, progress = 0.447137
slot update_slots: id  2 | task 20692 | n_tokens = 16384, memory_seq_rm [16384, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 18432, batch.n_tokens = 2048, progress = 0.503029
slot update_slots: id  2 | task 20692 | n_tokens = 18432, memory_seq_rm [18432, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 20480, batch.n_tokens = 2048, progress = 0.558921
slot update_slots: id  2 | task 20692 | n_tokens = 20480, memory_seq_rm [20480, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 22528, batch.n_tokens = 2048, progress = 0.614814
slot update_slots: id  2 | task 20692 | n_tokens = 22528, memory_seq_rm [22528, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 24576, batch.n_tokens = 2048, progress = 0.670706
slot update_slots: id  2 | task 20692 | n_tokens = 24576, memory_seq_rm [24576, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 26624, batch.n_tokens = 2048, progress = 0.726598
slot update_slots: id  2 | task 20692 | n_tokens = 26624, memory_seq_rm [26624, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 28672, batch.n_tokens = 2048, progress = 0.782490
slot update_slots: id  2 | task 20692 | n_tokens = 28672, memory_seq_rm [28672, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 30720, batch.n_tokens = 2048, progress = 0.838382
slot update_slots: id  2 | task 20692 | n_tokens = 30720, memory_seq_rm [30720, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 32768, batch.n_tokens = 2048, progress = 0.894274
slot update_slots: id  2 | task 20692 | n_tokens = 32768, memory_seq_rm [32768, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 34816, batch.n_tokens = 2048, progress = 0.950166
slot update_slots: id  2 | task 20692 | n_tokens = 34816, memory_seq_rm [34816, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 36578, batch.n_tokens = 1762, progress = 0.998253
slot update_slots: id  2 | task 20692 | n_tokens = 36578, memory_seq_rm [36578, end)
slot update_slots: id  2 | task 20692 | prompt processing progress, n_tokens = 36642, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 20692 | prompt done, n_tokens = 36642, batch.n_tokens = 64
slot init_sampler: id  2 | task 20692 | init sampler, took 8.13 ms, tokens: text = 36642, total = 36642
slot update_slots: id  2 | task 20692 | created context checkpoint 1 of 8 (pos_min = 35681, pos_max = 36577, size = 21.034 MiB)
slot print_timing: id  2 | task 20692 | 
prompt eval time =   46758.99 ms / 36642 tokens (    1.28 ms per token,   783.64 tokens per second)
       eval time =   25379.52 ms /   903 tokens (   28.11 ms per token,    35.58 tokens per second)
      total time =   72138.51 ms / 37545 tokens
slot      release: id  2 | task 20692 | stop processing: n_tokens = 37544, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.978 (> 0.100 thold), f_keep = 0.976
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 21614 | processing task, is_child = 0
slot update_slots: id  2 | task 21614 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 37468
slot update_slots: id  2 | task 21614 | n_past = 36643, slot.prompt.tokens.size() = 37544, seq_id = 2, pos_min = 36647, n_swa = 128
slot update_slots: id  2 | task 21614 | restored context checkpoint (pos_min = 35681, pos_max = 36577, size = 21.034 MiB)
slot update_slots: id  2 | task 21614 | n_tokens = 36577, memory_seq_rm [36577, end)
slot update_slots: id  2 | task 21614 | prompt processing progress, n_tokens = 37404, batch.n_tokens = 827, progress = 0.998292
slot update_slots: id  2 | task 21614 | n_tokens = 37404, memory_seq_rm [37404, end)
slot update_slots: id  2 | task 21614 | prompt processing progress, n_tokens = 37468, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 21614 | prompt done, n_tokens = 37468, batch.n_tokens = 64
slot init_sampler: id  2 | task 21614 | init sampler, took 7.65 ms, tokens: text = 37468, total = 37468
slot update_slots: id  2 | task 21614 | created context checkpoint 2 of 8 (pos_min = 36507, pos_max = 37403, size = 21.034 MiB)
slot print_timing: id  2 | task 21614 | 
prompt eval time =    1848.99 ms /   891 tokens (    2.08 ms per token,   481.88 tokens per second)
       eval time =   29793.08 ms /  1006 tokens (   29.62 ms per token,    33.77 tokens per second)
      total time =   31642.07 ms /  1897 tokens
slot      release: id  2 | task 21614 | stop processing: n_tokens = 38473, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.974
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 22622 | processing task, is_child = 0
slot update_slots: id  2 | task 22622 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 37951
slot update_slots: id  2 | task 22622 | n_past = 37469, slot.prompt.tokens.size() = 38473, seq_id = 2, pos_min = 37576, n_swa = 128
slot update_slots: id  2 | task 22622 | restored context checkpoint (pos_min = 36507, pos_max = 37403, size = 21.034 MiB)
slot update_slots: id  2 | task 22622 | n_tokens = 37403, memory_seq_rm [37403, end)
slot update_slots: id  2 | task 22622 | prompt processing progress, n_tokens = 37887, batch.n_tokens = 484, progress = 0.998314
slot update_slots: id  2 | task 22622 | n_tokens = 37887, memory_seq_rm [37887, end)
slot update_slots: id  2 | task 22622 | prompt processing progress, n_tokens = 37951, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 22622 | prompt done, n_tokens = 37951, batch.n_tokens = 64
slot init_sampler: id  2 | task 22622 | init sampler, took 5.71 ms, tokens: text = 37951, total = 37951
slot update_slots: id  2 | task 22622 | created context checkpoint 3 of 8 (pos_min = 36990, pos_max = 37886, size = 21.034 MiB)
slot print_timing: id  2 | task 22622 | 
prompt eval time =    1269.37 ms /   548 tokens (    2.32 ms per token,   431.71 tokens per second)
       eval time =   32875.60 ms /  1104 tokens (   29.78 ms per token,    33.58 tokens per second)
      total time =   34144.97 ms /  1652 tokens
slot      release: id  2 | task 22622 | stop processing: n_tokens = 39054, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.973 (> 0.100 thold), f_keep = 0.972
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 23728 | processing task, is_child = 0
slot update_slots: id  2 | task 23728 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 38998
slot update_slots: id  2 | task 23728 | n_past = 37952, slot.prompt.tokens.size() = 39054, seq_id = 2, pos_min = 38157, n_swa = 128
slot update_slots: id  2 | task 23728 | restored context checkpoint (pos_min = 36990, pos_max = 37886, size = 21.034 MiB)
slot update_slots: id  2 | task 23728 | n_tokens = 37886, memory_seq_rm [37886, end)
slot update_slots: id  2 | task 23728 | prompt processing progress, n_tokens = 38934, batch.n_tokens = 1048, progress = 0.998359
slot update_slots: id  2 | task 23728 | n_tokens = 38934, memory_seq_rm [38934, end)
slot update_slots: id  2 | task 23728 | prompt processing progress, n_tokens = 38998, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 23728 | prompt done, n_tokens = 38998, batch.n_tokens = 64
slot init_sampler: id  2 | task 23728 | init sampler, took 6.54 ms, tokens: text = 38998, total = 38998
slot update_slots: id  2 | task 23728 | created context checkpoint 4 of 8 (pos_min = 38037, pos_max = 38933, size = 21.034 MiB)
slot print_timing: id  2 | task 23728 | 
prompt eval time =    2277.76 ms /  1112 tokens (    2.05 ms per token,   488.20 tokens per second)
       eval time =    1741.21 ms /    59 tokens (   29.51 ms per token,    33.88 tokens per second)
      total time =    4018.97 ms /  1171 tokens
slot      release: id  2 | task 23728 | stop processing: n_tokens = 39056, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.948 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 23789 | processing task, is_child = 0
slot update_slots: id  2 | task 23789 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 41123
slot update_slots: id  2 | task 23789 | n_tokens = 38998, memory_seq_rm [38998, end)
slot update_slots: id  2 | task 23789 | prompt processing progress, n_tokens = 41046, batch.n_tokens = 2048, progress = 0.998128
slot update_slots: id  2 | task 23789 | n_tokens = 41046, memory_seq_rm [41046, end)
slot update_slots: id  2 | task 23789 | prompt processing progress, n_tokens = 41059, batch.n_tokens = 13, progress = 0.998444
slot update_slots: id  2 | task 23789 | n_tokens = 41059, memory_seq_rm [41059, end)
slot update_slots: id  2 | task 23789 | prompt processing progress, n_tokens = 41123, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 23789 | prompt done, n_tokens = 41123, batch.n_tokens = 64
slot init_sampler: id  2 | task 23789 | init sampler, took 6.35 ms, tokens: text = 41123, total = 41123
slot update_slots: id  2 | task 23789 | created context checkpoint 5 of 8 (pos_min = 40162, pos_max = 41058, size = 21.034 MiB)
slot print_timing: id  2 | task 23789 | 
prompt eval time =    3942.25 ms /  2125 tokens (    1.86 ms per token,   539.03 tokens per second)
       eval time =   21332.08 ms /   706 tokens (   30.22 ms per token,    33.10 tokens per second)
      total time =   25274.33 ms /  2831 tokens
slot      release: id  2 | task 23789 | stop processing: n_tokens = 41828, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.983
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 24498 | processing task, is_child = 0
slot update_slots: id  2 | task 24498 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 41227
slot update_slots: id  2 | task 24498 | n_tokens = 41123, memory_seq_rm [41123, end)
slot update_slots: id  2 | task 24498 | prompt processing progress, n_tokens = 41163, batch.n_tokens = 40, progress = 0.998448
slot update_slots: id  2 | task 24498 | n_tokens = 41163, memory_seq_rm [41163, end)
slot update_slots: id  2 | task 24498 | prompt processing progress, n_tokens = 41227, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 24498 | prompt done, n_tokens = 41227, batch.n_tokens = 64
slot init_sampler: id  2 | task 24498 | init sampler, took 6.26 ms, tokens: text = 41227, total = 41227
slot update_slots: id  2 | task 24498 | created context checkpoint 6 of 8 (pos_min = 40931, pos_max = 41162, size = 5.440 MiB)
slot print_timing: id  2 | task 24498 | 
prompt eval time =     395.57 ms /   104 tokens (    3.80 ms per token,   262.91 tokens per second)
       eval time =   10121.87 ms /   348 tokens (   29.09 ms per token,    34.38 tokens per second)
      total time =   10517.44 ms /   452 tokens
slot      release: id  2 | task 24498 | stop processing: n_tokens = 41574, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.931 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 24848 | processing task, is_child = 0
slot update_slots: id  2 | task 24848 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 44262
slot update_slots: id  2 | task 24848 | n_tokens = 41227, memory_seq_rm [41227, end)
slot update_slots: id  2 | task 24848 | prompt processing progress, n_tokens = 43275, batch.n_tokens = 2048, progress = 0.977701
slot update_slots: id  2 | task 24848 | n_tokens = 43275, memory_seq_rm [43275, end)
slot update_slots: id  2 | task 24848 | prompt processing progress, n_tokens = 44198, batch.n_tokens = 923, progress = 0.998554
slot update_slots: id  2 | task 24848 | n_tokens = 44198, memory_seq_rm [44198, end)
slot update_slots: id  2 | task 24848 | prompt processing progress, n_tokens = 44262, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 24848 | prompt done, n_tokens = 44262, batch.n_tokens = 64
slot init_sampler: id  2 | task 24848 | init sampler, took 7.21 ms, tokens: text = 44262, total = 44262
slot update_slots: id  2 | task 24848 | created context checkpoint 7 of 8 (pos_min = 43301, pos_max = 44197, size = 21.034 MiB)
slot print_timing: id  2 | task 24848 | 
prompt eval time =    5149.09 ms /  3035 tokens (    1.70 ms per token,   589.43 tokens per second)
       eval time =   32536.98 ms /  1109 tokens (   29.34 ms per token,    34.08 tokens per second)
      total time =   37686.06 ms /  4144 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 24848 | stop processing: n_tokens = 45370, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.906 (> 0.100 thold), f_keep = 0.906
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 25960 | processing task, is_child = 0
slot update_slots: id  2 | task 25960 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 45412
slot update_slots: id  2 | task 25960 | n_past = 41123, slot.prompt.tokens.size() = 45370, seq_id = 2, pos_min = 44473, n_swa = 128
slot update_slots: id  2 | task 25960 | restored context checkpoint (pos_min = 40931, pos_max = 41162, size = 5.440 MiB)
slot update_slots: id  2 | task 25960 | erased invalidated context checkpoint (pos_min = 43301, pos_max = 44197, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 25960 | n_tokens = 41123, memory_seq_rm [41123, end)
slot update_slots: id  2 | task 25960 | prompt processing progress, n_tokens = 43171, batch.n_tokens = 2048, progress = 0.950652
slot update_slots: id  2 | task 25960 | n_tokens = 43171, memory_seq_rm [43171, end)
slot update_slots: id  2 | task 25960 | prompt processing progress, n_tokens = 45219, batch.n_tokens = 2048, progress = 0.995750
slot update_slots: id  2 | task 25960 | n_tokens = 45219, memory_seq_rm [45219, end)
slot update_slots: id  2 | task 25960 | prompt processing progress, n_tokens = 45348, batch.n_tokens = 129, progress = 0.998591
slot update_slots: id  2 | task 25960 | n_tokens = 45348, memory_seq_rm [45348, end)
slot update_slots: id  2 | task 25960 | prompt processing progress, n_tokens = 45412, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 25960 | prompt done, n_tokens = 45412, batch.n_tokens = 64
slot init_sampler: id  2 | task 25960 | init sampler, took 6.68 ms, tokens: text = 45412, total = 45412
slot update_slots: id  2 | task 25960 | created context checkpoint 7 of 8 (pos_min = 44451, pos_max = 45347, size = 21.034 MiB)
slot print_timing: id  2 | task 25960 | 
prompt eval time =    7912.76 ms /  4289 tokens (    1.84 ms per token,   542.04 tokens per second)
       eval time =   57094.26 ms /  1860 tokens (   30.70 ms per token,    32.58 tokens per second)
      total time =   65007.03 ms /  6149 tokens
slot      release: id  2 | task 25960 | stop processing: n_tokens = 47271, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.962 (> 0.100 thold), f_keep = 0.961
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27824 | processing task, is_child = 0
slot update_slots: id  2 | task 27824 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 47224
slot update_slots: id  2 | task 27824 | n_past = 45413, slot.prompt.tokens.size() = 47271, seq_id = 2, pos_min = 46374, n_swa = 128
slot update_slots: id  2 | task 27824 | restored context checkpoint (pos_min = 44451, pos_max = 45347, size = 21.034 MiB)
slot update_slots: id  2 | task 27824 | n_tokens = 45347, memory_seq_rm [45347, end)
slot update_slots: id  2 | task 27824 | prompt processing progress, n_tokens = 47160, batch.n_tokens = 1813, progress = 0.998645
slot update_slots: id  2 | task 27824 | n_tokens = 47160, memory_seq_rm [47160, end)
slot update_slots: id  2 | task 27824 | prompt processing progress, n_tokens = 47224, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 27824 | prompt done, n_tokens = 47224, batch.n_tokens = 64
slot init_sampler: id  2 | task 27824 | init sampler, took 7.20 ms, tokens: text = 47224, total = 47224
slot update_slots: id  2 | task 27824 | created context checkpoint 8 of 8 (pos_min = 46263, pos_max = 47159, size = 21.034 MiB)
slot print_timing: id  2 | task 27824 | 
prompt eval time =    3616.63 ms /  1877 tokens (    1.93 ms per token,   518.99 tokens per second)
       eval time =    2042.84 ms /    69 tokens (   29.61 ms per token,    33.78 tokens per second)
      total time =    5659.47 ms /  1946 tokens
slot      release: id  2 | task 27824 | stop processing: n_tokens = 47292, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.999
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 27895 | processing task, is_child = 0
slot update_slots: id  2 | task 27895 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 47482
slot update_slots: id  2 | task 27895 | n_tokens = 47224, memory_seq_rm [47224, end)
slot update_slots: id  2 | task 27895 | prompt processing progress, n_tokens = 47418, batch.n_tokens = 194, progress = 0.998652
slot update_slots: id  2 | task 27895 | n_tokens = 47418, memory_seq_rm [47418, end)
slot update_slots: id  2 | task 27895 | prompt processing progress, n_tokens = 47482, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 27895 | prompt done, n_tokens = 47482, batch.n_tokens = 64
slot init_sampler: id  2 | task 27895 | init sampler, took 7.18 ms, tokens: text = 47482, total = 47482
slot update_slots: id  2 | task 27895 | erasing old context checkpoint (pos_min = 35681, pos_max = 36577, size = 21.034 MiB)
slot update_slots: id  2 | task 27895 | created context checkpoint 8 of 8 (pos_min = 46572, pos_max = 47417, size = 19.838 MiB)
slot print_timing: id  2 | task 27895 | 
prompt eval time =     717.50 ms /   258 tokens (    2.78 ms per token,   359.58 tokens per second)
       eval time =   42381.24 ms /  1392 tokens (   30.45 ms per token,    32.84 tokens per second)
      total time =   43098.74 ms /  1650 tokens
slot      release: id  2 | task 27895 | stop processing: n_tokens = 48873, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.974 (> 0.100 thold), f_keep = 0.972
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 29289 | processing task, is_child = 0
slot update_slots: id  2 | task 29289 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 48747
slot update_slots: id  2 | task 29289 | n_past = 47482, slot.prompt.tokens.size() = 48873, seq_id = 2, pos_min = 47976, n_swa = 128
slot update_slots: id  2 | task 29289 | restored context checkpoint (pos_min = 46572, pos_max = 47417, size = 19.838 MiB)
slot update_slots: id  2 | task 29289 | n_tokens = 47417, memory_seq_rm [47417, end)
slot update_slots: id  2 | task 29289 | prompt processing progress, n_tokens = 48683, batch.n_tokens = 1266, progress = 0.998687
slot update_slots: id  2 | task 29289 | n_tokens = 48683, memory_seq_rm [48683, end)
slot update_slots: id  2 | task 29289 | prompt processing progress, n_tokens = 48747, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 29289 | prompt done, n_tokens = 48747, batch.n_tokens = 64
slot init_sampler: id  2 | task 29289 | init sampler, took 7.60 ms, tokens: text = 48747, total = 48747
slot update_slots: id  2 | task 29289 | erasing old context checkpoint (pos_min = 36507, pos_max = 37403, size = 21.034 MiB)
slot update_slots: id  2 | task 29289 | created context checkpoint 8 of 8 (pos_min = 47786, pos_max = 48682, size = 21.034 MiB)
slot print_timing: id  2 | task 29289 | 
prompt eval time =    2885.59 ms /  1330 tokens (    2.17 ms per token,   460.91 tokens per second)
       eval time =    2316.97 ms /    79 tokens (   29.33 ms per token,    34.10 tokens per second)
      total time =    5202.56 ms /  1409 tokens
slot      release: id  2 | task 29289 | stop processing: n_tokens = 48825, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.995 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 29370 | processing task, is_child = 0
slot update_slots: id  2 | task 29370 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 49005
slot update_slots: id  2 | task 29370 | n_tokens = 48747, memory_seq_rm [48747, end)
slot update_slots: id  2 | task 29370 | prompt processing progress, n_tokens = 48941, batch.n_tokens = 194, progress = 0.998694
slot update_slots: id  2 | task 29370 | n_tokens = 48941, memory_seq_rm [48941, end)
slot update_slots: id  2 | task 29370 | prompt processing progress, n_tokens = 49005, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 29370 | prompt done, n_tokens = 49005, batch.n_tokens = 64
slot init_sampler: id  2 | task 29370 | init sampler, took 7.61 ms, tokens: text = 49005, total = 49005
slot update_slots: id  2 | task 29370 | erasing old context checkpoint (pos_min = 36990, pos_max = 37886, size = 21.034 MiB)
slot update_slots: id  2 | task 29370 | created context checkpoint 8 of 8 (pos_min = 48044, pos_max = 48940, size = 21.034 MiB)
slot print_timing: id  2 | task 29370 | 
prompt eval time =     695.85 ms /   258 tokens (    2.70 ms per token,   370.77 tokens per second)
       eval time =   34368.50 ms /  1144 tokens (   30.04 ms per token,    33.29 tokens per second)
      total time =   35064.35 ms /  1402 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 29370 | stop processing: n_tokens = 50148, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.280 (> 0.100 thold), f_keep = 0.003
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 50148, total state size = 1196.952 MiB
srv          load:  - looking for better prompt, base f_keep = 0.003, sim = 0.280
srv        update:  - cache state: 3 prompts, 2238.232 MiB (limits: 8192.000 MiB, 64000 tokens, 284951 est)
srv        update:    - prompt 0x5b74dc0d5ef0:    1042 tokens, checkpoints:  1,    56.513 MiB
srv        update:    - prompt 0x5b74e55a53f0:   26665 tokens, checkpoints:  8,   833.285 MiB
srv        update:    - prompt 0x5b74f4b2e0a0:   50148 tokens, checkpoints:  8,  1348.434 MiB
srv  get_availabl: prompt cache update took 1454.32 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 30516 | processing task, is_child = 0
slot update_slots: id  2 | task 30516 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 461
slot update_slots: id  2 | task 30516 | n_past = 129, slot.prompt.tokens.size() = 50148, seq_id = 2, pos_min = 49251, n_swa = 128
slot update_slots: id  2 | task 30516 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  2 | task 30516 | erased invalidated context checkpoint (pos_min = 38037, pos_max = 38933, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 30516 | erased invalidated context checkpoint (pos_min = 40162, pos_max = 41058, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 30516 | erased invalidated context checkpoint (pos_min = 40931, pos_max = 41162, n_swa = 128, size = 5.440 MiB)
slot update_slots: id  2 | task 30516 | erased invalidated context checkpoint (pos_min = 44451, pos_max = 45347, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 30516 | erased invalidated context checkpoint (pos_min = 46263, pos_max = 47159, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 30516 | erased invalidated context checkpoint (pos_min = 46572, pos_max = 47417, n_swa = 128, size = 19.838 MiB)
slot update_slots: id  2 | task 30516 | erased invalidated context checkpoint (pos_min = 47786, pos_max = 48682, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 30516 | erased invalidated context checkpoint (pos_min = 48044, pos_max = 48940, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 30516 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 30516 | prompt processing progress, n_tokens = 397, batch.n_tokens = 397, progress = 0.861171
slot update_slots: id  2 | task 30516 | n_tokens = 397, memory_seq_rm [397, end)
slot update_slots: id  2 | task 30516 | prompt processing progress, n_tokens = 461, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 30516 | prompt done, n_tokens = 461, batch.n_tokens = 64
slot init_sampler: id  2 | task 30516 | init sampler, took 0.12 ms, tokens: text = 461, total = 461
slot update_slots: id  2 | task 30516 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 396, size = 9.310 MiB)
slot print_timing: id  2 | task 30516 | 
prompt eval time =     629.97 ms /   461 tokens (    1.37 ms per token,   731.78 tokens per second)
       eval time =     797.22 ms /    33 tokens (   24.16 ms per token,    41.39 tokens per second)
      total time =    1427.19 ms /   494 tokens
slot      release: id  2 | task 30516 | stop processing: n_tokens = 493, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.923
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 30551 | processing task, is_child = 0
slot update_slots: id  2 | task 30551 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 460
slot update_slots: id  2 | task 30551 | n_tokens = 455, memory_seq_rm [455, end)
slot update_slots: id  2 | task 30551 | prompt processing progress, n_tokens = 460, batch.n_tokens = 5, progress = 1.000000
slot update_slots: id  2 | task 30551 | prompt done, n_tokens = 460, batch.n_tokens = 5
slot init_sampler: id  2 | task 30551 | init sampler, took 0.12 ms, tokens: text = 460, total = 460
slot print_timing: id  2 | task 30551 | 
prompt eval time =      51.78 ms /     5 tokens (   10.36 ms per token,    96.57 tokens per second)
       eval time =    7925.46 ms /   313 tokens (   25.32 ms per token,    39.49 tokens per second)
      total time =    7977.24 ms /   318 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 30551 | stop processing: n_tokens = 772, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.871 (> 0.100 thold), f_keep = 0.596
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 30865 | processing task, is_child = 0
slot update_slots: id  2 | task 30865 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 528
slot update_slots: id  2 | task 30865 | n_tokens = 460, memory_seq_rm [460, end)
slot update_slots: id  2 | task 30865 | prompt processing progress, n_tokens = 464, batch.n_tokens = 4, progress = 0.878788
slot update_slots: id  2 | task 30865 | n_tokens = 464, memory_seq_rm [464, end)
slot update_slots: id  2 | task 30865 | prompt processing progress, n_tokens = 528, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 30865 | prompt done, n_tokens = 528, batch.n_tokens = 64
slot init_sampler: id  2 | task 30865 | init sampler, took 0.10 ms, tokens: text = 528, total = 528
slot update_slots: id  2 | task 30865 | created context checkpoint 2 of 8 (pos_min = 0, pos_max = 463, size = 10.881 MiB)
slot print_timing: id  2 | task 30865 | 
prompt eval time =     299.44 ms /    68 tokens (    4.40 ms per token,   227.09 tokens per second)
       eval time =    4246.18 ms /   167 tokens (   25.43 ms per token,    39.33 tokens per second)
      total time =    4545.62 ms /   235 tokens
slot      release: id  2 | task 30865 | stop processing: n_tokens = 694, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.496 (> 0.100 thold), f_keep = 0.761
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 31034 | processing task, is_child = 0
slot update_slots: id  2 | task 31034 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1064
slot update_slots: id  2 | task 31034 | n_tokens = 528, memory_seq_rm [528, end)
slot update_slots: id  2 | task 31034 | prompt processing progress, n_tokens = 1000, batch.n_tokens = 472, progress = 0.939850
slot update_slots: id  2 | task 31034 | n_tokens = 1000, memory_seq_rm [1000, end)
slot update_slots: id  2 | task 31034 | prompt processing progress, n_tokens = 1064, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 31034 | prompt done, n_tokens = 1064, batch.n_tokens = 64
slot init_sampler: id  2 | task 31034 | init sampler, took 0.22 ms, tokens: text = 1064, total = 1064
slot update_slots: id  2 | task 31034 | created context checkpoint 3 of 8 (pos_min = 103, pos_max = 999, size = 21.034 MiB)
slot print_timing: id  2 | task 31034 | 
prompt eval time =     620.74 ms /   536 tokens (    1.16 ms per token,   863.48 tokens per second)
       eval time =    4656.44 ms /   181 tokens (   25.73 ms per token,    38.87 tokens per second)
      total time =    5277.18 ms /   717 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 31034 | stop processing: n_tokens = 1244, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.764 (> 0.100 thold), f_keep = 0.855
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 31217 | processing task, is_child = 0
slot update_slots: id  2 | task 31217 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1392
slot update_slots: id  2 | task 31217 | n_tokens = 1064, memory_seq_rm [1064, end)
slot update_slots: id  2 | task 31217 | prompt processing progress, n_tokens = 1328, batch.n_tokens = 264, progress = 0.954023
slot update_slots: id  2 | task 31217 | n_tokens = 1328, memory_seq_rm [1328, end)
slot update_slots: id  2 | task 31217 | prompt processing progress, n_tokens = 1392, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 31217 | prompt done, n_tokens = 1392, batch.n_tokens = 64
slot init_sampler: id  2 | task 31217 | init sampler, took 0.33 ms, tokens: text = 1392, total = 1392
slot update_slots: id  2 | task 31217 | created context checkpoint 4 of 8 (pos_min = 431, pos_max = 1327, size = 21.034 MiB)
slot print_timing: id  2 | task 31217 | 
prompt eval time =     489.13 ms /   328 tokens (    1.49 ms per token,   670.58 tokens per second)
       eval time =    4788.81 ms /   190 tokens (   25.20 ms per token,    39.68 tokens per second)
      total time =    5277.94 ms /   518 tokens
slot      release: id  2 | task 31217 | stop processing: n_tokens = 1581, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.871 (> 0.100 thold), f_keep = 0.880
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 31409 | processing task, is_child = 0
slot update_slots: id  2 | task 31409 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1599
slot update_slots: id  2 | task 31409 | n_tokens = 1392, memory_seq_rm [1392, end)
slot update_slots: id  2 | task 31409 | prompt processing progress, n_tokens = 1535, batch.n_tokens = 143, progress = 0.959975
slot update_slots: id  2 | task 31409 | n_tokens = 1535, memory_seq_rm [1535, end)
slot update_slots: id  2 | task 31409 | prompt processing progress, n_tokens = 1599, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 31409 | prompt done, n_tokens = 1599, batch.n_tokens = 64
slot init_sampler: id  2 | task 31409 | init sampler, took 0.27 ms, tokens: text = 1599, total = 1599
slot update_slots: id  2 | task 31409 | created context checkpoint 5 of 8 (pos_min = 684, pos_max = 1534, size = 19.955 MiB)
slot print_timing: id  2 | task 31409 | 
prompt eval time =     397.94 ms /   207 tokens (    1.92 ms per token,   520.17 tokens per second)
       eval time =    5189.91 ms /   212 tokens (   24.48 ms per token,    40.85 tokens per second)
      total time =    5587.86 ms /   419 tokens
slot      release: id  2 | task 31409 | stop processing: n_tokens = 1810, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.887 (> 0.100 thold), f_keep = 0.251
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 1810, total state size = 63.477 MiB
srv          load:  - looking for better prompt, base f_keep = 0.251, sim = 0.887
srv        update:  - cache state: 4 prompts, 2383.922 MiB (limits: 8192.000 MiB, 64000 tokens, 273757 est)
srv        update:    - prompt 0x5b74dc0d5ef0:    1042 tokens, checkpoints:  1,    56.513 MiB
srv        update:    - prompt 0x5b74e55a53f0:   26665 tokens, checkpoints:  8,   833.285 MiB
srv        update:    - prompt 0x5b74f4b2e0a0:   50148 tokens, checkpoints:  8,  1348.434 MiB
srv        update:    - prompt 0x5b74e53f67f0:    1810 tokens, checkpoints:  5,   145.690 MiB
srv  get_availabl: prompt cache update took 82.77 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 31623 | processing task, is_child = 0
slot update_slots: id  2 | task 31623 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 513
slot update_slots: id  2 | task 31623 | n_past = 455, slot.prompt.tokens.size() = 1810, seq_id = 2, pos_min = 913, n_swa = 128
slot update_slots: id  2 | task 31623 | restored context checkpoint (pos_min = 103, pos_max = 999, size = 21.034 MiB)
slot update_slots: id  2 | task 31623 | erased invalidated context checkpoint (pos_min = 431, pos_max = 1327, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 31623 | erased invalidated context checkpoint (pos_min = 684, pos_max = 1534, n_swa = 128, size = 19.955 MiB)
slot update_slots: id  2 | task 31623 | n_tokens = 455, memory_seq_rm [455, end)
slot update_slots: id  2 | task 31623 | prompt processing progress, n_tokens = 513, batch.n_tokens = 58, progress = 1.000000
slot update_slots: id  2 | task 31623 | prompt done, n_tokens = 513, batch.n_tokens = 58
slot init_sampler: id  2 | task 31623 | init sampler, took 0.10 ms, tokens: text = 513, total = 513
slot print_timing: id  2 | task 31623 | 
prompt eval time =     402.88 ms /    58 tokens (    6.95 ms per token,   143.96 tokens per second)
       eval time =     856.01 ms /    36 tokens (   23.78 ms per token,    42.06 tokens per second)
      total time =    1258.89 ms /    94 tokens
slot      release: id  2 | task 31623 | stop processing: n_tokens = 548, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.491 (> 0.100 thold), f_keep = 0.936
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 31660 | processing task, is_child = 0
slot update_slots: id  2 | task 31660 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1045
slot update_slots: id  2 | task 31660 | n_tokens = 513, memory_seq_rm [513, end)
slot update_slots: id  2 | task 31660 | prompt processing progress, n_tokens = 981, batch.n_tokens = 468, progress = 0.938756
slot update_slots: id  2 | task 31660 | n_tokens = 981, memory_seq_rm [981, end)
slot update_slots: id  2 | task 31660 | prompt processing progress, n_tokens = 1045, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 31660 | prompt done, n_tokens = 1045, batch.n_tokens = 64
slot init_sampler: id  2 | task 31660 | init sampler, took 0.19 ms, tokens: text = 1045, total = 1045
slot print_timing: id  2 | task 31660 | 
prompt eval time =     612.76 ms /   532 tokens (    1.15 ms per token,   868.20 tokens per second)
       eval time =    2824.17 ms /   112 tokens (   25.22 ms per token,    39.66 tokens per second)
      total time =    3436.93 ms /   644 tokens
slot      release: id  2 | task 31660 | stop processing: n_tokens = 1156, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.388 (> 0.100 thold), f_keep = 0.904
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 31774 | processing task, is_child = 0
slot update_slots: id  2 | task 31774 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2691
slot update_slots: id  2 | task 31774 | n_tokens = 1045, memory_seq_rm [1045, end)
slot update_slots: id  2 | task 31774 | prompt processing progress, n_tokens = 2627, batch.n_tokens = 1582, progress = 0.976217
slot update_slots: id  2 | task 31774 | n_tokens = 2627, memory_seq_rm [2627, end)
slot update_slots: id  2 | task 31774 | prompt processing progress, n_tokens = 2691, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 31774 | prompt done, n_tokens = 2691, batch.n_tokens = 64
slot init_sampler: id  2 | task 31774 | init sampler, took 0.47 ms, tokens: text = 2691, total = 2691
slot update_slots: id  2 | task 31774 | created context checkpoint 4 of 8 (pos_min = 1730, pos_max = 2626, size = 21.034 MiB)
slot print_timing: id  2 | task 31774 | 
prompt eval time =    1871.93 ms /  1646 tokens (    1.14 ms per token,   879.31 tokens per second)
       eval time =    1037.68 ms /    40 tokens (   25.94 ms per token,    38.55 tokens per second)
      total time =    2909.61 ms /  1686 tokens
slot      release: id  2 | task 31774 | stop processing: n_tokens = 2730, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.738 (> 0.100 thold), f_keep = 0.986
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 31816 | processing task, is_child = 0
slot update_slots: id  2 | task 31816 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3648
slot update_slots: id  2 | task 31816 | n_tokens = 2691, memory_seq_rm [2691, end)
slot update_slots: id  2 | task 31816 | prompt processing progress, n_tokens = 3584, batch.n_tokens = 893, progress = 0.982456
slot update_slots: id  2 | task 31816 | n_tokens = 3584, memory_seq_rm [3584, end)
slot update_slots: id  2 | task 31816 | prompt processing progress, n_tokens = 3648, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 31816 | prompt done, n_tokens = 3648, batch.n_tokens = 64
slot init_sampler: id  2 | task 31816 | init sampler, took 0.82 ms, tokens: text = 3648, total = 3648
slot update_slots: id  2 | task 31816 | created context checkpoint 5 of 8 (pos_min = 2687, pos_max = 3583, size = 21.034 MiB)
slot print_timing: id  2 | task 31816 | 
prompt eval time =    1146.21 ms /   957 tokens (    1.20 ms per token,   834.93 tokens per second)
       eval time =    2007.87 ms /    75 tokens (   26.77 ms per token,    37.35 tokens per second)
      total time =    3154.07 ms /  1032 tokens
slot      release: id  2 | task 31816 | stop processing: n_tokens = 3722, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.981 (> 0.100 thold), f_keep = 0.980
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 31893 | processing task, is_child = 0
slot update_slots: id  2 | task 31893 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3719
slot update_slots: id  2 | task 31893 | n_tokens = 3648, memory_seq_rm [3648, end)
slot update_slots: id  2 | task 31893 | prompt processing progress, n_tokens = 3655, batch.n_tokens = 7, progress = 0.982791
slot update_slots: id  2 | task 31893 | n_tokens = 3655, memory_seq_rm [3655, end)
slot update_slots: id  2 | task 31893 | prompt processing progress, n_tokens = 3719, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 31893 | prompt done, n_tokens = 3719, batch.n_tokens = 64
slot init_sampler: id  2 | task 31893 | init sampler, took 0.80 ms, tokens: text = 3719, total = 3719
slot update_slots: id  2 | task 31893 | created context checkpoint 6 of 8 (pos_min = 2825, pos_max = 3654, size = 19.463 MiB)
slot print_timing: id  2 | task 31893 | 
prompt eval time =     253.03 ms /    71 tokens (    3.56 ms per token,   280.59 tokens per second)
       eval time =    1407.61 ms /    46 tokens (   30.60 ms per token,    32.68 tokens per second)
      total time =    1660.64 ms /   117 tokens
slot      release: id  2 | task 31893 | stop processing: n_tokens = 3764, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.530 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 31941 | processing task, is_child = 0
slot update_slots: id  2 | task 31941 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7017
slot update_slots: id  2 | task 31941 | n_tokens = 3719, memory_seq_rm [3719, end)
slot update_slots: id  2 | task 31941 | prompt processing progress, n_tokens = 5767, batch.n_tokens = 2048, progress = 0.821861
slot update_slots: id  2 | task 31941 | n_tokens = 5767, memory_seq_rm [5767, end)
slot update_slots: id  2 | task 31941 | prompt processing progress, n_tokens = 6953, batch.n_tokens = 1186, progress = 0.990879
slot update_slots: id  2 | task 31941 | n_tokens = 6953, memory_seq_rm [6953, end)
slot update_slots: id  2 | task 31941 | prompt processing progress, n_tokens = 7017, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 31941 | prompt done, n_tokens = 7017, batch.n_tokens = 64
slot init_sampler: id  2 | task 31941 | init sampler, took 1.26 ms, tokens: text = 7017, total = 7017
slot update_slots: id  2 | task 31941 | created context checkpoint 7 of 8 (pos_min = 6056, pos_max = 6952, size = 21.034 MiB)
slot print_timing: id  2 | task 31941 | 
prompt eval time =    4188.80 ms /  3298 tokens (    1.27 ms per token,   787.34 tokens per second)
       eval time =    2582.03 ms /    96 tokens (   26.90 ms per token,    37.18 tokens per second)
      total time =    6770.84 ms /  3394 tokens
slot      release: id  2 | task 31941 | stop processing: n_tokens = 7112, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32040 | processing task, is_child = 0
slot update_slots: id  2 | task 32040 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7123
slot update_slots: id  2 | task 32040 | n_tokens = 7017, memory_seq_rm [7017, end)
slot update_slots: id  2 | task 32040 | prompt processing progress, n_tokens = 7059, batch.n_tokens = 42, progress = 0.991015
slot update_slots: id  2 | task 32040 | n_tokens = 7059, memory_seq_rm [7059, end)
slot update_slots: id  2 | task 32040 | prompt processing progress, n_tokens = 7123, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 32040 | prompt done, n_tokens = 7123, batch.n_tokens = 64
slot init_sampler: id  2 | task 32040 | init sampler, took 1.21 ms, tokens: text = 7123, total = 7123
slot update_slots: id  2 | task 32040 | created context checkpoint 8 of 8 (pos_min = 6215, pos_max = 7058, size = 19.791 MiB)
slot print_timing: id  2 | task 32040 | 
prompt eval time =     335.22 ms /   106 tokens (    3.16 ms per token,   316.21 tokens per second)
       eval time =    2898.18 ms /   110 tokens (   26.35 ms per token,    37.95 tokens per second)
      total time =    3233.40 ms /   216 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 32040 | stop processing: n_tokens = 7232, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.752 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32152 | processing task, is_child = 0
slot update_slots: id  2 | task 32152 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 9466
slot update_slots: id  2 | task 32152 | n_tokens = 7123, memory_seq_rm [7123, end)
slot update_slots: id  2 | task 32152 | prompt processing progress, n_tokens = 9171, batch.n_tokens = 2048, progress = 0.968836
slot update_slots: id  2 | task 32152 | n_tokens = 9171, memory_seq_rm [9171, end)
slot update_slots: id  2 | task 32152 | prompt processing progress, n_tokens = 9402, batch.n_tokens = 231, progress = 0.993239
slot update_slots: id  2 | task 32152 | n_tokens = 9402, memory_seq_rm [9402, end)
slot update_slots: id  2 | task 32152 | prompt processing progress, n_tokens = 9466, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 32152 | prompt done, n_tokens = 9466, batch.n_tokens = 64
slot init_sampler: id  2 | task 32152 | init sampler, took 1.67 ms, tokens: text = 9466, total = 9466
slot update_slots: id  2 | task 32152 | erasing old context checkpoint (pos_min = 0, pos_max = 396, size = 9.310 MiB)
slot update_slots: id  2 | task 32152 | created context checkpoint 8 of 8 (pos_min = 8505, pos_max = 9401, size = 21.034 MiB)
slot print_timing: id  2 | task 32152 | 
prompt eval time =    2824.23 ms /  2343 tokens (    1.21 ms per token,   829.61 tokens per second)
       eval time =    1583.81 ms /    62 tokens (   25.55 ms per token,    39.15 tokens per second)
      total time =    4408.03 ms /  2405 tokens
slot      release: id  2 | task 32152 | stop processing: n_tokens = 9527, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32217 | processing task, is_child = 0
slot update_slots: id  2 | task 32217 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 9532
slot update_slots: id  2 | task 32217 | n_tokens = 9466, memory_seq_rm [9466, end)
slot update_slots: id  2 | task 32217 | prompt processing progress, n_tokens = 9468, batch.n_tokens = 2, progress = 0.993286
slot update_slots: id  2 | task 32217 | n_tokens = 9468, memory_seq_rm [9468, end)
slot update_slots: id  2 | task 32217 | prompt processing progress, n_tokens = 9532, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 32217 | prompt done, n_tokens = 9532, batch.n_tokens = 64
slot init_sampler: id  2 | task 32217 | init sampler, took 1.51 ms, tokens: text = 9532, total = 9532
slot update_slots: id  2 | task 32217 | erasing old context checkpoint (pos_min = 0, pos_max = 463, size = 10.881 MiB)
slot update_slots: id  2 | task 32217 | created context checkpoint 8 of 8 (pos_min = 8630, pos_max = 9467, size = 19.651 MiB)
slot print_timing: id  2 | task 32217 | 
prompt eval time =     220.49 ms /    66 tokens (    3.34 ms per token,   299.33 tokens per second)
       eval time =    1511.98 ms /    58 tokens (   26.07 ms per token,    38.36 tokens per second)
      total time =    1732.47 ms /   124 tokens
slot      release: id  2 | task 32217 | stop processing: n_tokens = 9589, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.891 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32277 | processing task, is_child = 0
slot update_slots: id  2 | task 32277 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10701
slot update_slots: id  2 | task 32277 | n_tokens = 9532, memory_seq_rm [9532, end)
slot update_slots: id  2 | task 32277 | prompt processing progress, n_tokens = 10637, batch.n_tokens = 1105, progress = 0.994019
slot update_slots: id  2 | task 32277 | n_tokens = 10637, memory_seq_rm [10637, end)
slot update_slots: id  2 | task 32277 | prompt processing progress, n_tokens = 10701, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 32277 | prompt done, n_tokens = 10701, batch.n_tokens = 64
slot init_sampler: id  2 | task 32277 | init sampler, took 1.65 ms, tokens: text = 10701, total = 10701
slot update_slots: id  2 | task 32277 | erasing old context checkpoint (pos_min = 103, pos_max = 999, size = 21.034 MiB)
slot update_slots: id  2 | task 32277 | created context checkpoint 8 of 8 (pos_min = 9740, pos_max = 10636, size = 21.034 MiB)
slot print_timing: id  2 | task 32277 | 
prompt eval time =    1521.82 ms /  1169 tokens (    1.30 ms per token,   768.16 tokens per second)
       eval time =    2605.97 ms /   103 tokens (   25.30 ms per token,    39.52 tokens per second)
      total time =    4127.79 ms /  1272 tokens
slot      release: id  2 | task 32277 | stop processing: n_tokens = 10803, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32382 | processing task, is_child = 0
slot update_slots: id  2 | task 32382 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10764
slot update_slots: id  2 | task 32382 | n_tokens = 10701, memory_seq_rm [10701, end)
slot update_slots: id  2 | task 32382 | prompt processing progress, n_tokens = 10764, batch.n_tokens = 63, progress = 1.000000
slot update_slots: id  2 | task 32382 | prompt done, n_tokens = 10764, batch.n_tokens = 63
slot init_sampler: id  2 | task 32382 | init sampler, took 1.95 ms, tokens: text = 10764, total = 10764
slot print_timing: id  2 | task 32382 | 
prompt eval time =     250.49 ms /    63 tokens (    3.98 ms per token,   251.51 tokens per second)
       eval time =    2494.26 ms /    99 tokens (   25.19 ms per token,    39.69 tokens per second)
      total time =    2744.75 ms /   162 tokens
slot      release: id  2 | task 32382 | stop processing: n_tokens = 10862, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.909 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32482 | processing task, is_child = 0
slot update_slots: id  2 | task 32482 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11841
slot update_slots: id  2 | task 32482 | n_tokens = 10764, memory_seq_rm [10764, end)
slot update_slots: id  2 | task 32482 | prompt processing progress, n_tokens = 11777, batch.n_tokens = 1013, progress = 0.994595
slot update_slots: id  2 | task 32482 | n_tokens = 11777, memory_seq_rm [11777, end)
slot update_slots: id  2 | task 32482 | prompt processing progress, n_tokens = 11841, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 32482 | prompt done, n_tokens = 11841, batch.n_tokens = 64
slot init_sampler: id  2 | task 32482 | init sampler, took 3.36 ms, tokens: text = 11841, total = 11841
slot update_slots: id  2 | task 32482 | erasing old context checkpoint (pos_min = 1730, pos_max = 2626, size = 21.034 MiB)
slot update_slots: id  2 | task 32482 | created context checkpoint 8 of 8 (pos_min = 10880, pos_max = 11776, size = 21.034 MiB)
slot print_timing: id  2 | task 32482 | 
prompt eval time =    1294.77 ms /  1077 tokens (    1.20 ms per token,   831.81 tokens per second)
       eval time =    2984.97 ms /   111 tokens (   26.89 ms per token,    37.19 tokens per second)
      total time =    4279.74 ms /  1188 tokens
slot      release: id  2 | task 32482 | stop processing: n_tokens = 11951, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32595 | processing task, is_child = 0
slot update_slots: id  2 | task 32595 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 11969
slot update_slots: id  2 | task 32595 | n_tokens = 11841, memory_seq_rm [11841, end)
slot update_slots: id  2 | task 32595 | prompt processing progress, n_tokens = 11905, batch.n_tokens = 64, progress = 0.994653
slot update_slots: id  2 | task 32595 | n_tokens = 11905, memory_seq_rm [11905, end)
slot update_slots: id  2 | task 32595 | prompt processing progress, n_tokens = 11969, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 32595 | prompt done, n_tokens = 11969, batch.n_tokens = 64
slot init_sampler: id  2 | task 32595 | init sampler, took 2.87 ms, tokens: text = 11969, total = 11969
slot update_slots: id  2 | task 32595 | erasing old context checkpoint (pos_min = 2687, pos_max = 3583, size = 21.034 MiB)
slot update_slots: id  2 | task 32595 | created context checkpoint 8 of 8 (pos_min = 11054, pos_max = 11904, size = 19.955 MiB)
slot print_timing: id  2 | task 32595 | 
prompt eval time =     379.94 ms /   128 tokens (    2.97 ms per token,   336.89 tokens per second)
       eval time =    2551.88 ms /    97 tokens (   26.31 ms per token,    38.01 tokens per second)
      total time =    2931.82 ms /   225 tokens
slot      release: id  2 | task 32595 | stop processing: n_tokens = 12065, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.844 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32694 | processing task, is_child = 0
slot update_slots: id  2 | task 32694 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 14174
slot update_slots: id  2 | task 32694 | n_tokens = 11969, memory_seq_rm [11969, end)
slot update_slots: id  2 | task 32694 | prompt processing progress, n_tokens = 14017, batch.n_tokens = 2048, progress = 0.988923
slot update_slots: id  2 | task 32694 | n_tokens = 14017, memory_seq_rm [14017, end)
slot update_slots: id  2 | task 32694 | prompt processing progress, n_tokens = 14110, batch.n_tokens = 93, progress = 0.995485
slot update_slots: id  2 | task 32694 | n_tokens = 14110, memory_seq_rm [14110, end)
slot update_slots: id  2 | task 32694 | prompt processing progress, n_tokens = 14174, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 32694 | prompt done, n_tokens = 14174, batch.n_tokens = 64
slot init_sampler: id  2 | task 32694 | init sampler, took 3.04 ms, tokens: text = 14174, total = 14174
slot update_slots: id  2 | task 32694 | erasing old context checkpoint (pos_min = 2825, pos_max = 3654, size = 19.463 MiB)
slot update_slots: id  2 | task 32694 | created context checkpoint 8 of 8 (pos_min = 13213, pos_max = 14109, size = 21.034 MiB)
slot print_timing: id  2 | task 32694 | 
prompt eval time =    2741.78 ms /  2205 tokens (    1.24 ms per token,   804.22 tokens per second)
       eval time =    2753.75 ms /   106 tokens (   25.98 ms per token,    38.49 tokens per second)
      total time =    5495.53 ms /  2311 tokens
slot      release: id  2 | task 32694 | stop processing: n_tokens = 14279, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.902 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 32803 | processing task, is_child = 0
slot update_slots: id  2 | task 32803 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15717
slot update_slots: id  2 | task 32803 | n_tokens = 14174, memory_seq_rm [14174, end)
slot update_slots: id  2 | task 32803 | prompt processing progress, n_tokens = 15653, batch.n_tokens = 1479, progress = 0.995928
slot update_slots: id  2 | task 32803 | n_tokens = 15653, memory_seq_rm [15653, end)
slot update_slots: id  2 | task 32803 | prompt processing progress, n_tokens = 15717, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 32803 | prompt done, n_tokens = 15717, batch.n_tokens = 64
slot init_sampler: id  2 | task 32803 | init sampler, took 3.15 ms, tokens: text = 15717, total = 15717
slot update_slots: id  2 | task 32803 | erasing old context checkpoint (pos_min = 6056, pos_max = 6952, size = 21.034 MiB)
slot update_slots: id  2 | task 32803 | created context checkpoint 8 of 8 (pos_min = 14756, pos_max = 15652, size = 21.034 MiB)
slot print_timing: id  2 | task 32803 | 
prompt eval time =    1968.49 ms /  1543 tokens (    1.28 ms per token,   783.85 tokens per second)
       eval time =   76210.79 ms /  2768 tokens (   27.53 ms per token,    36.32 tokens per second)
      total time =   78179.27 ms /  4311 tokens
slot      release: id  2 | task 32803 | stop processing: n_tokens = 18484, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.850
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 35573 | processing task, is_child = 0
slot update_slots: id  2 | task 35573 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15920
slot update_slots: id  2 | task 35573 | n_past = 15717, slot.prompt.tokens.size() = 18484, seq_id = 2, pos_min = 17587, n_swa = 128
slot update_slots: id  2 | task 35573 | restored context checkpoint (pos_min = 14756, pos_max = 15652, size = 21.034 MiB)
slot update_slots: id  2 | task 35573 | n_tokens = 15652, memory_seq_rm [15652, end)
slot update_slots: id  2 | task 35573 | prompt processing progress, n_tokens = 15856, batch.n_tokens = 204, progress = 0.995980
slot update_slots: id  2 | task 35573 | n_tokens = 15856, memory_seq_rm [15856, end)
slot update_slots: id  2 | task 35573 | prompt processing progress, n_tokens = 15920, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 35573 | prompt done, n_tokens = 15920, batch.n_tokens = 64
slot init_sampler: id  2 | task 35573 | init sampler, took 3.35 ms, tokens: text = 15920, total = 15920
slot update_slots: id  2 | task 35573 | erasing old context checkpoint (pos_min = 6215, pos_max = 7058, size = 19.791 MiB)
slot update_slots: id  2 | task 35573 | created context checkpoint 8 of 8 (pos_min = 14959, pos_max = 15855, size = 21.034 MiB)
slot print_timing: id  2 | task 35573 | 
prompt eval time =     754.20 ms /   268 tokens (    2.81 ms per token,   355.34 tokens per second)
       eval time =    1229.74 ms /    47 tokens (   26.16 ms per token,    38.22 tokens per second)
      total time =    1983.93 ms /   315 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 35573 | stop processing: n_tokens = 15966, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.996 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 35622 | processing task, is_child = 0
slot update_slots: id  2 | task 35622 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 15983
slot update_slots: id  2 | task 35622 | n_tokens = 15920, memory_seq_rm [15920, end)
slot update_slots: id  2 | task 35622 | prompt processing progress, n_tokens = 15983, batch.n_tokens = 63, progress = 1.000000
slot update_slots: id  2 | task 35622 | prompt done, n_tokens = 15983, batch.n_tokens = 63
slot init_sampler: id  2 | task 35622 | init sampler, took 3.49 ms, tokens: text = 15983, total = 15983
slot print_timing: id  2 | task 35622 | 
prompt eval time =     199.04 ms /    63 tokens (    3.16 ms per token,   316.52 tokens per second)
       eval time =    1260.37 ms /    39 tokens (   32.32 ms per token,    30.94 tokens per second)
      total time =    1459.41 ms /   102 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 35622 | stop processing: n_tokens = 16021, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 35662 | processing task, is_child = 0
slot update_slots: id  2 | task 35662 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16245
slot update_slots: id  2 | task 35662 | n_tokens = 15983, memory_seq_rm [15983, end)
slot update_slots: id  2 | task 35662 | prompt processing progress, n_tokens = 16181, batch.n_tokens = 198, progress = 0.996060
slot update_slots: id  2 | task 35662 | n_tokens = 16181, memory_seq_rm [16181, end)
slot update_slots: id  2 | task 35662 | prompt processing progress, n_tokens = 16245, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 35662 | prompt done, n_tokens = 16245, batch.n_tokens = 64
slot init_sampler: id  2 | task 35662 | init sampler, took 3.59 ms, tokens: text = 16245, total = 16245
slot update_slots: id  2 | task 35662 | erasing old context checkpoint (pos_min = 8505, pos_max = 9401, size = 21.034 MiB)
slot update_slots: id  2 | task 35662 | created context checkpoint 8 of 8 (pos_min = 15284, pos_max = 16180, size = 21.034 MiB)
slot print_timing: id  2 | task 35662 | 
prompt eval time =     550.44 ms /   262 tokens (    2.10 ms per token,   475.98 tokens per second)
       eval time =    5451.49 ms /   206 tokens (   26.46 ms per token,    37.79 tokens per second)
      total time =    6001.93 ms /   468 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 35662 | stop processing: n_tokens = 16450, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 35870 | processing task, is_child = 0
slot update_slots: id  2 | task 35870 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16462
slot update_slots: id  2 | task 35870 | n_tokens = 16245, memory_seq_rm [16245, end)
slot update_slots: id  2 | task 35870 | prompt processing progress, n_tokens = 16398, batch.n_tokens = 153, progress = 0.996112
slot update_slots: id  2 | task 35870 | n_tokens = 16398, memory_seq_rm [16398, end)
slot update_slots: id  2 | task 35870 | prompt processing progress, n_tokens = 16462, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 35870 | prompt done, n_tokens = 16462, batch.n_tokens = 64
slot init_sampler: id  2 | task 35870 | init sampler, took 3.58 ms, tokens: text = 16462, total = 16462
slot update_slots: id  2 | task 35870 | erasing old context checkpoint (pos_min = 8630, pos_max = 9467, size = 19.651 MiB)
slot update_slots: id  2 | task 35870 | created context checkpoint 8 of 8 (pos_min = 15553, pos_max = 16397, size = 19.815 MiB)
slot print_timing: id  2 | task 35870 | 
prompt eval time =     494.62 ms /   217 tokens (    2.28 ms per token,   438.72 tokens per second)
       eval time =    1427.73 ms /    52 tokens (   27.46 ms per token,    36.42 tokens per second)
      total time =    1922.36 ms /   269 tokens
slot      release: id  2 | task 35870 | stop processing: n_tokens = 16513, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.983 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 35924 | processing task, is_child = 0
slot update_slots: id  2 | task 35924 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16741
slot update_slots: id  2 | task 35924 | n_tokens = 16462, memory_seq_rm [16462, end)
slot update_slots: id  2 | task 35924 | prompt processing progress, n_tokens = 16677, batch.n_tokens = 215, progress = 0.996177
slot update_slots: id  2 | task 35924 | n_tokens = 16677, memory_seq_rm [16677, end)
slot update_slots: id  2 | task 35924 | prompt processing progress, n_tokens = 16741, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 35924 | prompt done, n_tokens = 16741, batch.n_tokens = 64
slot init_sampler: id  2 | task 35924 | init sampler, took 3.79 ms, tokens: text = 16741, total = 16741
slot update_slots: id  2 | task 35924 | erasing old context checkpoint (pos_min = 9740, pos_max = 10636, size = 21.034 MiB)
slot update_slots: id  2 | task 35924 | created context checkpoint 8 of 8 (pos_min = 15780, pos_max = 16676, size = 21.034 MiB)
slot print_timing: id  2 | task 35924 | 
prompt eval time =     545.88 ms /   279 tokens (    1.96 ms per token,   511.10 tokens per second)
       eval time =    5289.96 ms /   197 tokens (   26.85 ms per token,    37.24 tokens per second)
      total time =    5835.84 ms /   476 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 35924 | stop processing: n_tokens = 16937, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36123 | processing task, is_child = 0
slot update_slots: id  2 | task 36123 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 16957
slot update_slots: id  2 | task 36123 | n_tokens = 16741, memory_seq_rm [16741, end)
slot update_slots: id  2 | task 36123 | prompt processing progress, n_tokens = 16893, batch.n_tokens = 152, progress = 0.996226
slot update_slots: id  2 | task 36123 | n_tokens = 16893, memory_seq_rm [16893, end)
slot update_slots: id  2 | task 36123 | prompt processing progress, n_tokens = 16957, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36123 | prompt done, n_tokens = 16957, batch.n_tokens = 64
slot init_sampler: id  2 | task 36123 | init sampler, took 3.22 ms, tokens: text = 16957, total = 16957
slot update_slots: id  2 | task 36123 | erasing old context checkpoint (pos_min = 10880, pos_max = 11776, size = 21.034 MiB)
slot update_slots: id  2 | task 36123 | created context checkpoint 8 of 8 (pos_min = 16040, pos_max = 16892, size = 20.002 MiB)
slot print_timing: id  2 | task 36123 | 
prompt eval time =     502.96 ms /   216 tokens (    2.33 ms per token,   429.46 tokens per second)
       eval time =    1930.06 ms /    53 tokens (   36.42 ms per token,    27.46 tokens per second)
      total time =    2433.02 ms /   269 tokens
slot      release: id  2 | task 36123 | stop processing: n_tokens = 17009, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36178 | processing task, is_child = 0
slot update_slots: id  2 | task 36178 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 17312
slot update_slots: id  2 | task 36178 | n_tokens = 16957, memory_seq_rm [16957, end)
slot update_slots: id  2 | task 36178 | prompt processing progress, n_tokens = 17248, batch.n_tokens = 291, progress = 0.996303
slot update_slots: id  2 | task 36178 | n_tokens = 17248, memory_seq_rm [17248, end)
slot update_slots: id  2 | task 36178 | prompt processing progress, n_tokens = 17312, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36178 | prompt done, n_tokens = 17312, batch.n_tokens = 64
slot init_sampler: id  2 | task 36178 | init sampler, took 3.63 ms, tokens: text = 17312, total = 17312
slot update_slots: id  2 | task 36178 | erasing old context checkpoint (pos_min = 11054, pos_max = 11904, size = 19.955 MiB)
slot update_slots: id  2 | task 36178 | created context checkpoint 8 of 8 (pos_min = 16351, pos_max = 17247, size = 21.034 MiB)
slot print_timing: id  2 | task 36178 | 
prompt eval time =     630.32 ms /   355 tokens (    1.78 ms per token,   563.21 tokens per second)
       eval time =    1397.04 ms /    52 tokens (   26.87 ms per token,    37.22 tokens per second)
      total time =    2027.36 ms /   407 tokens
slot      release: id  2 | task 36178 | stop processing: n_tokens = 17363, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.975 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36232 | processing task, is_child = 0
slot update_slots: id  2 | task 36232 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 17761
slot update_slots: id  2 | task 36232 | n_tokens = 17312, memory_seq_rm [17312, end)
slot update_slots: id  2 | task 36232 | prompt processing progress, n_tokens = 17697, batch.n_tokens = 385, progress = 0.996397
slot update_slots: id  2 | task 36232 | n_tokens = 17697, memory_seq_rm [17697, end)
slot update_slots: id  2 | task 36232 | prompt processing progress, n_tokens = 17761, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36232 | prompt done, n_tokens = 17761, batch.n_tokens = 64
slot init_sampler: id  2 | task 36232 | init sampler, took 3.78 ms, tokens: text = 17761, total = 17761
slot update_slots: id  2 | task 36232 | erasing old context checkpoint (pos_min = 13213, pos_max = 14109, size = 21.034 MiB)
slot update_slots: id  2 | task 36232 | created context checkpoint 8 of 8 (pos_min = 16839, pos_max = 17696, size = 20.119 MiB)
slot print_timing: id  2 | task 36232 | 
prompt eval time =     695.29 ms /   449 tokens (    1.55 ms per token,   645.77 tokens per second)
       eval time =    1429.70 ms /    52 tokens (   27.49 ms per token,    36.37 tokens per second)
      total time =    2124.99 ms /   501 tokens
slot      release: id  2 | task 36232 | stop processing: n_tokens = 17812, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.966 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36286 | processing task, is_child = 0
slot update_slots: id  2 | task 36286 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 18385
slot update_slots: id  2 | task 36286 | n_tokens = 17761, memory_seq_rm [17761, end)
slot update_slots: id  2 | task 36286 | prompt processing progress, n_tokens = 18321, batch.n_tokens = 560, progress = 0.996519
slot update_slots: id  2 | task 36286 | n_tokens = 18321, memory_seq_rm [18321, end)
slot update_slots: id  2 | task 36286 | prompt processing progress, n_tokens = 18385, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36286 | prompt done, n_tokens = 18385, batch.n_tokens = 64
slot init_sampler: id  2 | task 36286 | init sampler, took 3.62 ms, tokens: text = 18385, total = 18385
slot update_slots: id  2 | task 36286 | erasing old context checkpoint (pos_min = 14756, pos_max = 15652, size = 21.034 MiB)
slot update_slots: id  2 | task 36286 | created context checkpoint 8 of 8 (pos_min = 17424, pos_max = 18320, size = 21.034 MiB)
slot print_timing: id  2 | task 36286 | 
prompt eval time =    1046.27 ms /   624 tokens (    1.68 ms per token,   596.41 tokens per second)
       eval time =    1778.68 ms /    66 tokens (   26.95 ms per token,    37.11 tokens per second)
      total time =    2824.95 ms /   690 tokens
slot      release: id  2 | task 36286 | stop processing: n_tokens = 18450, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36354 | processing task, is_child = 0
slot update_slots: id  2 | task 36354 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 18548
slot update_slots: id  2 | task 36354 | n_tokens = 18385, memory_seq_rm [18385, end)
slot update_slots: id  2 | task 36354 | prompt processing progress, n_tokens = 18484, batch.n_tokens = 99, progress = 0.996549
slot update_slots: id  2 | task 36354 | n_tokens = 18484, memory_seq_rm [18484, end)
slot update_slots: id  2 | task 36354 | prompt processing progress, n_tokens = 18548, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36354 | prompt done, n_tokens = 18548, batch.n_tokens = 64
slot init_sampler: id  2 | task 36354 | init sampler, took 3.73 ms, tokens: text = 18548, total = 18548
slot update_slots: id  2 | task 36354 | erasing old context checkpoint (pos_min = 14959, pos_max = 15855, size = 21.034 MiB)
slot update_slots: id  2 | task 36354 | created context checkpoint 8 of 8 (pos_min = 17587, pos_max = 18483, size = 21.034 MiB)
slot print_timing: id  2 | task 36354 | 
prompt eval time =     461.42 ms /   163 tokens (    2.83 ms per token,   353.26 tokens per second)
       eval time =    1431.26 ms /    50 tokens (   28.63 ms per token,    34.93 tokens per second)
      total time =    1892.67 ms /   213 tokens
slot      release: id  2 | task 36354 | stop processing: n_tokens = 18597, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.923 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36406 | processing task, is_child = 0
slot update_slots: id  2 | task 36406 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20091
slot update_slots: id  2 | task 36406 | n_tokens = 18548, memory_seq_rm [18548, end)
slot update_slots: id  2 | task 36406 | prompt processing progress, n_tokens = 20027, batch.n_tokens = 1479, progress = 0.996814
slot update_slots: id  2 | task 36406 | n_tokens = 20027, memory_seq_rm [20027, end)
slot update_slots: id  2 | task 36406 | prompt processing progress, n_tokens = 20091, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36406 | prompt done, n_tokens = 20091, batch.n_tokens = 64
slot init_sampler: id  2 | task 36406 | init sampler, took 4.10 ms, tokens: text = 20091, total = 20091
slot update_slots: id  2 | task 36406 | erasing old context checkpoint (pos_min = 15284, pos_max = 16180, size = 21.034 MiB)
slot update_slots: id  2 | task 36406 | created context checkpoint 8 of 8 (pos_min = 19130, pos_max = 20026, size = 21.034 MiB)
slot print_timing: id  2 | task 36406 | 
prompt eval time =    2123.08 ms /  1543 tokens (    1.38 ms per token,   726.77 tokens per second)
       eval time =    7208.11 ms /   267 tokens (   27.00 ms per token,    37.04 tokens per second)
      total time =    9331.19 ms /  1810 tokens
slot      release: id  2 | task 36406 | stop processing: n_tokens = 20357, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.987
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36675 | processing task, is_child = 0
slot update_slots: id  2 | task 36675 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20307
slot update_slots: id  2 | task 36675 | n_tokens = 20091, memory_seq_rm [20091, end)
slot update_slots: id  2 | task 36675 | prompt processing progress, n_tokens = 20243, batch.n_tokens = 152, progress = 0.996848
slot update_slots: id  2 | task 36675 | n_tokens = 20243, memory_seq_rm [20243, end)
slot update_slots: id  2 | task 36675 | prompt processing progress, n_tokens = 20307, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36675 | prompt done, n_tokens = 20307, batch.n_tokens = 64
slot init_sampler: id  2 | task 36675 | init sampler, took 4.19 ms, tokens: text = 20307, total = 20307
slot update_slots: id  2 | task 36675 | erasing old context checkpoint (pos_min = 15553, pos_max = 16397, size = 19.815 MiB)
slot update_slots: id  2 | task 36675 | created context checkpoint 8 of 8 (pos_min = 19460, pos_max = 20242, size = 18.361 MiB)
slot print_timing: id  2 | task 36675 | 
prompt eval time =     517.60 ms /   216 tokens (    2.40 ms per token,   417.31 tokens per second)
       eval time =    1283.17 ms /    46 tokens (   27.90 ms per token,    35.85 tokens per second)
      total time =    1800.77 ms /   262 tokens
slot      release: id  2 | task 36675 | stop processing: n_tokens = 20352, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36723 | processing task, is_child = 0
slot update_slots: id  2 | task 36723 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20370
slot update_slots: id  2 | task 36723 | n_tokens = 20307, memory_seq_rm [20307, end)
slot update_slots: id  2 | task 36723 | prompt processing progress, n_tokens = 20370, batch.n_tokens = 63, progress = 1.000000
slot update_slots: id  2 | task 36723 | prompt done, n_tokens = 20370, batch.n_tokens = 63
slot init_sampler: id  2 | task 36723 | init sampler, took 4.19 ms, tokens: text = 20370, total = 20370
slot print_timing: id  2 | task 36723 | 
prompt eval time =     210.45 ms /    63 tokens (    3.34 ms per token,   299.36 tokens per second)
       eval time =    1471.94 ms /    50 tokens (   29.44 ms per token,    33.97 tokens per second)
      total time =    1682.39 ms /   113 tokens
slot      release: id  2 | task 36723 | stop processing: n_tokens = 20419, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36774 | processing task, is_child = 0
slot update_slots: id  2 | task 36774 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20602
slot update_slots: id  2 | task 36774 | n_tokens = 20370, memory_seq_rm [20370, end)
slot update_slots: id  2 | task 36774 | prompt processing progress, n_tokens = 20538, batch.n_tokens = 168, progress = 0.996894
slot update_slots: id  2 | task 36774 | n_tokens = 20538, memory_seq_rm [20538, end)
slot update_slots: id  2 | task 36774 | prompt processing progress, n_tokens = 20602, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36774 | prompt done, n_tokens = 20602, batch.n_tokens = 64
slot init_sampler: id  2 | task 36774 | init sampler, took 4.38 ms, tokens: text = 20602, total = 20602
slot update_slots: id  2 | task 36774 | erasing old context checkpoint (pos_min = 15780, pos_max = 16676, size = 21.034 MiB)
slot update_slots: id  2 | task 36774 | created context checkpoint 8 of 8 (pos_min = 19641, pos_max = 20537, size = 21.034 MiB)
slot print_timing: id  2 | task 36774 | 
prompt eval time =     522.63 ms /   232 tokens (    2.25 ms per token,   443.91 tokens per second)
       eval time =    5352.47 ms /   183 tokens (   29.25 ms per token,    34.19 tokens per second)
      total time =    5875.09 ms /   415 tokens
slot      release: id  2 | task 36774 | stop processing: n_tokens = 20784, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 36959 | processing task, is_child = 0
slot update_slots: id  2 | task 36959 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 20818
slot update_slots: id  2 | task 36959 | n_tokens = 20602, memory_seq_rm [20602, end)
slot update_slots: id  2 | task 36959 | prompt processing progress, n_tokens = 20754, batch.n_tokens = 152, progress = 0.996926
slot update_slots: id  2 | task 36959 | n_tokens = 20754, memory_seq_rm [20754, end)
slot update_slots: id  2 | task 36959 | prompt processing progress, n_tokens = 20818, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 36959 | prompt done, n_tokens = 20818, batch.n_tokens = 64
slot init_sampler: id  2 | task 36959 | init sampler, took 4.40 ms, tokens: text = 20818, total = 20818
slot update_slots: id  2 | task 36959 | erasing old context checkpoint (pos_min = 16040, pos_max = 16892, size = 20.002 MiB)
slot update_slots: id  2 | task 36959 | created context checkpoint 8 of 8 (pos_min = 19887, pos_max = 20753, size = 20.331 MiB)
slot print_timing: id  2 | task 36959 | 
prompt eval time =     511.53 ms /   216 tokens (    2.37 ms per token,   422.26 tokens per second)
       eval time =    1584.45 ms /    58 tokens (   27.32 ms per token,    36.61 tokens per second)
      total time =    2095.98 ms /   274 tokens
slot      release: id  2 | task 36959 | stop processing: n_tokens = 20875, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 37019 | processing task, is_child = 0
slot update_slots: id  2 | task 37019 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21124
slot update_slots: id  2 | task 37019 | n_tokens = 20818, memory_seq_rm [20818, end)
slot update_slots: id  2 | task 37019 | prompt processing progress, n_tokens = 21060, batch.n_tokens = 242, progress = 0.996970
slot update_slots: id  2 | task 37019 | n_tokens = 21060, memory_seq_rm [21060, end)
slot update_slots: id  2 | task 37019 | prompt processing progress, n_tokens = 21124, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 37019 | prompt done, n_tokens = 21124, batch.n_tokens = 64
slot init_sampler: id  2 | task 37019 | init sampler, took 3.96 ms, tokens: text = 21124, total = 21124
slot update_slots: id  2 | task 37019 | erasing old context checkpoint (pos_min = 16351, pos_max = 17247, size = 21.034 MiB)
slot update_slots: id  2 | task 37019 | created context checkpoint 8 of 8 (pos_min = 20163, pos_max = 21059, size = 21.034 MiB)
slot print_timing: id  2 | task 37019 | 
prompt eval time =     617.84 ms /   306 tokens (    2.02 ms per token,   495.27 tokens per second)
       eval time =    1915.38 ms /    70 tokens (   27.36 ms per token,    36.55 tokens per second)
      total time =    2533.22 ms /   376 tokens
slot      release: id  2 | task 37019 | stop processing: n_tokens = 21193, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 37091 | processing task, is_child = 0
slot update_slots: id  2 | task 37091 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21386
slot update_slots: id  2 | task 37091 | n_tokens = 21124, memory_seq_rm [21124, end)
slot update_slots: id  2 | task 37091 | prompt processing progress, n_tokens = 21322, batch.n_tokens = 198, progress = 0.997007
slot update_slots: id  2 | task 37091 | n_tokens = 21322, memory_seq_rm [21322, end)
slot update_slots: id  2 | task 37091 | prompt processing progress, n_tokens = 21386, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 37091 | prompt done, n_tokens = 21386, batch.n_tokens = 64
slot init_sampler: id  2 | task 37091 | init sampler, took 3.95 ms, tokens: text = 21386, total = 21386
slot update_slots: id  2 | task 37091 | erasing old context checkpoint (pos_min = 16839, pos_max = 17696, size = 20.119 MiB)
slot update_slots: id  2 | task 37091 | created context checkpoint 8 of 8 (pos_min = 20425, pos_max = 21321, size = 21.034 MiB)
slot print_timing: id  2 | task 37091 | 
prompt eval time =     561.12 ms /   262 tokens (    2.14 ms per token,   466.92 tokens per second)
       eval time =    1680.07 ms /    54 tokens (   31.11 ms per token,    32.14 tokens per second)
      total time =    2241.19 ms /   316 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 37091 | stop processing: n_tokens = 21439, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 37147 | processing task, is_child = 0
slot update_slots: id  2 | task 37147 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21648
slot update_slots: id  2 | task 37147 | n_tokens = 21386, memory_seq_rm [21386, end)
slot update_slots: id  2 | task 37147 | prompt processing progress, n_tokens = 21584, batch.n_tokens = 198, progress = 0.997044
slot update_slots: id  2 | task 37147 | n_tokens = 21584, memory_seq_rm [21584, end)
slot update_slots: id  2 | task 37147 | prompt processing progress, n_tokens = 21648, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 37147 | prompt done, n_tokens = 21648, batch.n_tokens = 64
slot init_sampler: id  2 | task 37147 | init sampler, took 4.71 ms, tokens: text = 21648, total = 21648
slot update_slots: id  2 | task 37147 | erasing old context checkpoint (pos_min = 17424, pos_max = 18320, size = 21.034 MiB)
slot update_slots: id  2 | task 37147 | created context checkpoint 8 of 8 (pos_min = 20687, pos_max = 21583, size = 21.034 MiB)
slot print_timing: id  2 | task 37147 | 
prompt eval time =     567.37 ms /   262 tokens (    2.17 ms per token,   461.78 tokens per second)
       eval time =    5972.03 ms /   220 tokens (   27.15 ms per token,    36.84 tokens per second)
      total time =    6539.40 ms /   482 tokens
slot      release: id  2 | task 37147 | stop processing: n_tokens = 21867, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.990
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 37369 | processing task, is_child = 0
slot update_slots: id  2 | task 37369 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 21864
slot update_slots: id  2 | task 37369 | n_tokens = 21648, memory_seq_rm [21648, end)
slot update_slots: id  2 | task 37369 | prompt processing progress, n_tokens = 21800, batch.n_tokens = 152, progress = 0.997073
slot update_slots: id  2 | task 37369 | n_tokens = 21800, memory_seq_rm [21800, end)
slot update_slots: id  2 | task 37369 | prompt processing progress, n_tokens = 21864, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 37369 | prompt done, n_tokens = 21864, batch.n_tokens = 64
slot init_sampler: id  2 | task 37369 | init sampler, took 4.31 ms, tokens: text = 21864, total = 21864
slot update_slots: id  2 | task 37369 | erasing old context checkpoint (pos_min = 17587, pos_max = 18483, size = 21.034 MiB)
slot update_slots: id  2 | task 37369 | created context checkpoint 8 of 8 (pos_min = 21052, pos_max = 21799, size = 17.540 MiB)
slot print_timing: id  2 | task 37369 | 
prompt eval time =     517.33 ms /   216 tokens (    2.40 ms per token,   417.53 tokens per second)
       eval time =    1242.45 ms /    45 tokens (   27.61 ms per token,    36.22 tokens per second)
      total time =    1759.79 ms /   261 tokens
slot      release: id  2 | task 37369 | stop processing: n_tokens = 21908, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 37416 | processing task, is_child = 0
slot update_slots: id  2 | task 37416 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 22170
slot update_slots: id  2 | task 37416 | n_tokens = 21864, memory_seq_rm [21864, end)
slot update_slots: id  2 | task 37416 | prompt processing progress, n_tokens = 22106, batch.n_tokens = 242, progress = 0.997113
slot update_slots: id  2 | task 37416 | n_tokens = 22106, memory_seq_rm [22106, end)
slot update_slots: id  2 | task 37416 | prompt processing progress, n_tokens = 22170, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 37416 | prompt done, n_tokens = 22170, batch.n_tokens = 64
slot init_sampler: id  2 | task 37416 | init sampler, took 12.59 ms, tokens: text = 22170, total = 22170
slot update_slots: id  2 | task 37416 | erasing old context checkpoint (pos_min = 19130, pos_max = 20026, size = 21.034 MiB)
slot update_slots: id  2 | task 37416 | created context checkpoint 8 of 8 (pos_min = 21358, pos_max = 22105, size = 17.540 MiB)
slot print_timing: id  2 | task 37416 | 
prompt eval time =     622.01 ms /   306 tokens (    2.03 ms per token,   491.95 tokens per second)
       eval time =    1434.76 ms /    53 tokens (   27.07 ms per token,    36.94 tokens per second)
      total time =    2056.77 ms /   359 tokens
slot      release: id  2 | task 37416 | stop processing: n_tokens = 22222, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 37471 | processing task, is_child = 0
slot update_slots: id  2 | task 37471 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 22449
slot update_slots: id  2 | task 37471 | n_tokens = 22170, memory_seq_rm [22170, end)
slot update_slots: id  2 | task 37471 | prompt processing progress, n_tokens = 22385, batch.n_tokens = 215, progress = 0.997149
slot update_slots: id  2 | task 37471 | n_tokens = 22385, memory_seq_rm [22385, end)
slot update_slots: id  2 | task 37471 | prompt processing progress, n_tokens = 22449, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 37471 | prompt done, n_tokens = 22449, batch.n_tokens = 64
slot init_sampler: id  2 | task 37471 | init sampler, took 4.84 ms, tokens: text = 22449, total = 22449
slot update_slots: id  2 | task 37471 | erasing old context checkpoint (pos_min = 19460, pos_max = 20242, size = 18.361 MiB)
slot update_slots: id  2 | task 37471 | created context checkpoint 8 of 8 (pos_min = 21637, pos_max = 22384, size = 17.540 MiB)
slot print_timing: id  2 | task 37471 | 
prompt eval time =     582.93 ms /   279 tokens (    2.09 ms per token,   478.61 tokens per second)
       eval time =    2044.99 ms /    71 tokens (   28.80 ms per token,    34.72 tokens per second)
      total time =    2627.93 ms /   350 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 37471 | stop processing: n_tokens = 22519, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 37544 | processing task, is_child = 0
slot update_slots: id  2 | task 37544 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 22804
slot update_slots: id  2 | task 37544 | n_tokens = 22449, memory_seq_rm [22449, end)
slot update_slots: id  2 | task 37544 | prompt processing progress, n_tokens = 22740, batch.n_tokens = 291, progress = 0.997193
slot update_slots: id  2 | task 37544 | n_tokens = 22740, memory_seq_rm [22740, end)
slot update_slots: id  2 | task 37544 | prompt processing progress, n_tokens = 22804, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 37544 | prompt done, n_tokens = 22804, batch.n_tokens = 64
slot init_sampler: id  2 | task 37544 | init sampler, took 4.50 ms, tokens: text = 22804, total = 22804
slot update_slots: id  2 | task 37544 | erasing old context checkpoint (pos_min = 19641, pos_max = 20537, size = 21.034 MiB)
slot update_slots: id  2 | task 37544 | created context checkpoint 8 of 8 (pos_min = 21843, pos_max = 22739, size = 21.034 MiB)
slot print_timing: id  2 | task 37544 | 
prompt eval time =     646.07 ms /   355 tokens (    1.82 ms per token,   549.48 tokens per second)
       eval time =    1793.34 ms /    65 tokens (   27.59 ms per token,    36.25 tokens per second)
      total time =    2439.41 ms /   420 tokens
slot      release: id  2 | task 37544 | stop processing: n_tokens = 22868, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 37611 | processing task, is_child = 0
slot update_slots: id  2 | task 37611 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23066
slot update_slots: id  2 | task 37611 | n_tokens = 22804, memory_seq_rm [22804, end)
slot update_slots: id  2 | task 37611 | prompt processing progress, n_tokens = 23002, batch.n_tokens = 198, progress = 0.997225
slot update_slots: id  2 | task 37611 | n_tokens = 23002, memory_seq_rm [23002, end)
slot update_slots: id  2 | task 37611 | prompt processing progress, n_tokens = 23066, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 37611 | prompt done, n_tokens = 23066, batch.n_tokens = 64
slot init_sampler: id  2 | task 37611 | init sampler, took 4.85 ms, tokens: text = 23066, total = 23066
slot update_slots: id  2 | task 37611 | erasing old context checkpoint (pos_min = 19887, pos_max = 20753, size = 20.331 MiB)
slot update_slots: id  2 | task 37611 | created context checkpoint 8 of 8 (pos_min = 22105, pos_max = 23001, size = 21.034 MiB)
slot print_timing: id  2 | task 37611 | 
prompt eval time =     557.66 ms /   262 tokens (    2.13 ms per token,   469.82 tokens per second)
       eval time =    1389.08 ms /    51 tokens (   27.24 ms per token,    36.71 tokens per second)
      total time =    1946.74 ms /   313 tokens
slot      release: id  2 | task 37611 | stop processing: n_tokens = 23116, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 37664 | processing task, is_child = 0
slot update_slots: id  2 | task 37664 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23421
slot update_slots: id  2 | task 37664 | n_tokens = 23066, memory_seq_rm [23066, end)
slot update_slots: id  2 | task 37664 | prompt processing progress, n_tokens = 23357, batch.n_tokens = 291, progress = 0.997267
slot update_slots: id  2 | task 37664 | n_tokens = 23357, memory_seq_rm [23357, end)
slot update_slots: id  2 | task 37664 | prompt processing progress, n_tokens = 23421, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 37664 | prompt done, n_tokens = 23421, batch.n_tokens = 64
slot init_sampler: id  2 | task 37664 | init sampler, took 4.78 ms, tokens: text = 23421, total = 23421
slot update_slots: id  2 | task 37664 | erasing old context checkpoint (pos_min = 20163, pos_max = 21059, size = 21.034 MiB)
slot update_slots: id  2 | task 37664 | created context checkpoint 8 of 8 (pos_min = 22460, pos_max = 23356, size = 21.034 MiB)
slot print_timing: id  2 | task 37664 | 
prompt eval time =     647.42 ms /   355 tokens (    1.82 ms per token,   548.33 tokens per second)
       eval time =    1480.63 ms /    54 tokens (   27.42 ms per token,    36.47 tokens per second)
      total time =    2128.05 ms /   409 tokens
slot      release: id  2 | task 37664 | stop processing: n_tokens = 23474, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 37720 | processing task, is_child = 0
slot update_slots: id  2 | task 37720 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23776
slot update_slots: id  2 | task 37720 | n_tokens = 23421, memory_seq_rm [23421, end)
slot update_slots: id  2 | task 37720 | prompt processing progress, n_tokens = 23712, batch.n_tokens = 291, progress = 0.997308
slot update_slots: id  2 | task 37720 | n_tokens = 23712, memory_seq_rm [23712, end)
slot update_slots: id  2 | task 37720 | prompt processing progress, n_tokens = 23776, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 37720 | prompt done, n_tokens = 23776, batch.n_tokens = 64
slot init_sampler: id  2 | task 37720 | init sampler, took 4.61 ms, tokens: text = 23776, total = 23776
slot update_slots: id  2 | task 37720 | erasing old context checkpoint (pos_min = 20425, pos_max = 21321, size = 21.034 MiB)
slot update_slots: id  2 | task 37720 | created context checkpoint 8 of 8 (pos_min = 22836, pos_max = 23711, size = 20.542 MiB)
slot print_timing: id  2 | task 37720 | 
prompt eval time =     652.01 ms /   355 tokens (    1.84 ms per token,   544.47 tokens per second)
       eval time =    4588.37 ms /   162 tokens (   28.32 ms per token,    35.31 tokens per second)
      total time =    5240.38 ms /   517 tokens
slot      release: id  2 | task 37720 | stop processing: n_tokens = 23937, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.997 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 37884 | processing task, is_child = 0
slot update_slots: id  2 | task 37884 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 23858
slot update_slots: id  2 | task 37884 | n_tokens = 23776, memory_seq_rm [23776, end)
slot update_slots: id  2 | task 37884 | prompt processing progress, n_tokens = 23794, batch.n_tokens = 18, progress = 0.997317
slot update_slots: id  2 | task 37884 | n_tokens = 23794, memory_seq_rm [23794, end)
slot update_slots: id  2 | task 37884 | prompt processing progress, n_tokens = 23858, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 37884 | prompt done, n_tokens = 23858, batch.n_tokens = 64
slot init_sampler: id  2 | task 37884 | init sampler, took 5.08 ms, tokens: text = 23858, total = 23858
slot update_slots: id  2 | task 37884 | erasing old context checkpoint (pos_min = 20687, pos_max = 21583, size = 21.034 MiB)
slot update_slots: id  2 | task 37884 | created context checkpoint 8 of 8 (pos_min = 23061, pos_max = 23793, size = 17.188 MiB)
slot print_timing: id  2 | task 37884 | 
prompt eval time =     395.81 ms /    82 tokens (    4.83 ms per token,   207.17 tokens per second)
       eval time =    5533.73 ms /   204 tokens (   27.13 ms per token,    36.86 tokens per second)
      total time =    5929.53 ms /   286 tokens
slot      release: id  2 | task 37884 | stop processing: n_tokens = 24061, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 38090 | processing task, is_child = 0
slot update_slots: id  2 | task 38090 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 24076
slot update_slots: id  2 | task 38090 | n_tokens = 23858, memory_seq_rm [23858, end)
slot update_slots: id  2 | task 38090 | prompt processing progress, n_tokens = 24012, batch.n_tokens = 154, progress = 0.997342
slot update_slots: id  2 | task 38090 | n_tokens = 24012, memory_seq_rm [24012, end)
slot update_slots: id  2 | task 38090 | prompt processing progress, n_tokens = 24076, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 38090 | prompt done, n_tokens = 24076, batch.n_tokens = 64
slot init_sampler: id  2 | task 38090 | init sampler, took 5.28 ms, tokens: text = 24076, total = 24076
slot update_slots: id  2 | task 38090 | erasing old context checkpoint (pos_min = 21052, pos_max = 21799, size = 17.540 MiB)
slot update_slots: id  2 | task 38090 | created context checkpoint 8 of 8 (pos_min = 23185, pos_max = 24011, size = 19.393 MiB)
slot print_timing: id  2 | task 38090 | 
prompt eval time =     530.21 ms /   218 tokens (    2.43 ms per token,   411.16 tokens per second)
       eval time =    1497.95 ms /    54 tokens (   27.74 ms per token,    36.05 tokens per second)
      total time =    2028.16 ms /   272 tokens
slot      release: id  2 | task 38090 | stop processing: n_tokens = 24129, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 38146 | processing task, is_child = 0
slot update_slots: id  2 | task 38146 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 24338
slot update_slots: id  2 | task 38146 | n_tokens = 24076, memory_seq_rm [24076, end)
slot update_slots: id  2 | task 38146 | prompt processing progress, n_tokens = 24274, batch.n_tokens = 198, progress = 0.997370
slot update_slots: id  2 | task 38146 | n_tokens = 24274, memory_seq_rm [24274, end)
slot update_slots: id  2 | task 38146 | prompt processing progress, n_tokens = 24338, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 38146 | prompt done, n_tokens = 24338, batch.n_tokens = 64
slot init_sampler: id  2 | task 38146 | init sampler, took 6.66 ms, tokens: text = 24338, total = 24338
slot update_slots: id  2 | task 38146 | erasing old context checkpoint (pos_min = 21358, pos_max = 22105, size = 17.540 MiB)
slot update_slots: id  2 | task 38146 | created context checkpoint 8 of 8 (pos_min = 23398, pos_max = 24273, size = 20.542 MiB)
slot print_timing: id  2 | task 38146 | 
prompt eval time =     566.40 ms /   262 tokens (    2.16 ms per token,   462.57 tokens per second)
       eval time =   72269.88 ms /  2602 tokens (   27.77 ms per token,    36.00 tokens per second)
      total time =   72836.28 ms /  2864 tokens
slot      release: id  2 | task 38146 | stop processing: n_tokens = 26939, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.903
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 40750 | processing task, is_child = 0
slot update_slots: id  2 | task 40750 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 24661
slot update_slots: id  2 | task 40750 | n_past = 24338, slot.prompt.tokens.size() = 26939, seq_id = 2, pos_min = 26042, n_swa = 128
slot update_slots: id  2 | task 40750 | restored context checkpoint (pos_min = 23398, pos_max = 24273, size = 20.542 MiB)
slot update_slots: id  2 | task 40750 | n_tokens = 24273, memory_seq_rm [24273, end)
slot update_slots: id  2 | task 40750 | prompt processing progress, n_tokens = 24597, batch.n_tokens = 324, progress = 0.997405
slot update_slots: id  2 | task 40750 | n_tokens = 24597, memory_seq_rm [24597, end)
slot update_slots: id  2 | task 40750 | prompt processing progress, n_tokens = 24661, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 40750 | prompt done, n_tokens = 24661, batch.n_tokens = 64
slot init_sampler: id  2 | task 40750 | init sampler, took 7.03 ms, tokens: text = 24661, total = 24661
slot update_slots: id  2 | task 40750 | erasing old context checkpoint (pos_min = 21637, pos_max = 22384, size = 17.540 MiB)
slot update_slots: id  2 | task 40750 | created context checkpoint 8 of 8 (pos_min = 23700, pos_max = 24596, size = 21.034 MiB)
slot print_timing: id  2 | task 40750 | 
prompt eval time =     845.24 ms /   388 tokens (    2.18 ms per token,   459.04 tokens per second)
       eval time =    5715.19 ms /   209 tokens (   27.35 ms per token,    36.57 tokens per second)
      total time =    6560.43 ms /   597 tokens
slot      release: id  2 | task 40750 | stop processing: n_tokens = 24869, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 40961 | processing task, is_child = 0
slot update_slots: id  2 | task 40961 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 24816
slot update_slots: id  2 | task 40961 | n_tokens = 24661, memory_seq_rm [24661, end)
slot update_slots: id  2 | task 40961 | prompt processing progress, n_tokens = 24752, batch.n_tokens = 91, progress = 0.997421
slot update_slots: id  2 | task 40961 | n_tokens = 24752, memory_seq_rm [24752, end)
slot update_slots: id  2 | task 40961 | prompt processing progress, n_tokens = 24816, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 40961 | prompt done, n_tokens = 24816, batch.n_tokens = 64
slot init_sampler: id  2 | task 40961 | init sampler, took 3.81 ms, tokens: text = 24816, total = 24816
slot update_slots: id  2 | task 40961 | erasing old context checkpoint (pos_min = 21843, pos_max = 22739, size = 21.034 MiB)
slot update_slots: id  2 | task 40961 | created context checkpoint 8 of 8 (pos_min = 23972, pos_max = 24751, size = 18.290 MiB)
slot print_timing: id  2 | task 40961 | 
prompt eval time =     470.65 ms /   155 tokens (    3.04 ms per token,   329.33 tokens per second)
       eval time =    1547.60 ms /    56 tokens (   27.64 ms per token,    36.19 tokens per second)
      total time =    2018.25 ms /   211 tokens
slot      release: id  2 | task 40961 | stop processing: n_tokens = 24871, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 41019 | processing task, is_child = 0
slot update_slots: id  2 | task 41019 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 25171
slot update_slots: id  2 | task 41019 | n_tokens = 24816, memory_seq_rm [24816, end)
slot update_slots: id  2 | task 41019 | prompt processing progress, n_tokens = 25107, batch.n_tokens = 291, progress = 0.997457
slot update_slots: id  2 | task 41019 | n_tokens = 25107, memory_seq_rm [25107, end)
slot update_slots: id  2 | task 41019 | prompt processing progress, n_tokens = 25171, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 41019 | prompt done, n_tokens = 25171, batch.n_tokens = 64
slot init_sampler: id  2 | task 41019 | init sampler, took 4.05 ms, tokens: text = 25171, total = 25171
slot update_slots: id  2 | task 41019 | erasing old context checkpoint (pos_min = 22105, pos_max = 23001, size = 21.034 MiB)
slot update_slots: id  2 | task 41019 | created context checkpoint 8 of 8 (pos_min = 24210, pos_max = 25106, size = 21.034 MiB)
slot print_timing: id  2 | task 41019 | 
prompt eval time =     651.64 ms /   355 tokens (    1.84 ms per token,   544.78 tokens per second)
       eval time =    1667.64 ms /    61 tokens (   27.34 ms per token,    36.58 tokens per second)
      total time =    2319.28 ms /   416 tokens
slot      release: id  2 | task 41019 | stop processing: n_tokens = 25231, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.982 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 41082 | processing task, is_child = 0
slot update_slots: id  2 | task 41082 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 25634
slot update_slots: id  2 | task 41082 | n_tokens = 25171, memory_seq_rm [25171, end)
slot update_slots: id  2 | task 41082 | prompt processing progress, n_tokens = 25570, batch.n_tokens = 399, progress = 0.997503
slot update_slots: id  2 | task 41082 | n_tokens = 25570, memory_seq_rm [25570, end)
slot update_slots: id  2 | task 41082 | prompt processing progress, n_tokens = 25634, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 41082 | prompt done, n_tokens = 25634, batch.n_tokens = 64
slot init_sampler: id  2 | task 41082 | init sampler, took 6.81 ms, tokens: text = 25634, total = 25634
slot update_slots: id  2 | task 41082 | erasing old context checkpoint (pos_min = 22460, pos_max = 23356, size = 21.034 MiB)
slot update_slots: id  2 | task 41082 | created context checkpoint 8 of 8 (pos_min = 24717, pos_max = 25569, size = 20.002 MiB)
slot print_timing: id  2 | task 41082 | 
prompt eval time =     762.70 ms /   463 tokens (    1.65 ms per token,   607.06 tokens per second)
       eval time =   25063.06 ms /   918 tokens (   27.30 ms per token,    36.63 tokens per second)
      total time =   25825.76 ms /  1381 tokens
slot      release: id  2 | task 41082 | stop processing: n_tokens = 26551, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.965
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 42002 | processing task, is_child = 0
slot update_slots: id  2 | task 42002 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 25963
slot update_slots: id  2 | task 42002 | n_past = 25634, slot.prompt.tokens.size() = 26551, seq_id = 2, pos_min = 25654, n_swa = 128
slot update_slots: id  2 | task 42002 | restored context checkpoint (pos_min = 24717, pos_max = 25569, size = 20.002 MiB)
slot update_slots: id  2 | task 42002 | n_tokens = 25569, memory_seq_rm [25569, end)
slot update_slots: id  2 | task 42002 | prompt processing progress, n_tokens = 25899, batch.n_tokens = 330, progress = 0.997535
slot update_slots: id  2 | task 42002 | n_tokens = 25899, memory_seq_rm [25899, end)
slot update_slots: id  2 | task 42002 | prompt processing progress, n_tokens = 25963, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 42002 | prompt done, n_tokens = 25963, batch.n_tokens = 64
slot init_sampler: id  2 | task 42002 | init sampler, took 4.57 ms, tokens: text = 25963, total = 25963
slot update_slots: id  2 | task 42002 | erasing old context checkpoint (pos_min = 22836, pos_max = 23711, size = 20.542 MiB)
slot update_slots: id  2 | task 42002 | created context checkpoint 8 of 8 (pos_min = 25046, pos_max = 25898, size = 20.002 MiB)
slot print_timing: id  2 | task 42002 | 
prompt eval time =     873.82 ms /   394 tokens (    2.22 ms per token,   450.90 tokens per second)
       eval time =    1505.69 ms /    55 tokens (   27.38 ms per token,    36.53 tokens per second)
      total time =    2379.51 ms /   449 tokens
slot      release: id  2 | task 42002 | stop processing: n_tokens = 26017, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 42059 | processing task, is_child = 0
slot update_slots: id  2 | task 42059 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 26225
slot update_slots: id  2 | task 42059 | n_tokens = 25963, memory_seq_rm [25963, end)
slot update_slots: id  2 | task 42059 | prompt processing progress, n_tokens = 26161, batch.n_tokens = 198, progress = 0.997560
slot update_slots: id  2 | task 42059 | n_tokens = 26161, memory_seq_rm [26161, end)
slot update_slots: id  2 | task 42059 | prompt processing progress, n_tokens = 26225, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 42059 | prompt done, n_tokens = 26225, batch.n_tokens = 64
slot init_sampler: id  2 | task 42059 | init sampler, took 4.22 ms, tokens: text = 26225, total = 26225
slot update_slots: id  2 | task 42059 | erasing old context checkpoint (pos_min = 23061, pos_max = 23793, size = 17.188 MiB)
slot update_slots: id  2 | task 42059 | created context checkpoint 8 of 8 (pos_min = 25264, pos_max = 26160, size = 21.034 MiB)
slot print_timing: id  2 | task 42059 | 
prompt eval time =     578.97 ms /   262 tokens (    2.21 ms per token,   452.53 tokens per second)
       eval time =    1501.85 ms /    53 tokens (   28.34 ms per token,    35.29 tokens per second)
      total time =    2080.81 ms /   315 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 42059 | stop processing: n_tokens = 26277, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 42114 | processing task, is_child = 0
slot update_slots: id  2 | task 42114 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 26580
slot update_slots: id  2 | task 42114 | n_tokens = 26225, memory_seq_rm [26225, end)
slot update_slots: id  2 | task 42114 | prompt processing progress, n_tokens = 26516, batch.n_tokens = 291, progress = 0.997592
slot update_slots: id  2 | task 42114 | n_tokens = 26516, memory_seq_rm [26516, end)
slot update_slots: id  2 | task 42114 | prompt processing progress, n_tokens = 26580, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 42114 | prompt done, n_tokens = 26580, batch.n_tokens = 64
slot init_sampler: id  2 | task 42114 | init sampler, took 5.83 ms, tokens: text = 26580, total = 26580
slot update_slots: id  2 | task 42114 | erasing old context checkpoint (pos_min = 23185, pos_max = 24011, size = 19.393 MiB)
slot update_slots: id  2 | task 42114 | created context checkpoint 8 of 8 (pos_min = 25619, pos_max = 26515, size = 21.034 MiB)
slot print_timing: id  2 | task 42114 | 
prompt eval time =     678.35 ms /   355 tokens (    1.91 ms per token,   523.33 tokens per second)
       eval time =    7882.87 ms /   288 tokens (   27.37 ms per token,    36.53 tokens per second)
      total time =    8561.22 ms /   643 tokens
slot      release: id  2 | task 42114 | stop processing: n_tokens = 26867, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.989
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 42404 | processing task, is_child = 0
slot update_slots: id  2 | task 42404 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 26807
slot update_slots: id  2 | task 42404 | n_tokens = 26580, memory_seq_rm [26580, end)
slot update_slots: id  2 | task 42404 | prompt processing progress, n_tokens = 26743, batch.n_tokens = 163, progress = 0.997613
slot update_slots: id  2 | task 42404 | n_tokens = 26743, memory_seq_rm [26743, end)
slot update_slots: id  2 | task 42404 | prompt processing progress, n_tokens = 26807, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 42404 | prompt done, n_tokens = 26807, batch.n_tokens = 64
slot init_sampler: id  2 | task 42404 | init sampler, took 3.91 ms, tokens: text = 26807, total = 26807
slot update_slots: id  2 | task 42404 | erasing old context checkpoint (pos_min = 23398, pos_max = 24273, size = 20.542 MiB)
slot update_slots: id  2 | task 42404 | created context checkpoint 8 of 8 (pos_min = 25970, pos_max = 26742, size = 18.126 MiB)
slot print_timing: id  2 | task 42404 | 
prompt eval time =     563.41 ms /   227 tokens (    2.48 ms per token,   402.90 tokens per second)
       eval time =    3170.76 ms /   115 tokens (   27.57 ms per token,    36.27 tokens per second)
      total time =    3734.18 ms /   342 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 42404 | stop processing: n_tokens = 26921, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.996
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 42521 | processing task, is_child = 0
slot update_slots: id  2 | task 42521 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 27069
slot update_slots: id  2 | task 42521 | n_tokens = 26807, memory_seq_rm [26807, end)
slot update_slots: id  2 | task 42521 | prompt processing progress, n_tokens = 27005, batch.n_tokens = 198, progress = 0.997636
slot update_slots: id  2 | task 42521 | n_tokens = 27005, memory_seq_rm [27005, end)
slot update_slots: id  2 | task 42521 | prompt processing progress, n_tokens = 27069, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 42521 | prompt done, n_tokens = 27069, batch.n_tokens = 64
slot init_sampler: id  2 | task 42521 | init sampler, took 5.66 ms, tokens: text = 27069, total = 27069
slot update_slots: id  2 | task 42521 | erasing old context checkpoint (pos_min = 23700, pos_max = 24596, size = 21.034 MiB)
slot update_slots: id  2 | task 42521 | created context checkpoint 8 of 8 (pos_min = 26108, pos_max = 27004, size = 21.034 MiB)
slot print_timing: id  2 | task 42521 | 
prompt eval time =     583.97 ms /   262 tokens (    2.23 ms per token,   448.65 tokens per second)
       eval time =    1745.70 ms /    62 tokens (   28.16 ms per token,    35.52 tokens per second)
      total time =    2329.67 ms /   324 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 42521 | stop processing: n_tokens = 27130, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 42585 | processing task, is_child = 0
slot update_slots: id  2 | task 42585 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 27424
slot update_slots: id  2 | task 42585 | n_tokens = 27069, memory_seq_rm [27069, end)
slot update_slots: id  2 | task 42585 | prompt processing progress, n_tokens = 27360, batch.n_tokens = 291, progress = 0.997666
slot update_slots: id  2 | task 42585 | n_tokens = 27360, memory_seq_rm [27360, end)
slot update_slots: id  2 | task 42585 | prompt processing progress, n_tokens = 27424, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 42585 | prompt done, n_tokens = 27424, batch.n_tokens = 64
slot init_sampler: id  2 | task 42585 | init sampler, took 4.03 ms, tokens: text = 27424, total = 27424
slot update_slots: id  2 | task 42585 | erasing old context checkpoint (pos_min = 23972, pos_max = 24751, size = 18.290 MiB)
slot update_slots: id  2 | task 42585 | created context checkpoint 8 of 8 (pos_min = 26463, pos_max = 27359, size = 21.034 MiB)
slot print_timing: id  2 | task 42585 | 
prompt eval time =     672.35 ms /   355 tokens (    1.89 ms per token,   528.00 tokens per second)
       eval time =    1604.84 ms /    59 tokens (   27.20 ms per token,    36.76 tokens per second)
      total time =    2277.20 ms /   414 tokens
slot      release: id  2 | task 42585 | stop processing: n_tokens = 27482, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.984 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 42646 | processing task, is_child = 0
slot update_slots: id  2 | task 42646 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 27873
slot update_slots: id  2 | task 42646 | n_tokens = 27424, memory_seq_rm [27424, end)
slot update_slots: id  2 | task 42646 | prompt processing progress, n_tokens = 27809, batch.n_tokens = 385, progress = 0.997704
slot update_slots: id  2 | task 42646 | n_tokens = 27809, memory_seq_rm [27809, end)
slot update_slots: id  2 | task 42646 | prompt processing progress, n_tokens = 27873, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 42646 | prompt done, n_tokens = 27873, batch.n_tokens = 64
slot init_sampler: id  2 | task 42646 | init sampler, took 4.43 ms, tokens: text = 27873, total = 27873
slot update_slots: id  2 | task 42646 | erasing old context checkpoint (pos_min = 24210, pos_max = 25106, size = 21.034 MiB)
slot update_slots: id  2 | task 42646 | created context checkpoint 8 of 8 (pos_min = 26912, pos_max = 27808, size = 21.034 MiB)
slot print_timing: id  2 | task 42646 | 
prompt eval time =     774.31 ms /   449 tokens (    1.72 ms per token,   579.87 tokens per second)
       eval time =    1461.06 ms /    53 tokens (   27.57 ms per token,    36.28 tokens per second)
      total time =    2235.36 ms /   502 tokens
slot      release: id  2 | task 42646 | stop processing: n_tokens = 27925, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.978 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 42701 | processing task, is_child = 0
slot update_slots: id  2 | task 42701 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 28497
slot update_slots: id  2 | task 42701 | n_tokens = 27873, memory_seq_rm [27873, end)
slot update_slots: id  2 | task 42701 | prompt processing progress, n_tokens = 28433, batch.n_tokens = 560, progress = 0.997754
slot update_slots: id  2 | task 42701 | n_tokens = 28433, memory_seq_rm [28433, end)
slot update_slots: id  2 | task 42701 | prompt processing progress, n_tokens = 28497, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 42701 | prompt done, n_tokens = 28497, batch.n_tokens = 64
slot init_sampler: id  2 | task 42701 | init sampler, took 4.36 ms, tokens: text = 28497, total = 28497
slot update_slots: id  2 | task 42701 | erasing old context checkpoint (pos_min = 24717, pos_max = 25569, size = 20.002 MiB)
slot update_slots: id  2 | task 42701 | created context checkpoint 8 of 8 (pos_min = 27536, pos_max = 28432, size = 21.034 MiB)
slot print_timing: id  2 | task 42701 | 
prompt eval time =    1108.73 ms /   624 tokens (    1.78 ms per token,   562.81 tokens per second)
       eval time =    1723.02 ms /    63 tokens (   27.35 ms per token,    36.56 tokens per second)
      total time =    2831.75 ms /   687 tokens
slot      release: id  2 | task 42701 | stop processing: n_tokens = 28559, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 42766 | processing task, is_child = 0
slot update_slots: id  2 | task 42766 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 28759
slot update_slots: id  2 | task 42766 | n_tokens = 28497, memory_seq_rm [28497, end)
slot update_slots: id  2 | task 42766 | prompt processing progress, n_tokens = 28695, batch.n_tokens = 198, progress = 0.997775
slot update_slots: id  2 | task 42766 | n_tokens = 28695, memory_seq_rm [28695, end)
slot update_slots: id  2 | task 42766 | prompt processing progress, n_tokens = 28759, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 42766 | prompt done, n_tokens = 28759, batch.n_tokens = 64
slot init_sampler: id  2 | task 42766 | init sampler, took 4.41 ms, tokens: text = 28759, total = 28759
slot update_slots: id  2 | task 42766 | erasing old context checkpoint (pos_min = 25046, pos_max = 25898, size = 20.002 MiB)
slot update_slots: id  2 | task 42766 | created context checkpoint 8 of 8 (pos_min = 27798, pos_max = 28694, size = 21.034 MiB)
slot print_timing: id  2 | task 42766 | 
prompt eval time =     594.42 ms /   262 tokens (    2.27 ms per token,   440.76 tokens per second)
       eval time =    2328.99 ms /    82 tokens (   28.40 ms per token,    35.21 tokens per second)
      total time =    2923.42 ms /   344 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 42766 | stop processing: n_tokens = 28840, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.982 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 42850 | processing task, is_child = 0
slot update_slots: id  2 | task 42850 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 29289
slot update_slots: id  2 | task 42850 | n_tokens = 28759, memory_seq_rm [28759, end)
slot update_slots: id  2 | task 42850 | prompt processing progress, n_tokens = 29225, batch.n_tokens = 466, progress = 0.997815
slot update_slots: id  2 | task 42850 | n_tokens = 29225, memory_seq_rm [29225, end)
slot update_slots: id  2 | task 42850 | prompt processing progress, n_tokens = 29289, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 42850 | prompt done, n_tokens = 29289, batch.n_tokens = 64
slot init_sampler: id  2 | task 42850 | init sampler, took 6.28 ms, tokens: text = 29289, total = 29289
slot update_slots: id  2 | task 42850 | erasing old context checkpoint (pos_min = 25264, pos_max = 26160, size = 21.034 MiB)
slot update_slots: id  2 | task 42850 | created context checkpoint 8 of 8 (pos_min = 28328, pos_max = 29224, size = 21.034 MiB)
slot print_timing: id  2 | task 42850 | 
prompt eval time =     903.35 ms /   530 tokens (    1.70 ms per token,   586.71 tokens per second)
       eval time =    1551.86 ms /    56 tokens (   27.71 ms per token,    36.09 tokens per second)
      total time =    2455.21 ms /   586 tokens
slot      release: id  2 | task 42850 | stop processing: n_tokens = 29344, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 42908 | processing task, is_child = 0
slot update_slots: id  2 | task 42908 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 29738
slot update_slots: id  2 | task 42908 | n_tokens = 29289, memory_seq_rm [29289, end)
slot update_slots: id  2 | task 42908 | prompt processing progress, n_tokens = 29674, batch.n_tokens = 385, progress = 0.997848
slot update_slots: id  2 | task 42908 | n_tokens = 29674, memory_seq_rm [29674, end)
slot update_slots: id  2 | task 42908 | prompt processing progress, n_tokens = 29738, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 42908 | prompt done, n_tokens = 29738, batch.n_tokens = 64
slot init_sampler: id  2 | task 42908 | init sampler, took 4.44 ms, tokens: text = 29738, total = 29738
slot update_slots: id  2 | task 42908 | erasing old context checkpoint (pos_min = 25619, pos_max = 26515, size = 21.034 MiB)
slot update_slots: id  2 | task 42908 | created context checkpoint 8 of 8 (pos_min = 28777, pos_max = 29673, size = 21.034 MiB)
slot print_timing: id  2 | task 42908 | 
prompt eval time =     789.21 ms /   449 tokens (    1.76 ms per token,   568.92 tokens per second)
       eval time =    7726.95 ms /   278 tokens (   27.79 ms per token,    35.98 tokens per second)
      total time =    8516.17 ms /   727 tokens
slot      release: id  2 | task 42908 | stop processing: n_tokens = 30015, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 43188 | processing task, is_child = 0
slot update_slots: id  2 | task 43188 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 29954
slot update_slots: id  2 | task 43188 | n_tokens = 29738, memory_seq_rm [29738, end)
slot update_slots: id  2 | task 43188 | prompt processing progress, n_tokens = 29890, batch.n_tokens = 152, progress = 0.997863
slot update_slots: id  2 | task 43188 | n_tokens = 29890, memory_seq_rm [29890, end)
slot update_slots: id  2 | task 43188 | prompt processing progress, n_tokens = 29954, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 43188 | prompt done, n_tokens = 29954, batch.n_tokens = 64
slot init_sampler: id  2 | task 43188 | init sampler, took 6.25 ms, tokens: text = 29954, total = 29954
slot update_slots: id  2 | task 43188 | erasing old context checkpoint (pos_min = 25970, pos_max = 26742, size = 18.126 MiB)
slot update_slots: id  2 | task 43188 | created context checkpoint 8 of 8 (pos_min = 29118, pos_max = 29889, size = 18.103 MiB)
slot print_timing: id  2 | task 43188 | 
prompt eval time =     548.98 ms /   216 tokens (    2.54 ms per token,   393.45 tokens per second)
       eval time =   37283.23 ms /  1335 tokens (   27.93 ms per token,    35.81 tokens per second)
      total time =   37832.22 ms /  1551 tokens
slot      release: id  2 | task 43188 | stop processing: n_tokens = 31288, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.990 (> 0.100 thold), f_keep = 0.957
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 44525 | processing task, is_child = 0
slot update_slots: id  2 | task 44525 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 30269
slot update_slots: id  2 | task 44525 | n_past = 29954, slot.prompt.tokens.size() = 31288, seq_id = 2, pos_min = 30391, n_swa = 128
slot update_slots: id  2 | task 44525 | restored context checkpoint (pos_min = 29118, pos_max = 29889, size = 18.103 MiB)
slot update_slots: id  2 | task 44525 | n_tokens = 29889, memory_seq_rm [29889, end)
slot update_slots: id  2 | task 44525 | prompt processing progress, n_tokens = 30205, batch.n_tokens = 316, progress = 0.997886
slot update_slots: id  2 | task 44525 | n_tokens = 30205, memory_seq_rm [30205, end)
slot update_slots: id  2 | task 44525 | prompt processing progress, n_tokens = 30269, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 44525 | prompt done, n_tokens = 30269, batch.n_tokens = 64
slot init_sampler: id  2 | task 44525 | init sampler, took 4.69 ms, tokens: text = 30269, total = 30269
slot update_slots: id  2 | task 44525 | erasing old context checkpoint (pos_min = 26108, pos_max = 27004, size = 21.034 MiB)
slot update_slots: id  2 | task 44525 | created context checkpoint 8 of 8 (pos_min = 29433, pos_max = 30204, size = 18.103 MiB)
slot print_timing: id  2 | task 44525 | 
prompt eval time =     865.39 ms /   380 tokens (    2.28 ms per token,   439.11 tokens per second)
       eval time =    2398.59 ms /    82 tokens (   29.25 ms per token,    34.19 tokens per second)
      total time =    3263.98 ms /   462 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 44525 | stop processing: n_tokens = 30350, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 44609 | processing task, is_child = 0
slot update_slots: id  2 | task 44609 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 30531
slot update_slots: id  2 | task 44609 | n_tokens = 30269, memory_seq_rm [30269, end)
slot update_slots: id  2 | task 44609 | prompt processing progress, n_tokens = 30467, batch.n_tokens = 198, progress = 0.997904
slot update_slots: id  2 | task 44609 | n_tokens = 30467, memory_seq_rm [30467, end)
slot update_slots: id  2 | task 44609 | prompt processing progress, n_tokens = 30531, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 44609 | prompt done, n_tokens = 30531, batch.n_tokens = 64
slot init_sampler: id  2 | task 44609 | init sampler, took 11.98 ms, tokens: text = 30531, total = 30531
slot update_slots: id  2 | task 44609 | erasing old context checkpoint (pos_min = 26463, pos_max = 27359, size = 21.034 MiB)
slot update_slots: id  2 | task 44609 | created context checkpoint 8 of 8 (pos_min = 29656, pos_max = 30466, size = 19.017 MiB)
slot print_timing: id  2 | task 44609 | 
prompt eval time =     614.46 ms /   262 tokens (    2.35 ms per token,   426.39 tokens per second)
       eval time =   25804.94 ms /   927 tokens (   27.84 ms per token,    35.92 tokens per second)
      total time =   26419.40 ms /  1189 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 44609 | stop processing: n_tokens = 31457, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.971
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 45538 | processing task, is_child = 0
slot update_slots: id  2 | task 45538 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 30723
slot update_slots: id  2 | task 45538 | n_past = 30531, slot.prompt.tokens.size() = 31457, seq_id = 2, pos_min = 30560, n_swa = 128
slot update_slots: id  2 | task 45538 | restored context checkpoint (pos_min = 29656, pos_max = 30466, size = 19.017 MiB)
slot update_slots: id  2 | task 45538 | n_tokens = 30466, memory_seq_rm [30466, end)
slot update_slots: id  2 | task 45538 | prompt processing progress, n_tokens = 30659, batch.n_tokens = 193, progress = 0.997917
slot update_slots: id  2 | task 45538 | n_tokens = 30659, memory_seq_rm [30659, end)
slot update_slots: id  2 | task 45538 | prompt processing progress, n_tokens = 30723, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 45538 | prompt done, n_tokens = 30723, batch.n_tokens = 64
slot init_sampler: id  2 | task 45538 | init sampler, took 6.84 ms, tokens: text = 30723, total = 30723
slot update_slots: id  2 | task 45538 | erasing old context checkpoint (pos_min = 26912, pos_max = 27808, size = 21.034 MiB)
slot update_slots: id  2 | task 45538 | created context checkpoint 8 of 8 (pos_min = 29762, pos_max = 30658, size = 21.034 MiB)
slot print_timing: id  2 | task 45538 | 
prompt eval time =     823.97 ms /   257 tokens (    3.21 ms per token,   311.91 tokens per second)
       eval time =    2078.21 ms /    75 tokens (   27.71 ms per token,    36.09 tokens per second)
      total time =    2902.18 ms /   332 tokens
slot      release: id  2 | task 45538 | stop processing: n_tokens = 30797, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 45615 | processing task, is_child = 0
slot update_slots: id  2 | task 45615 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31060
slot update_slots: id  2 | task 45615 | n_tokens = 30723, memory_seq_rm [30723, end)
slot update_slots: id  2 | task 45615 | prompt processing progress, n_tokens = 30996, batch.n_tokens = 273, progress = 0.997939
slot update_slots: id  2 | task 45615 | n_tokens = 30996, memory_seq_rm [30996, end)
slot update_slots: id  2 | task 45615 | prompt processing progress, n_tokens = 31060, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 45615 | prompt done, n_tokens = 31060, batch.n_tokens = 64
slot init_sampler: id  2 | task 45615 | init sampler, took 4.83 ms, tokens: text = 31060, total = 31060
slot update_slots: id  2 | task 45615 | erasing old context checkpoint (pos_min = 27536, pos_max = 28432, size = 21.034 MiB)
slot update_slots: id  2 | task 45615 | created context checkpoint 8 of 8 (pos_min = 30099, pos_max = 30995, size = 21.034 MiB)
slot print_timing: id  2 | task 45615 | 
prompt eval time =     671.17 ms /   337 tokens (    1.99 ms per token,   502.11 tokens per second)
       eval time =   24280.26 ms /   865 tokens (   28.07 ms per token,    35.63 tokens per second)
      total time =   24951.43 ms /  1202 tokens
slot      release: id  2 | task 45615 | stop processing: n_tokens = 31924, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.991 (> 0.100 thold), f_keep = 0.973
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 46482 | processing task, is_child = 0
slot update_slots: id  2 | task 46482 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31334
slot update_slots: id  2 | task 46482 | n_past = 31060, slot.prompt.tokens.size() = 31924, seq_id = 2, pos_min = 31027, n_swa = 128
slot update_slots: id  2 | task 46482 | restored context checkpoint (pos_min = 30099, pos_max = 30995, size = 21.034 MiB)
slot update_slots: id  2 | task 46482 | n_tokens = 30995, memory_seq_rm [30995, end)
slot update_slots: id  2 | task 46482 | prompt processing progress, n_tokens = 31270, batch.n_tokens = 275, progress = 0.997957
slot update_slots: id  2 | task 46482 | n_tokens = 31270, memory_seq_rm [31270, end)
slot update_slots: id  2 | task 46482 | prompt processing progress, n_tokens = 31334, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 46482 | prompt done, n_tokens = 31334, batch.n_tokens = 64
slot init_sampler: id  2 | task 46482 | init sampler, took 4.88 ms, tokens: text = 31334, total = 31334
slot update_slots: id  2 | task 46482 | erasing old context checkpoint (pos_min = 27798, pos_max = 28694, size = 21.034 MiB)
slot update_slots: id  2 | task 46482 | created context checkpoint 8 of 8 (pos_min = 30373, pos_max = 31269, size = 21.034 MiB)
slot print_timing: id  2 | task 46482 | 
prompt eval time =     842.67 ms /   339 tokens (    2.49 ms per token,   402.29 tokens per second)
       eval time =    7211.48 ms /   258 tokens (   27.95 ms per token,    35.78 tokens per second)
      total time =    8054.15 ms /   597 tokens
slot      release: id  2 | task 46482 | stop processing: n_tokens = 31591, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.992
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 46742 | processing task, is_child = 0
slot update_slots: id  2 | task 46742 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31386
slot update_slots: id  2 | task 46742 | n_tokens = 31334, memory_seq_rm [31334, end)
slot update_slots: id  2 | task 46742 | prompt processing progress, n_tokens = 31386, batch.n_tokens = 52, progress = 1.000000
slot update_slots: id  2 | task 46742 | prompt done, n_tokens = 31386, batch.n_tokens = 52
slot init_sampler: id  2 | task 46742 | init sampler, took 4.75 ms, tokens: text = 31386, total = 31386
slot print_timing: id  2 | task 46742 | 
prompt eval time =     189.20 ms /    52 tokens (    3.64 ms per token,   274.85 tokens per second)
       eval time =   16255.36 ms /   578 tokens (   28.12 ms per token,    35.56 tokens per second)
      total time =   16444.56 ms /   630 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 46742 | stop processing: n_tokens = 31963, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.982
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 47321 | processing task, is_child = 0
slot update_slots: id  2 | task 47321 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31595
slot update_slots: id  2 | task 47321 | n_tokens = 31386, memory_seq_rm [31386, end)
slot update_slots: id  2 | task 47321 | prompt processing progress, n_tokens = 31531, batch.n_tokens = 145, progress = 0.997974
slot update_slots: id  2 | task 47321 | n_tokens = 31531, memory_seq_rm [31531, end)
slot update_slots: id  2 | task 47321 | prompt processing progress, n_tokens = 31595, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 47321 | prompt done, n_tokens = 31595, batch.n_tokens = 64
slot init_sampler: id  2 | task 47321 | init sampler, took 7.60 ms, tokens: text = 31595, total = 31595
slot update_slots: id  2 | task 47321 | erasing old context checkpoint (pos_min = 28328, pos_max = 29224, size = 21.034 MiB)
slot update_slots: id  2 | task 47321 | created context checkpoint 8 of 8 (pos_min = 31182, pos_max = 31530, size = 8.184 MiB)
slot print_timing: id  2 | task 47321 | 
prompt eval time =     549.15 ms /   209 tokens (    2.63 ms per token,   380.59 tokens per second)
       eval time =   32197.18 ms /  1145 tokens (   28.12 ms per token,    35.56 tokens per second)
      total time =   32746.33 ms /  1354 tokens
slot      release: id  2 | task 47321 | stop processing: n_tokens = 32739, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.965
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 48468 | processing task, is_child = 0
slot update_slots: id  2 | task 48468 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 31841
slot update_slots: id  2 | task 48468 | n_past = 31595, slot.prompt.tokens.size() = 32739, seq_id = 2, pos_min = 31842, n_swa = 128
slot update_slots: id  2 | task 48468 | restored context checkpoint (pos_min = 31182, pos_max = 31530, size = 8.184 MiB)
slot update_slots: id  2 | task 48468 | n_tokens = 31530, memory_seq_rm [31530, end)
slot update_slots: id  2 | task 48468 | prompt processing progress, n_tokens = 31777, batch.n_tokens = 247, progress = 0.997990
slot update_slots: id  2 | task 48468 | n_tokens = 31777, memory_seq_rm [31777, end)
slot update_slots: id  2 | task 48468 | prompt processing progress, n_tokens = 31841, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 48468 | prompt done, n_tokens = 31841, batch.n_tokens = 64
slot init_sampler: id  2 | task 48468 | init sampler, took 6.33 ms, tokens: text = 31841, total = 31841
slot update_slots: id  2 | task 48468 | erasing old context checkpoint (pos_min = 28777, pos_max = 29673, size = 21.034 MiB)
slot update_slots: id  2 | task 48468 | created context checkpoint 8 of 8 (pos_min = 31334, pos_max = 31776, size = 10.388 MiB)
slot print_timing: id  2 | task 48468 | 
prompt eval time =     723.22 ms /   311 tokens (    2.33 ms per token,   430.02 tokens per second)
       eval time =   29108.53 ms /  1035 tokens (   28.12 ms per token,    35.56 tokens per second)
      total time =   29831.75 ms /  1346 tokens
slot      release: id  2 | task 48468 | stop processing: n_tokens = 32875, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.969
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 49505 | processing task, is_child = 0
slot update_slots: id  2 | task 49505 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32109
slot update_slots: id  2 | task 49505 | n_past = 31841, slot.prompt.tokens.size() = 32875, seq_id = 2, pos_min = 31978, n_swa = 128
slot update_slots: id  2 | task 49505 | restored context checkpoint (pos_min = 31334, pos_max = 31776, size = 10.388 MiB)
slot update_slots: id  2 | task 49505 | n_tokens = 31776, memory_seq_rm [31776, end)
slot update_slots: id  2 | task 49505 | prompt processing progress, n_tokens = 32045, batch.n_tokens = 269, progress = 0.998007
slot update_slots: id  2 | task 49505 | n_tokens = 32045, memory_seq_rm [32045, end)
slot update_slots: id  2 | task 49505 | prompt processing progress, n_tokens = 32109, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 49505 | prompt done, n_tokens = 32109, batch.n_tokens = 64
slot init_sampler: id  2 | task 49505 | init sampler, took 5.02 ms, tokens: text = 32109, total = 32109
slot update_slots: id  2 | task 49505 | erasing old context checkpoint (pos_min = 29118, pos_max = 29889, size = 18.103 MiB)
slot update_slots: id  2 | task 49505 | created context checkpoint 8 of 8 (pos_min = 31334, pos_max = 32044, size = 16.672 MiB)
slot print_timing: id  2 | task 49505 | 
prompt eval time =     690.81 ms /   333 tokens (    2.07 ms per token,   482.05 tokens per second)
       eval time =    4834.38 ms /   170 tokens (   28.44 ms per token,    35.16 tokens per second)
      total time =    5525.18 ms /   503 tokens
slot      release: id  2 | task 49505 | stop processing: n_tokens = 32278, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.998 (> 0.100 thold), f_keep = 0.995
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 49677 | processing task, is_child = 0
slot update_slots: id  2 | task 49677 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32172
slot update_slots: id  2 | task 49677 | n_tokens = 32109, memory_seq_rm [32109, end)
slot update_slots: id  2 | task 49677 | prompt processing progress, n_tokens = 32172, batch.n_tokens = 63, progress = 1.000000
slot update_slots: id  2 | task 49677 | prompt done, n_tokens = 32172, batch.n_tokens = 63
slot init_sampler: id  2 | task 49677 | init sampler, took 4.83 ms, tokens: text = 32172, total = 32172
slot print_timing: id  2 | task 49677 | 
prompt eval time =     236.84 ms /    63 tokens (    3.76 ms per token,   266.00 tokens per second)
       eval time =    1678.14 ms /    60 tokens (   27.97 ms per token,    35.75 tokens per second)
      total time =    1914.98 ms /   123 tokens
slot      release: id  2 | task 49677 | stop processing: n_tokens = 32231, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.992 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 49738 | processing task, is_child = 0
slot update_slots: id  2 | task 49738 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32434
slot update_slots: id  2 | task 49738 | n_tokens = 32172, memory_seq_rm [32172, end)
slot update_slots: id  2 | task 49738 | prompt processing progress, n_tokens = 32370, batch.n_tokens = 198, progress = 0.998027
slot update_slots: id  2 | task 49738 | n_tokens = 32370, memory_seq_rm [32370, end)
slot update_slots: id  2 | task 49738 | prompt processing progress, n_tokens = 32434, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 49738 | prompt done, n_tokens = 32434, batch.n_tokens = 64
slot init_sampler: id  2 | task 49738 | init sampler, took 5.17 ms, tokens: text = 32434, total = 32434
slot update_slots: id  2 | task 49738 | erasing old context checkpoint (pos_min = 29433, pos_max = 30204, size = 18.103 MiB)
slot update_slots: id  2 | task 49738 | created context checkpoint 8 of 8 (pos_min = 31595, pos_max = 32369, size = 18.173 MiB)
slot print_timing: id  2 | task 49738 | 
prompt eval time =     609.61 ms /   262 tokens (    2.33 ms per token,   429.79 tokens per second)
       eval time =   22079.72 ms /   786 tokens (   28.09 ms per token,    35.60 tokens per second)
      total time =   22689.33 ms /  1048 tokens
slot      release: id  2 | task 49738 | stop processing: n_tokens = 33219, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.976
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 50526 | processing task, is_child = 0
slot update_slots: id  2 | task 50526 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 32675
slot update_slots: id  2 | task 50526 | n_past = 32434, slot.prompt.tokens.size() = 33219, seq_id = 2, pos_min = 32322, n_swa = 128
slot update_slots: id  2 | task 50526 | restored context checkpoint (pos_min = 31595, pos_max = 32369, size = 18.173 MiB)
slot update_slots: id  2 | task 50526 | n_tokens = 32369, memory_seq_rm [32369, end)
slot update_slots: id  2 | task 50526 | prompt processing progress, n_tokens = 32611, batch.n_tokens = 242, progress = 0.998041
slot update_slots: id  2 | task 50526 | n_tokens = 32611, memory_seq_rm [32611, end)
slot update_slots: id  2 | task 50526 | prompt processing progress, n_tokens = 32675, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 50526 | prompt done, n_tokens = 32675, batch.n_tokens = 64
slot init_sampler: id  2 | task 50526 | init sampler, took 7.11 ms, tokens: text = 32675, total = 32675
slot update_slots: id  2 | task 50526 | erasing old context checkpoint (pos_min = 29656, pos_max = 30466, size = 19.017 MiB)
slot update_slots: id  2 | task 50526 | created context checkpoint 8 of 8 (pos_min = 31836, pos_max = 32610, size = 18.173 MiB)
slot print_timing: id  2 | task 50526 | 
prompt eval time =     991.90 ms /   306 tokens (    3.24 ms per token,   308.50 tokens per second)
       eval time =    1949.57 ms /    70 tokens (   27.85 ms per token,    35.91 tokens per second)
      total time =    2941.47 ms /   376 tokens
slot      release: id  2 | task 50526 | stop processing: n_tokens = 32744, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.955 (> 0.100 thold), f_keep = 0.998
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 50598 | processing task, is_child = 0
slot update_slots: id  2 | task 50598 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 34218
slot update_slots: id  2 | task 50598 | n_tokens = 32675, memory_seq_rm [32675, end)
slot update_slots: id  2 | task 50598 | prompt processing progress, n_tokens = 34154, batch.n_tokens = 1479, progress = 0.998130
slot update_slots: id  2 | task 50598 | n_tokens = 34154, memory_seq_rm [34154, end)
slot update_slots: id  2 | task 50598 | prompt processing progress, n_tokens = 34218, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 50598 | prompt done, n_tokens = 34218, batch.n_tokens = 64
slot init_sampler: id  2 | task 50598 | init sampler, took 5.48 ms, tokens: text = 34218, total = 34218
slot update_slots: id  2 | task 50598 | erasing old context checkpoint (pos_min = 29762, pos_max = 30658, size = 21.034 MiB)
slot update_slots: id  2 | task 50598 | created context checkpoint 8 of 8 (pos_min = 33257, pos_max = 34153, size = 21.034 MiB)
slot print_timing: id  2 | task 50598 | 
prompt eval time =    2467.55 ms /  1543 tokens (    1.60 ms per token,   625.32 tokens per second)
       eval time =   27129.51 ms /   957 tokens (   28.35 ms per token,    35.28 tokens per second)
      total time =   29597.07 ms /  2500 tokens
slot      release: id  2 | task 50598 | stop processing: n_tokens = 35174, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.973
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 51557 | processing task, is_child = 0
slot update_slots: id  2 | task 51557 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 34715
slot update_slots: id  2 | task 51557 | n_past = 34218, slot.prompt.tokens.size() = 35174, seq_id = 2, pos_min = 34277, n_swa = 128
slot update_slots: id  2 | task 51557 | restored context checkpoint (pos_min = 33257, pos_max = 34153, size = 21.034 MiB)
slot update_slots: id  2 | task 51557 | n_tokens = 34153, memory_seq_rm [34153, end)
slot update_slots: id  2 | task 51557 | prompt processing progress, n_tokens = 34651, batch.n_tokens = 498, progress = 0.998156
slot update_slots: id  2 | task 51557 | n_tokens = 34651, memory_seq_rm [34651, end)
slot update_slots: id  2 | task 51557 | prompt processing progress, n_tokens = 34715, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 51557 | prompt done, n_tokens = 34715, batch.n_tokens = 64
slot init_sampler: id  2 | task 51557 | init sampler, took 5.78 ms, tokens: text = 34715, total = 34715
slot update_slots: id  2 | task 51557 | erasing old context checkpoint (pos_min = 30099, pos_max = 30995, size = 21.034 MiB)
slot update_slots: id  2 | task 51557 | created context checkpoint 8 of 8 (pos_min = 33754, pos_max = 34650, size = 21.034 MiB)
slot print_timing: id  2 | task 51557 | 
prompt eval time =    1198.84 ms /   562 tokens (    2.13 ms per token,   468.79 tokens per second)
       eval time =   20404.25 ms /   721 tokens (   28.30 ms per token,    35.34 tokens per second)
      total time =   21603.09 ms /  1283 tokens
slot      release: id  2 | task 51557 | stop processing: n_tokens = 35435, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.987 (> 0.100 thold), f_keep = 0.013
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 35435, total state size = 851.948 MiB
srv          load:  - looking for better prompt, base f_keep = 0.013, sim = 0.987
srv        update:  - cache state: 5 prompts, 3370.563 MiB (limits: 8192.000 MiB, 64000 tokens, 279745 est)
srv        update:    - prompt 0x5b74dc0d5ef0:    1042 tokens, checkpoints:  1,    56.513 MiB
srv        update:    - prompt 0x5b74e55a53f0:   26665 tokens, checkpoints:  8,   833.285 MiB
srv        update:    - prompt 0x5b74f4b2e0a0:   50148 tokens, checkpoints:  8,  1348.434 MiB
srv        update:    - prompt 0x5b74e53f67f0:    1810 tokens, checkpoints:  5,   145.690 MiB
srv        update:    - prompt 0x5b74e492c580:   35435 tokens, checkpoints:  8,   986.641 MiB
srv  get_availabl: prompt cache update took 992.71 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 52280 | processing task, is_child = 0
slot update_slots: id  2 | task 52280 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 461
slot update_slots: id  2 | task 52280 | n_past = 455, slot.prompt.tokens.size() = 35435, seq_id = 2, pos_min = 34538, n_swa = 128
slot update_slots: id  2 | task 52280 | forcing full prompt re-processing due to lack of cache data (likely due to SWA or hybrid/recurrent memory, see https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)
slot update_slots: id  2 | task 52280 | erased invalidated context checkpoint (pos_min = 30373, pos_max = 31269, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 52280 | erased invalidated context checkpoint (pos_min = 31182, pos_max = 31530, n_swa = 128, size = 8.184 MiB)
slot update_slots: id  2 | task 52280 | erased invalidated context checkpoint (pos_min = 31334, pos_max = 31776, n_swa = 128, size = 10.388 MiB)
slot update_slots: id  2 | task 52280 | erased invalidated context checkpoint (pos_min = 31334, pos_max = 32044, n_swa = 128, size = 16.672 MiB)
slot update_slots: id  2 | task 52280 | erased invalidated context checkpoint (pos_min = 31595, pos_max = 32369, n_swa = 128, size = 18.173 MiB)
slot update_slots: id  2 | task 52280 | erased invalidated context checkpoint (pos_min = 31836, pos_max = 32610, n_swa = 128, size = 18.173 MiB)
slot update_slots: id  2 | task 52280 | erased invalidated context checkpoint (pos_min = 33257, pos_max = 34153, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 52280 | erased invalidated context checkpoint (pos_min = 33754, pos_max = 34650, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 52280 | n_tokens = 0, memory_seq_rm [0, end)
slot update_slots: id  2 | task 52280 | prompt processing progress, n_tokens = 397, batch.n_tokens = 397, progress = 0.861171
slot update_slots: id  2 | task 52280 | n_tokens = 397, memory_seq_rm [397, end)
slot update_slots: id  2 | task 52280 | prompt processing progress, n_tokens = 461, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 52280 | prompt done, n_tokens = 461, batch.n_tokens = 64
slot init_sampler: id  2 | task 52280 | init sampler, took 0.12 ms, tokens: text = 461, total = 461
slot update_slots: id  2 | task 52280 | created context checkpoint 1 of 8 (pos_min = 0, pos_max = 396, size = 9.310 MiB)
slot print_timing: id  2 | task 52280 | 
prompt eval time =     682.99 ms /   461 tokens (    1.48 ms per token,   674.97 tokens per second)
       eval time =     751.71 ms /    31 tokens (   24.25 ms per token,    41.24 tokens per second)
      total time =    1434.70 ms /   492 tokens
slot      release: id  2 | task 52280 | stop processing: n_tokens = 491, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.970 (> 0.100 thold), f_keep = 0.923
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 52313 | processing task, is_child = 0
slot update_slots: id  2 | task 52313 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 467
slot update_slots: id  2 | task 52313 | n_tokens = 453, memory_seq_rm [453, end)
slot update_slots: id  2 | task 52313 | prompt processing progress, n_tokens = 467, batch.n_tokens = 14, progress = 1.000000
slot update_slots: id  2 | task 52313 | prompt done, n_tokens = 467, batch.n_tokens = 14
slot init_sampler: id  2 | task 52313 | init sampler, took 0.08 ms, tokens: text = 467, total = 467
slot print_timing: id  2 | task 52313 | 
prompt eval time =     133.39 ms /    14 tokens (    9.53 ms per token,   104.96 tokens per second)
       eval time =    1216.29 ms /    49 tokens (   24.82 ms per token,    40.29 tokens per second)
      total time =    1349.68 ms /    63 tokens
slot      release: id  2 | task 52313 | stop processing: n_tokens = 515, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.970 (> 0.100 thold), f_keep = 0.893
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 52363 | processing task, is_child = 0
slot update_slots: id  2 | task 52363 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 474
slot update_slots: id  2 | task 52363 | n_tokens = 460, memory_seq_rm [460, end)
slot update_slots: id  2 | task 52363 | prompt processing progress, n_tokens = 474, batch.n_tokens = 14, progress = 1.000000
slot update_slots: id  2 | task 52363 | prompt done, n_tokens = 474, batch.n_tokens = 14
slot init_sampler: id  2 | task 52363 | init sampler, took 0.07 ms, tokens: text = 474, total = 474
slot print_timing: id  2 | task 52363 | 
prompt eval time =     110.27 ms /    14 tokens (    7.88 ms per token,   126.96 tokens per second)
       eval time =    6910.75 ms /   274 tokens (   25.22 ms per token,    39.65 tokens per second)
      total time =    7021.02 ms /   288 tokens
slot      release: id  2 | task 52363 | stop processing: n_tokens = 747, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.958 (> 0.100 thold), f_keep = 0.606
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 52638 | processing task, is_child = 0
slot update_slots: id  2 | task 52638 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 473
slot update_slots: id  2 | task 52638 | n_tokens = 453, memory_seq_rm [453, end)
slot update_slots: id  2 | task 52638 | prompt processing progress, n_tokens = 473, batch.n_tokens = 20, progress = 1.000000
slot update_slots: id  2 | task 52638 | prompt done, n_tokens = 473, batch.n_tokens = 20
slot init_sampler: id  2 | task 52638 | init sampler, took 0.13 ms, tokens: text = 473, total = 473
slot print_timing: id  2 | task 52638 | 
prompt eval time =     156.68 ms /    20 tokens (    7.83 ms per token,   127.65 tokens per second)
       eval time =    1069.66 ms /    46 tokens (   23.25 ms per token,    43.00 tokens per second)
      total time =    1226.34 ms /    66 tokens
slot      release: id  2 | task 52638 | stop processing: n_tokens = 518, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.741 (> 0.100 thold), f_keep = 0.913
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 52685 | processing task, is_child = 0
slot update_slots: id  2 | task 52685 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 638
slot update_slots: id  2 | task 52685 | n_tokens = 473, memory_seq_rm [473, end)
slot update_slots: id  2 | task 52685 | prompt processing progress, n_tokens = 574, batch.n_tokens = 101, progress = 0.899687
slot update_slots: id  2 | task 52685 | n_tokens = 574, memory_seq_rm [574, end)
slot update_slots: id  2 | task 52685 | prompt processing progress, n_tokens = 638, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 52685 | prompt done, n_tokens = 638, batch.n_tokens = 64
slot init_sampler: id  2 | task 52685 | init sampler, took 0.12 ms, tokens: text = 638, total = 638
slot update_slots: id  2 | task 52685 | created context checkpoint 2 of 8 (pos_min = 0, pos_max = 573, size = 13.460 MiB)
slot print_timing: id  2 | task 52685 | 
prompt eval time =     389.24 ms /   165 tokens (    2.36 ms per token,   423.90 tokens per second)
       eval time =    7249.16 ms /   300 tokens (   24.16 ms per token,    41.38 tokens per second)
      total time =    7638.40 ms /   465 tokens
slot      release: id  2 | task 52685 | stop processing: n_tokens = 937, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.964 (> 0.100 thold), f_keep = 0.486
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 937, total state size = 43.006 MiB
srv          load:  - looking for better prompt, base f_keep = 0.486, sim = 0.964
srv        update:  - cache state: 6 prompts, 3436.338 MiB (limits: 8192.000 MiB, 64000 tokens, 276624 est)
srv        update:    - prompt 0x5b74dc0d5ef0:    1042 tokens, checkpoints:  1,    56.513 MiB
srv        update:    - prompt 0x5b74e55a53f0:   26665 tokens, checkpoints:  8,   833.285 MiB
srv        update:    - prompt 0x5b74f4b2e0a0:   50148 tokens, checkpoints:  8,  1348.434 MiB
srv        update:    - prompt 0x5b74e53f67f0:    1810 tokens, checkpoints:  5,   145.690 MiB
srv        update:    - prompt 0x5b74e492c580:   35435 tokens, checkpoints:  8,   986.641 MiB
srv        update:    - prompt 0x5b74d1dcc750:     937 tokens, checkpoints:  2,    65.775 MiB
srv  get_availabl: prompt cache update took 48.79 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 52987 | processing task, is_child = 0
slot update_slots: id  2 | task 52987 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 472
slot update_slots: id  2 | task 52987 | n_tokens = 455, memory_seq_rm [455, end)
slot update_slots: id  2 | task 52987 | prompt processing progress, n_tokens = 472, batch.n_tokens = 17, progress = 1.000000
slot update_slots: id  2 | task 52987 | prompt done, n_tokens = 472, batch.n_tokens = 17
slot init_sampler: id  2 | task 52987 | init sampler, took 0.11 ms, tokens: text = 472, total = 472
slot print_timing: id  2 | task 52987 | 
prompt eval time =     156.46 ms /    17 tokens (    9.20 ms per token,   108.65 tokens per second)
       eval time =    1299.62 ms /    53 tokens (   24.52 ms per token,    40.78 tokens per second)
      total time =    1456.09 ms /    70 tokens
slot      release: id  2 | task 52987 | stop processing: n_tokens = 524, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.470 (> 0.100 thold), f_keep = 0.901
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 53041 | processing task, is_child = 0
slot update_slots: id  2 | task 53041 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1004
slot update_slots: id  2 | task 53041 | n_tokens = 472, memory_seq_rm [472, end)
slot update_slots: id  2 | task 53041 | prompt processing progress, n_tokens = 940, batch.n_tokens = 468, progress = 0.936255
slot update_slots: id  2 | task 53041 | n_tokens = 940, memory_seq_rm [940, end)
slot update_slots: id  2 | task 53041 | prompt processing progress, n_tokens = 1004, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 53041 | prompt done, n_tokens = 1004, batch.n_tokens = 64
slot init_sampler: id  2 | task 53041 | init sampler, took 0.20 ms, tokens: text = 1004, total = 1004
slot update_slots: id  2 | task 53041 | created context checkpoint 3 of 8 (pos_min = 345, pos_max = 939, size = 13.952 MiB)
slot print_timing: id  2 | task 53041 | 
prompt eval time =     601.79 ms /   532 tokens (    1.13 ms per token,   884.03 tokens per second)
       eval time =    2206.79 ms /    89 tokens (   24.80 ms per token,    40.33 tokens per second)
      total time =    2808.58 ms /   621 tokens
slot      release: id  2 | task 53041 | stop processing: n_tokens = 1092, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.917 (> 0.100 thold), f_keep = 0.919
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 53132 | processing task, is_child = 0
slot update_slots: id  2 | task 53132 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1095
slot update_slots: id  2 | task 53132 | n_tokens = 1004, memory_seq_rm [1004, end)
slot update_slots: id  2 | task 53132 | prompt processing progress, n_tokens = 1031, batch.n_tokens = 27, progress = 0.941553
slot update_slots: id  2 | task 53132 | n_tokens = 1031, memory_seq_rm [1031, end)
slot update_slots: id  2 | task 53132 | prompt processing progress, n_tokens = 1095, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 53132 | prompt done, n_tokens = 1095, batch.n_tokens = 64
slot init_sampler: id  2 | task 53132 | init sampler, took 0.22 ms, tokens: text = 1095, total = 1095
slot update_slots: id  2 | task 53132 | created context checkpoint 4 of 8 (pos_min = 345, pos_max = 1030, size = 16.086 MiB)
slot print_timing: id  2 | task 53132 | 
prompt eval time =     275.61 ms /    91 tokens (    3.03 ms per token,   330.18 tokens per second)
       eval time =     699.21 ms /    28 tokens (   24.97 ms per token,    40.05 tokens per second)
      total time =     974.81 ms /   119 tokens
slot      release: id  2 | task 53132 | stop processing: n_tokens = 1122, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.938 (> 0.100 thold), f_keep = 0.406
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 1122, total state size = 44.530 MiB
srv          load:  - looking for better prompt, base f_keep = 0.406, sim = 0.938
srv        update:  - cache state: 7 prompts, 3533.677 MiB (limits: 8192.000 MiB, 64000 tokens, 271605 est)
srv        update:    - prompt 0x5b74dc0d5ef0:    1042 tokens, checkpoints:  1,    56.513 MiB
srv        update:    - prompt 0x5b74e55a53f0:   26665 tokens, checkpoints:  8,   833.285 MiB
srv        update:    - prompt 0x5b74f4b2e0a0:   50148 tokens, checkpoints:  8,  1348.434 MiB
srv        update:    - prompt 0x5b74e53f67f0:    1810 tokens, checkpoints:  5,   145.690 MiB
srv        update:    - prompt 0x5b74e492c580:   35435 tokens, checkpoints:  8,   986.641 MiB
srv        update:    - prompt 0x5b74d1dcc750:     937 tokens, checkpoints:  2,    65.775 MiB
srv        update:    - prompt 0x5b74e46f02e0:    1122 tokens, checkpoints:  4,    97.338 MiB
srv  get_availabl: prompt cache update took 64.27 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 53162 | processing task, is_child = 0
slot update_slots: id  2 | task 53162 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 485
slot update_slots: id  2 | task 53162 | n_past = 455, slot.prompt.tokens.size() = 1122, seq_id = 2, pos_min = 345, n_swa = 128
slot update_slots: id  2 | task 53162 | restored context checkpoint (pos_min = 0, pos_max = 573, size = 13.460 MiB)
slot update_slots: id  2 | task 53162 | erased invalidated context checkpoint (pos_min = 345, pos_max = 939, n_swa = 128, size = 13.952 MiB)
slot update_slots: id  2 | task 53162 | erased invalidated context checkpoint (pos_min = 345, pos_max = 1030, n_swa = 128, size = 16.086 MiB)
slot update_slots: id  2 | task 53162 | n_tokens = 455, memory_seq_rm [455, end)
slot update_slots: id  2 | task 53162 | prompt processing progress, n_tokens = 485, batch.n_tokens = 30, progress = 1.000000
slot update_slots: id  2 | task 53162 | prompt done, n_tokens = 485, batch.n_tokens = 30
slot init_sampler: id  2 | task 53162 | init sampler, took 0.10 ms, tokens: text = 485, total = 485
slot print_timing: id  2 | task 53162 | 
prompt eval time =     306.10 ms /    30 tokens (   10.20 ms per token,    98.01 tokens per second)
       eval time =    1437.03 ms /    59 tokens (   24.36 ms per token,    41.06 tokens per second)
      total time =    1743.13 ms /    89 tokens
slot      release: id  2 | task 53162 | stop processing: n_tokens = 543, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.470 (> 0.100 thold), f_keep = 0.893
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 53222 | processing task, is_child = 0
slot update_slots: id  2 | task 53222 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1031
slot update_slots: id  2 | task 53222 | n_tokens = 485, memory_seq_rm [485, end)
slot update_slots: id  2 | task 53222 | prompt processing progress, n_tokens = 967, batch.n_tokens = 482, progress = 0.937924
slot update_slots: id  2 | task 53222 | n_tokens = 967, memory_seq_rm [967, end)
slot update_slots: id  2 | task 53222 | prompt processing progress, n_tokens = 1031, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 53222 | prompt done, n_tokens = 1031, batch.n_tokens = 64
slot init_sampler: id  2 | task 53222 | init sampler, took 0.19 ms, tokens: text = 1031, total = 1031
slot update_slots: id  2 | task 53222 | created context checkpoint 3 of 8 (pos_min = 70, pos_max = 966, size = 21.034 MiB)
slot print_timing: id  2 | task 53222 | 
prompt eval time =     625.41 ms /   546 tokens (    1.15 ms per token,   873.03 tokens per second)
       eval time =    1749.95 ms /    69 tokens (   25.36 ms per token,    39.43 tokens per second)
      total time =    2375.35 ms /   615 tokens
slot      release: id  2 | task 53222 | stop processing: n_tokens = 1099, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.393 (> 0.100 thold), f_keep = 0.938
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 53293 | processing task, is_child = 0
slot update_slots: id  2 | task 53293 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2626
slot update_slots: id  2 | task 53293 | n_tokens = 1031, memory_seq_rm [1031, end)
slot update_slots: id  2 | task 53293 | prompt processing progress, n_tokens = 2562, batch.n_tokens = 1531, progress = 0.975628
slot update_slots: id  2 | task 53293 | n_tokens = 2562, memory_seq_rm [2562, end)
slot update_slots: id  2 | task 53293 | prompt processing progress, n_tokens = 2626, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 53293 | prompt done, n_tokens = 2626, batch.n_tokens = 64
slot init_sampler: id  2 | task 53293 | init sampler, took 0.50 ms, tokens: text = 2626, total = 2626
slot update_slots: id  2 | task 53293 | created context checkpoint 4 of 8 (pos_min = 1665, pos_max = 2561, size = 21.034 MiB)
slot print_timing: id  2 | task 53293 | 
prompt eval time =    1715.61 ms /  1595 tokens (    1.08 ms per token,   929.70 tokens per second)
       eval time =    3932.78 ms /   152 tokens (   25.87 ms per token,    38.65 tokens per second)
      total time =    5648.39 ms /  1747 tokens
slot      release: id  2 | task 53293 | stop processing: n_tokens = 2777, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.615 (> 0.100 thold), f_keep = 0.946
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 53447 | processing task, is_child = 0
slot update_slots: id  2 | task 53447 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4272
slot update_slots: id  2 | task 53447 | n_tokens = 2626, memory_seq_rm [2626, end)
slot update_slots: id  2 | task 53447 | prompt processing progress, n_tokens = 4208, batch.n_tokens = 1582, progress = 0.985019
slot update_slots: id  2 | task 53447 | n_tokens = 4208, memory_seq_rm [4208, end)
slot update_slots: id  2 | task 53447 | prompt processing progress, n_tokens = 4272, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 53447 | prompt done, n_tokens = 4272, batch.n_tokens = 64
slot init_sampler: id  2 | task 53447 | init sampler, took 0.82 ms, tokens: text = 4272, total = 4272
slot update_slots: id  2 | task 53447 | created context checkpoint 5 of 8 (pos_min = 3311, pos_max = 4207, size = 21.034 MiB)
slot print_timing: id  2 | task 53447 | 
prompt eval time =    1952.20 ms /  1646 tokens (    1.19 ms per token,   843.15 tokens per second)
       eval time =   14517.35 ms /   559 tokens (   25.97 ms per token,    38.51 tokens per second)
      total time =   16469.55 ms /  2205 tokens
slot      release: id  2 | task 53447 | stop processing: n_tokens = 4830, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.951 (> 0.100 thold), f_keep = 0.884
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 54008 | processing task, is_child = 0
slot update_slots: id  2 | task 54008 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4493
slot update_slots: id  2 | task 54008 | n_tokens = 4272, memory_seq_rm [4272, end)
slot update_slots: id  2 | task 54008 | prompt processing progress, n_tokens = 4429, batch.n_tokens = 157, progress = 0.985756
slot update_slots: id  2 | task 54008 | n_tokens = 4429, memory_seq_rm [4429, end)
slot update_slots: id  2 | task 54008 | prompt processing progress, n_tokens = 4493, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 54008 | prompt done, n_tokens = 4493, batch.n_tokens = 64
slot init_sampler: id  2 | task 54008 | init sampler, took 0.72 ms, tokens: text = 4493, total = 4493
slot update_slots: id  2 | task 54008 | created context checkpoint 6 of 8 (pos_min = 3933, pos_max = 4428, size = 11.631 MiB)
slot print_timing: id  2 | task 54008 | 
prompt eval time =     434.62 ms /   221 tokens (    1.97 ms per token,   508.49 tokens per second)
       eval time =    7556.83 ms /   302 tokens (   25.02 ms per token,    39.96 tokens per second)
      total time =    7991.45 ms /   523 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 54008 | stop processing: n_tokens = 4794, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.988 (> 0.100 thold), f_keep = 0.937
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 54312 | processing task, is_child = 0
slot update_slots: id  2 | task 54312 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4549
slot update_slots: id  2 | task 54312 | n_tokens = 4493, memory_seq_rm [4493, end)
slot update_slots: id  2 | task 54312 | prompt processing progress, n_tokens = 4549, batch.n_tokens = 56, progress = 1.000000
slot update_slots: id  2 | task 54312 | prompt done, n_tokens = 4549, batch.n_tokens = 56
slot init_sampler: id  2 | task 54312 | init sampler, took 0.89 ms, tokens: text = 4549, total = 4549
slot print_timing: id  2 | task 54312 | 
prompt eval time =     163.50 ms /    56 tokens (    2.92 ms per token,   342.52 tokens per second)
       eval time =    1919.04 ms /    76 tokens (   25.25 ms per token,    39.60 tokens per second)
      total time =    2082.53 ms /   132 tokens
slot      release: id  2 | task 54312 | stop processing: n_tokens = 4624, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.971 (> 0.100 thold), f_keep = 0.984
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 54389 | processing task, is_child = 0
slot update_slots: id  2 | task 54389 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4683
slot update_slots: id  2 | task 54389 | n_tokens = 4549, memory_seq_rm [4549, end)
slot update_slots: id  2 | task 54389 | prompt processing progress, n_tokens = 4619, batch.n_tokens = 70, progress = 0.986334
slot update_slots: id  2 | task 54389 | n_tokens = 4619, memory_seq_rm [4619, end)
slot update_slots: id  2 | task 54389 | prompt processing progress, n_tokens = 4683, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 54389 | prompt done, n_tokens = 4683, batch.n_tokens = 64
slot init_sampler: id  2 | task 54389 | init sampler, took 0.74 ms, tokens: text = 4683, total = 4683
slot update_slots: id  2 | task 54389 | created context checkpoint 7 of 8 (pos_min = 4045, pos_max = 4618, size = 13.460 MiB)
slot print_timing: id  2 | task 54389 | 
prompt eval time =     358.38 ms /   134 tokens (    2.67 ms per token,   373.90 tokens per second)
       eval time =    4648.65 ms /   188 tokens (   24.73 ms per token,    40.44 tokens per second)
      total time =    5007.03 ms /   322 tokens
slot      release: id  2 | task 54389 | stop processing: n_tokens = 4870, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.986 (> 0.100 thold), f_keep = 0.962
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 54579 | processing task, is_child = 0
slot update_slots: id  2 | task 54579 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4751
slot update_slots: id  2 | task 54579 | n_tokens = 4683, memory_seq_rm [4683, end)
slot update_slots: id  2 | task 54579 | prompt processing progress, n_tokens = 4687, batch.n_tokens = 4, progress = 0.986529
slot update_slots: id  2 | task 54579 | n_tokens = 4687, memory_seq_rm [4687, end)
slot update_slots: id  2 | task 54579 | prompt processing progress, n_tokens = 4751, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 54579 | prompt done, n_tokens = 4751, batch.n_tokens = 64
slot init_sampler: id  2 | task 54579 | init sampler, took 0.76 ms, tokens: text = 4751, total = 4751
slot update_slots: id  2 | task 54579 | created context checkpoint 8 of 8 (pos_min = 4121, pos_max = 4686, size = 13.272 MiB)
slot print_timing: id  2 | task 54579 | 
prompt eval time =     276.97 ms /    68 tokens (    4.07 ms per token,   245.52 tokens per second)
       eval time =    4741.27 ms /   195 tokens (   24.31 ms per token,    41.13 tokens per second)
      total time =    5018.24 ms /   263 tokens
slot      release: id  2 | task 54579 | stop processing: n_tokens = 4945, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.897 (> 0.100 thold), f_keep = 0.092
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 4945, total state size = 133.519 MiB
srv          load:  - looking for better prompt, base f_keep = 0.092, sim = 0.897
srv        update:  - cache state: 8 prompts, 3791.430 MiB (limits: 8192.000 MiB, 64000 tokens, 263825 est)
srv        update:    - prompt 0x5b74dc0d5ef0:    1042 tokens, checkpoints:  1,    56.513 MiB
srv        update:    - prompt 0x5b74e55a53f0:   26665 tokens, checkpoints:  8,   833.285 MiB
srv        update:    - prompt 0x5b74f4b2e0a0:   50148 tokens, checkpoints:  8,  1348.434 MiB
srv        update:    - prompt 0x5b74e53f67f0:    1810 tokens, checkpoints:  5,   145.690 MiB
srv        update:    - prompt 0x5b74e492c580:   35435 tokens, checkpoints:  8,   986.641 MiB
srv        update:    - prompt 0x5b74d1dcc750:     937 tokens, checkpoints:  2,    65.775 MiB
srv        update:    - prompt 0x5b74e46f02e0:    1122 tokens, checkpoints:  4,    97.338 MiB
srv        update:    - prompt 0x5b74e5014d10:    4945 tokens, checkpoints:  8,   257.754 MiB
srv  get_availabl: prompt cache update took 219.61 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 54776 | processing task, is_child = 0
slot update_slots: id  2 | task 54776 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 507
slot update_slots: id  2 | task 54776 | n_past = 455, slot.prompt.tokens.size() = 4945, seq_id = 2, pos_min = 4196, n_swa = 128
slot update_slots: id  2 | task 54776 | restored context checkpoint (pos_min = 70, pos_max = 966, size = 21.034 MiB)
slot update_slots: id  2 | task 54776 | erased invalidated context checkpoint (pos_min = 1665, pos_max = 2561, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 54776 | erased invalidated context checkpoint (pos_min = 3311, pos_max = 4207, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 54776 | erased invalidated context checkpoint (pos_min = 3933, pos_max = 4428, n_swa = 128, size = 11.631 MiB)
slot update_slots: id  2 | task 54776 | erased invalidated context checkpoint (pos_min = 4045, pos_max = 4618, n_swa = 128, size = 13.460 MiB)
slot update_slots: id  2 | task 54776 | erased invalidated context checkpoint (pos_min = 4121, pos_max = 4686, n_swa = 128, size = 13.272 MiB)
slot update_slots: id  2 | task 54776 | n_tokens = 455, memory_seq_rm [455, end)
slot update_slots: id  2 | task 54776 | prompt processing progress, n_tokens = 507, batch.n_tokens = 52, progress = 1.000000
slot update_slots: id  2 | task 54776 | prompt done, n_tokens = 507, batch.n_tokens = 52
slot init_sampler: id  2 | task 54776 | init sampler, took 0.09 ms, tokens: text = 507, total = 507
slot print_timing: id  2 | task 54776 | 
prompt eval time =     400.44 ms /    52 tokens (    7.70 ms per token,   129.86 tokens per second)
       eval time =     752.88 ms /    32 tokens (   23.53 ms per token,    42.50 tokens per second)
      total time =    1153.31 ms /    84 tokens
slot      release: id  2 | task 54776 | stop processing: n_tokens = 538, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.481 (> 0.100 thold), f_keep = 0.942
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 54809 | processing task, is_child = 0
slot update_slots: id  2 | task 54809 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1053
slot update_slots: id  2 | task 54809 | n_tokens = 507, memory_seq_rm [507, end)
slot update_slots: id  2 | task 54809 | prompt processing progress, n_tokens = 989, batch.n_tokens = 482, progress = 0.939221
slot update_slots: id  2 | task 54809 | n_tokens = 989, memory_seq_rm [989, end)
slot update_slots: id  2 | task 54809 | prompt processing progress, n_tokens = 1053, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 54809 | prompt done, n_tokens = 1053, batch.n_tokens = 64
slot init_sampler: id  2 | task 54809 | init sampler, took 0.20 ms, tokens: text = 1053, total = 1053
slot print_timing: id  2 | task 54809 | 
prompt eval time =     614.01 ms /   546 tokens (    1.12 ms per token,   889.24 tokens per second)
       eval time =    1679.58 ms /    67 tokens (   25.07 ms per token,    39.89 tokens per second)
      total time =    2293.59 ms /   613 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 54809 | stop processing: n_tokens = 1119, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.937 (> 0.100 thold), f_keep = 0.941
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 54878 | processing task, is_child = 0
slot update_slots: id  2 | task 54878 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1124
slot update_slots: id  2 | task 54878 | n_tokens = 1053, memory_seq_rm [1053, end)
slot update_slots: id  2 | task 54878 | prompt processing progress, n_tokens = 1060, batch.n_tokens = 7, progress = 0.943061
slot update_slots: id  2 | task 54878 | n_tokens = 1060, memory_seq_rm [1060, end)
slot update_slots: id  2 | task 54878 | prompt processing progress, n_tokens = 1124, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 54878 | prompt done, n_tokens = 1124, batch.n_tokens = 64
slot init_sampler: id  2 | task 54878 | init sampler, took 0.24 ms, tokens: text = 1124, total = 1124
slot update_slots: id  2 | task 54878 | created context checkpoint 4 of 8 (pos_min = 380, pos_max = 1059, size = 15.946 MiB)
slot print_timing: id  2 | task 54878 | 
prompt eval time =     219.64 ms /    71 tokens (    3.09 ms per token,   323.26 tokens per second)
       eval time =    1383.04 ms /    54 tokens (   25.61 ms per token,    39.04 tokens per second)
      total time =    1602.68 ms /   125 tokens
slot      release: id  2 | task 54878 | stop processing: n_tokens = 1177, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.338 (> 0.100 thold), f_keep = 0.955
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 54934 | processing task, is_child = 0
slot update_slots: id  2 | task 54934 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3329
slot update_slots: id  2 | task 54934 | n_tokens = 1124, memory_seq_rm [1124, end)
slot update_slots: id  2 | task 54934 | prompt processing progress, n_tokens = 3172, batch.n_tokens = 2048, progress = 0.952839
slot update_slots: id  2 | task 54934 | n_tokens = 3172, memory_seq_rm [3172, end)
slot update_slots: id  2 | task 54934 | prompt processing progress, n_tokens = 3265, batch.n_tokens = 93, progress = 0.980775
slot update_slots: id  2 | task 54934 | n_tokens = 3265, memory_seq_rm [3265, end)
slot update_slots: id  2 | task 54934 | prompt processing progress, n_tokens = 3329, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 54934 | prompt done, n_tokens = 3329, batch.n_tokens = 64
slot init_sampler: id  2 | task 54934 | init sampler, took 0.74 ms, tokens: text = 3329, total = 3329
slot update_slots: id  2 | task 54934 | created context checkpoint 5 of 8 (pos_min = 2368, pos_max = 3264, size = 21.034 MiB)
slot print_timing: id  2 | task 54934 | 
prompt eval time =    2478.57 ms /  2205 tokens (    1.12 ms per token,   889.63 tokens per second)
       eval time =    3381.47 ms /   129 tokens (   26.21 ms per token,    38.15 tokens per second)
      total time =    5860.04 ms /  2334 tokens
slot      release: id  2 | task 54934 | stop processing: n_tokens = 3457, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.979 (> 0.100 thold), f_keep = 0.963
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 55066 | processing task, is_child = 0
slot update_slots: id  2 | task 55066 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3400
slot update_slots: id  2 | task 55066 | n_tokens = 3329, memory_seq_rm [3329, end)
slot update_slots: id  2 | task 55066 | prompt processing progress, n_tokens = 3336, batch.n_tokens = 7, progress = 0.981176
slot update_slots: id  2 | task 55066 | n_tokens = 3336, memory_seq_rm [3336, end)
slot update_slots: id  2 | task 55066 | prompt processing progress, n_tokens = 3400, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 55066 | prompt done, n_tokens = 3400, batch.n_tokens = 64
slot init_sampler: id  2 | task 55066 | init sampler, took 0.65 ms, tokens: text = 3400, total = 3400
slot update_slots: id  2 | task 55066 | created context checkpoint 6 of 8 (pos_min = 2560, pos_max = 3335, size = 18.197 MiB)
slot print_timing: id  2 | task 55066 | 
prompt eval time =     232.01 ms /    71 tokens (    3.27 ms per token,   306.01 tokens per second)
       eval time =    2041.36 ms /    78 tokens (   26.17 ms per token,    38.21 tokens per second)
      total time =    2273.37 ms /   149 tokens
slot      release: id  2 | task 55066 | stop processing: n_tokens = 3477, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.860 (> 0.100 thold), f_keep = 0.978
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 55146 | processing task, is_child = 0
slot update_slots: id  2 | task 55146 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3953
slot update_slots: id  2 | task 55146 | n_tokens = 3400, memory_seq_rm [3400, end)
slot update_slots: id  2 | task 55146 | prompt processing progress, n_tokens = 3889, batch.n_tokens = 489, progress = 0.983810
slot update_slots: id  2 | task 55146 | n_tokens = 3889, memory_seq_rm [3889, end)
slot update_slots: id  2 | task 55146 | prompt processing progress, n_tokens = 3953, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 55146 | prompt done, n_tokens = 3953, batch.n_tokens = 64
slot init_sampler: id  2 | task 55146 | init sampler, took 0.90 ms, tokens: text = 3953, total = 3953
slot update_slots: id  2 | task 55146 | created context checkpoint 7 of 8 (pos_min = 2992, pos_max = 3888, size = 21.034 MiB)
slot print_timing: id  2 | task 55146 | 
prompt eval time =     666.10 ms /   553 tokens (    1.20 ms per token,   830.20 tokens per second)
       eval time =    1618.09 ms /    60 tokens (   26.97 ms per token,    37.08 tokens per second)
      total time =    2284.19 ms /   613 tokens
slot      release: id  2 | task 55146 | stop processing: n_tokens = 4012, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.697 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 55208 | processing task, is_child = 0
slot update_slots: id  2 | task 55208 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5670
slot update_slots: id  2 | task 55208 | n_tokens = 3953, memory_seq_rm [3953, end)
slot update_slots: id  2 | task 55208 | prompt processing progress, n_tokens = 5606, batch.n_tokens = 1653, progress = 0.988713
slot update_slots: id  2 | task 55208 | n_tokens = 5606, memory_seq_rm [5606, end)
slot update_slots: id  2 | task 55208 | prompt processing progress, n_tokens = 5670, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 55208 | prompt done, n_tokens = 5670, batch.n_tokens = 64
slot init_sampler: id  2 | task 55208 | init sampler, took 0.93 ms, tokens: text = 5670, total = 5670
slot update_slots: id  2 | task 55208 | created context checkpoint 8 of 8 (pos_min = 4709, pos_max = 5605, size = 21.034 MiB)
slot print_timing: id  2 | task 55208 | 
prompt eval time =    2123.93 ms /  1717 tokens (    1.24 ms per token,   808.41 tokens per second)
       eval time =    3439.64 ms /   129 tokens (   26.66 ms per token,    37.50 tokens per second)
      total time =    5563.57 ms /  1846 tokens
slot      release: id  2 | task 55208 | stop processing: n_tokens = 5798, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.852 (> 0.100 thold), f_keep = 0.978
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 55339 | processing task, is_child = 0
slot update_slots: id  2 | task 55339 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6655
slot update_slots: id  2 | task 55339 | n_tokens = 5670, memory_seq_rm [5670, end)
slot update_slots: id  2 | task 55339 | prompt processing progress, n_tokens = 6591, batch.n_tokens = 921, progress = 0.990383
slot update_slots: id  2 | task 55339 | n_tokens = 6591, memory_seq_rm [6591, end)
slot update_slots: id  2 | task 55339 | prompt processing progress, n_tokens = 6655, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 55339 | prompt done, n_tokens = 6655, batch.n_tokens = 64
slot init_sampler: id  2 | task 55339 | init sampler, took 1.27 ms, tokens: text = 6655, total = 6655
slot update_slots: id  2 | task 55339 | erasing old context checkpoint (pos_min = 0, pos_max = 396, size = 9.310 MiB)
slot update_slots: id  2 | task 55339 | created context checkpoint 8 of 8 (pos_min = 5694, pos_max = 6590, size = 21.034 MiB)
slot print_timing: id  2 | task 55339 | 
prompt eval time =    1242.27 ms /   985 tokens (    1.26 ms per token,   792.90 tokens per second)
       eval time =   27273.92 ms /  1082 tokens (   25.21 ms per token,    39.67 tokens per second)
      total time =   28516.19 ms /  2067 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 55339 | stop processing: n_tokens = 7736, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.349 (> 0.100 thold), f_keep = 0.059
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 7736, total state size = 202.435 MiB
srv          load:  - looking for better prompt, base f_keep = 0.059, sim = 0.349
srv        update:  - cache state: 9 prompts, 4146.638 MiB (limits: 8192.000 MiB, 64000 tokens, 256508 est)
srv        update:    - prompt 0x5b74dc0d5ef0:    1042 tokens, checkpoints:  1,    56.513 MiB
srv        update:    - prompt 0x5b74e55a53f0:   26665 tokens, checkpoints:  8,   833.285 MiB
srv        update:    - prompt 0x5b74f4b2e0a0:   50148 tokens, checkpoints:  8,  1348.434 MiB
srv        update:    - prompt 0x5b74e53f67f0:    1810 tokens, checkpoints:  5,   145.690 MiB
srv        update:    - prompt 0x5b74e492c580:   35435 tokens, checkpoints:  8,   986.641 MiB
srv        update:    - prompt 0x5b74d1dcc750:     937 tokens, checkpoints:  2,    65.775 MiB
srv        update:    - prompt 0x5b74e46f02e0:    1122 tokens, checkpoints:  4,    97.338 MiB
srv        update:    - prompt 0x5b74e5014d10:    4945 tokens, checkpoints:  8,   257.754 MiB
srv        update:    - prompt 0x5b74d1ea9d00:    7736 tokens, checkpoints:  8,   355.208 MiB
srv  get_availabl: prompt cache update took 397.87 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 56423 | processing task, is_child = 0
slot update_slots: id  2 | task 56423 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1299
slot update_slots: id  2 | task 56423 | n_past = 453, slot.prompt.tokens.size() = 7736, seq_id = 2, pos_min = 6839, n_swa = 128
slot update_slots: id  2 | task 56423 | restored context checkpoint (pos_min = 70, pos_max = 966, size = 21.034 MiB)
slot update_slots: id  2 | task 56423 | erased invalidated context checkpoint (pos_min = 380, pos_max = 1059, n_swa = 128, size = 15.946 MiB)
slot update_slots: id  2 | task 56423 | erased invalidated context checkpoint (pos_min = 2368, pos_max = 3264, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 56423 | erased invalidated context checkpoint (pos_min = 2560, pos_max = 3335, n_swa = 128, size = 18.197 MiB)
slot update_slots: id  2 | task 56423 | erased invalidated context checkpoint (pos_min = 2992, pos_max = 3888, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 56423 | erased invalidated context checkpoint (pos_min = 4709, pos_max = 5605, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 56423 | erased invalidated context checkpoint (pos_min = 5694, pos_max = 6590, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 56423 | n_tokens = 453, memory_seq_rm [453, end)
slot update_slots: id  2 | task 56423 | prompt processing progress, n_tokens = 1235, batch.n_tokens = 782, progress = 0.950731
slot update_slots: id  2 | task 56423 | n_tokens = 1235, memory_seq_rm [1235, end)
slot update_slots: id  2 | task 56423 | prompt processing progress, n_tokens = 1299, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 56423 | prompt done, n_tokens = 1299, batch.n_tokens = 64
slot init_sampler: id  2 | task 56423 | init sampler, took 0.24 ms, tokens: text = 1299, total = 1299
slot update_slots: id  2 | task 56423 | created context checkpoint 3 of 8 (pos_min = 465, pos_max = 1234, size = 18.056 MiB)
slot print_timing: id  2 | task 56423 | 
prompt eval time =    1267.80 ms /   846 tokens (    1.50 ms per token,   667.30 tokens per second)
       eval time =     958.77 ms /    39 tokens (   24.58 ms per token,    40.68 tokens per second)
      total time =    2226.58 ms /   885 tokens
slot      release: id  2 | task 56423 | stop processing: n_tokens = 1337, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.704 (> 0.100 thold), f_keep = 0.972
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 56464 | processing task, is_child = 0
slot update_slots: id  2 | task 56464 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1845
slot update_slots: id  2 | task 56464 | n_tokens = 1299, memory_seq_rm [1299, end)
slot update_slots: id  2 | task 56464 | prompt processing progress, n_tokens = 1781, batch.n_tokens = 482, progress = 0.965312
slot update_slots: id  2 | task 56464 | n_tokens = 1781, memory_seq_rm [1781, end)
slot update_slots: id  2 | task 56464 | prompt processing progress, n_tokens = 1845, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 56464 | prompt done, n_tokens = 1845, batch.n_tokens = 64
slot init_sampler: id  2 | task 56464 | init sampler, took 0.35 ms, tokens: text = 1845, total = 1845
slot update_slots: id  2 | task 56464 | created context checkpoint 4 of 8 (pos_min = 884, pos_max = 1780, size = 21.034 MiB)
slot print_timing: id  2 | task 56464 | 
prompt eval time =     625.64 ms /   546 tokens (    1.15 ms per token,   872.70 tokens per second)
       eval time =    1269.60 ms /    51 tokens (   24.89 ms per token,    40.17 tokens per second)
      total time =    1895.25 ms /   597 tokens
slot      release: id  2 | task 56464 | stop processing: n_tokens = 1895, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.652 (> 0.100 thold), f_keep = 0.974
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 56517 | processing task, is_child = 0
slot update_slots: id  2 | task 56517 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2830
slot update_slots: id  2 | task 56517 | n_tokens = 1845, memory_seq_rm [1845, end)
slot update_slots: id  2 | task 56517 | prompt processing progress, n_tokens = 2766, batch.n_tokens = 921, progress = 0.977385
slot update_slots: id  2 | task 56517 | n_tokens = 2766, memory_seq_rm [2766, end)
slot update_slots: id  2 | task 56517 | prompt processing progress, n_tokens = 2830, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 56517 | prompt done, n_tokens = 2830, batch.n_tokens = 64
slot init_sampler: id  2 | task 56517 | init sampler, took 0.57 ms, tokens: text = 2830, total = 2830
slot update_slots: id  2 | task 56517 | created context checkpoint 5 of 8 (pos_min = 1869, pos_max = 2765, size = 21.034 MiB)
slot print_timing: id  2 | task 56517 | 
prompt eval time =    1113.62 ms /   985 tokens (    1.13 ms per token,   884.50 tokens per second)
       eval time =   14149.82 ms /   552 tokens (   25.63 ms per token,    39.01 tokens per second)
      total time =   15263.45 ms /  1537 tokens
slot      release: id  2 | task 56517 | stop processing: n_tokens = 3381, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.843 (> 0.100 thold), f_keep = 0.837
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 57071 | processing task, is_child = 0
slot update_slots: id  2 | task 57071 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3357
slot update_slots: id  2 | task 57071 | n_tokens = 2830, memory_seq_rm [2830, end)
slot update_slots: id  2 | task 57071 | prompt processing progress, n_tokens = 3293, batch.n_tokens = 463, progress = 0.980935
slot update_slots: id  2 | task 57071 | n_tokens = 3293, memory_seq_rm [3293, end)
slot update_slots: id  2 | task 57071 | prompt processing progress, n_tokens = 3357, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 57071 | prompt done, n_tokens = 3357, batch.n_tokens = 64
slot init_sampler: id  2 | task 57071 | init sampler, took 0.62 ms, tokens: text = 3357, total = 3357
slot update_slots: id  2 | task 57071 | created context checkpoint 6 of 8 (pos_min = 2583, pos_max = 3292, size = 16.649 MiB)
slot print_timing: id  2 | task 57071 | 
prompt eval time =     693.92 ms /   527 tokens (    1.32 ms per token,   759.45 tokens per second)
       eval time =    1652.57 ms /    63 tokens (   26.23 ms per token,    38.12 tokens per second)
      total time =    2346.49 ms /   590 tokens
slot      release: id  2 | task 57071 | stop processing: n_tokens = 3419, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.773 (> 0.100 thold), f_keep = 0.982
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 57136 | processing task, is_child = 0
slot update_slots: id  2 | task 57136 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4342
slot update_slots: id  2 | task 57136 | n_tokens = 3357, memory_seq_rm [3357, end)
slot update_slots: id  2 | task 57136 | prompt processing progress, n_tokens = 4278, batch.n_tokens = 921, progress = 0.985260
slot update_slots: id  2 | task 57136 | n_tokens = 4278, memory_seq_rm [4278, end)
slot update_slots: id  2 | task 57136 | prompt processing progress, n_tokens = 4342, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 57136 | prompt done, n_tokens = 4342, batch.n_tokens = 64
slot init_sampler: id  2 | task 57136 | init sampler, took 0.98 ms, tokens: text = 4342, total = 4342
slot update_slots: id  2 | task 57136 | created context checkpoint 7 of 8 (pos_min = 3381, pos_max = 4277, size = 21.034 MiB)
slot print_timing: id  2 | task 57136 | 
prompt eval time =    1163.32 ms /   985 tokens (    1.18 ms per token,   846.71 tokens per second)
       eval time =   13769.73 ms /   541 tokens (   25.45 ms per token,    39.29 tokens per second)
      total time =   14933.05 ms /  1526 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 57136 | stop processing: n_tokens = 4882, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.892 (> 0.100 thold), f_keep = 0.889
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 57679 | processing task, is_child = 0
slot update_slots: id  2 | task 57679 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4869
slot update_slots: id  2 | task 57679 | n_tokens = 4342, memory_seq_rm [4342, end)
slot update_slots: id  2 | task 57679 | prompt processing progress, n_tokens = 4805, batch.n_tokens = 463, progress = 0.986856
slot update_slots: id  2 | task 57679 | n_tokens = 4805, memory_seq_rm [4805, end)
slot update_slots: id  2 | task 57679 | prompt processing progress, n_tokens = 4869, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 57679 | prompt done, n_tokens = 4869, batch.n_tokens = 64
slot init_sampler: id  2 | task 57679 | init sampler, took 1.18 ms, tokens: text = 4869, total = 4869
slot update_slots: id  2 | task 57679 | created context checkpoint 8 of 8 (pos_min = 4190, pos_max = 4804, size = 14.421 MiB)
slot print_timing: id  2 | task 57679 | 
prompt eval time =     689.25 ms /   527 tokens (    1.31 ms per token,   764.60 tokens per second)
       eval time =    1414.78 ms /    55 tokens (   25.72 ms per token,    38.88 tokens per second)
      total time =    2104.03 ms /   582 tokens
slot      release: id  2 | task 57679 | stop processing: n_tokens = 4923, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.942 (> 0.100 thold), f_keep = 0.989
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 57736 | processing task, is_child = 0
slot update_slots: id  2 | task 57736 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5171
slot update_slots: id  2 | task 57736 | n_tokens = 4869, memory_seq_rm [4869, end)
slot update_slots: id  2 | task 57736 | prompt processing progress, n_tokens = 5107, batch.n_tokens = 238, progress = 0.987623
slot update_slots: id  2 | task 57736 | n_tokens = 5107, memory_seq_rm [5107, end)
slot update_slots: id  2 | task 57736 | prompt processing progress, n_tokens = 5171, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 57736 | prompt done, n_tokens = 5171, batch.n_tokens = 64
slot init_sampler: id  2 | task 57736 | init sampler, took 1.00 ms, tokens: text = 5171, total = 5171
slot update_slots: id  2 | task 57736 | erasing old context checkpoint (pos_min = 0, pos_max = 573, size = 13.460 MiB)
slot update_slots: id  2 | task 57736 | created context checkpoint 8 of 8 (pos_min = 4342, pos_max = 5106, size = 17.939 MiB)
slot print_timing: id  2 | task 57736 | 
prompt eval time =     520.44 ms /   302 tokens (    1.72 ms per token,   580.28 tokens per second)
       eval time =    1444.07 ms /    58 tokens (   24.90 ms per token,    40.16 tokens per second)
      total time =    1964.51 ms /   360 tokens
slot      release: id  2 | task 57736 | stop processing: n_tokens = 5228, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.874 (> 0.100 thold), f_keep = 0.989
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 57796 | processing task, is_child = 0
slot update_slots: id  2 | task 57796 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5918
slot update_slots: id  2 | task 57796 | n_tokens = 5171, memory_seq_rm [5171, end)
slot update_slots: id  2 | task 57796 | prompt processing progress, n_tokens = 5854, batch.n_tokens = 683, progress = 0.989186
slot update_slots: id  2 | task 57796 | n_tokens = 5854, memory_seq_rm [5854, end)
slot update_slots: id  2 | task 57796 | prompt processing progress, n_tokens = 5918, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 57796 | prompt done, n_tokens = 5918, batch.n_tokens = 64
slot init_sampler: id  2 | task 57796 | init sampler, took 0.98 ms, tokens: text = 5918, total = 5918
slot update_slots: id  2 | task 57796 | erasing old context checkpoint (pos_min = 70, pos_max = 966, size = 21.034 MiB)
slot update_slots: id  2 | task 57796 | created context checkpoint 8 of 8 (pos_min = 4957, pos_max = 5853, size = 21.034 MiB)
slot print_timing: id  2 | task 57796 | 
prompt eval time =     981.14 ms /   747 tokens (    1.31 ms per token,   761.36 tokens per second)
       eval time =    1511.64 ms /    61 tokens (   24.78 ms per token,    40.35 tokens per second)
      total time =    2492.77 ms /   808 tokens
slot      release: id  2 | task 57796 | stop processing: n_tokens = 5978, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.857 (> 0.100 thold), f_keep = 0.990
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 57859 | processing task, is_child = 0
slot update_slots: id  2 | task 57859 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6903
slot update_slots: id  2 | task 57859 | n_tokens = 5918, memory_seq_rm [5918, end)
slot update_slots: id  2 | task 57859 | prompt processing progress, n_tokens = 6839, batch.n_tokens = 921, progress = 0.990729
slot update_slots: id  2 | task 57859 | n_tokens = 6839, memory_seq_rm [6839, end)
slot update_slots: id  2 | task 57859 | prompt processing progress, n_tokens = 6903, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 57859 | prompt done, n_tokens = 6903, batch.n_tokens = 64
slot init_sampler: id  2 | task 57859 | init sampler, took 1.08 ms, tokens: text = 6903, total = 6903
slot update_slots: id  2 | task 57859 | erasing old context checkpoint (pos_min = 465, pos_max = 1234, size = 18.056 MiB)
slot update_slots: id  2 | task 57859 | created context checkpoint 8 of 8 (pos_min = 5942, pos_max = 6838, size = 21.034 MiB)
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv          stop: cancel task, id_task = 57859
slot      release: id  2 | task 57859 | stop processing: n_tokens = 7117, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.494 (> 0.100 thold), f_keep = 0.181
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 7117, total state size = 187.920 MiB
srv          load:  - looking for better prompt, base f_keep = 0.181, sim = 0.494
srv        update:  - cache state: 10 prompts, 4488.737 MiB (limits: 8192.000 MiB, 64000 tokens, 249948 est)
srv        update:    - prompt 0x5b74dc0d5ef0:    1042 tokens, checkpoints:  1,    56.513 MiB
srv        update:    - prompt 0x5b74e55a53f0:   26665 tokens, checkpoints:  8,   833.285 MiB
srv        update:    - prompt 0x5b74f4b2e0a0:   50148 tokens, checkpoints:  8,  1348.434 MiB
srv        update:    - prompt 0x5b74e53f67f0:    1810 tokens, checkpoints:  5,   145.690 MiB
srv        update:    - prompt 0x5b74e492c580:   35435 tokens, checkpoints:  8,   986.641 MiB
srv        update:    - prompt 0x5b74d1dcc750:     937 tokens, checkpoints:  2,    65.775 MiB
srv        update:    - prompt 0x5b74e46f02e0:    1122 tokens, checkpoints:  4,    97.338 MiB
srv        update:    - prompt 0x5b74e5014d10:    4945 tokens, checkpoints:  8,   257.754 MiB
srv        update:    - prompt 0x5b74d1ea9d00:    7736 tokens, checkpoints:  8,   355.208 MiB
srv        update:    - prompt 0x5b74e47a0060:    7117 tokens, checkpoints:  8,   342.100 MiB
srv  get_availabl: prompt cache update took 342.07 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 58077 | processing task, is_child = 0
slot update_slots: id  2 | task 58077 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 2599
slot update_slots: id  2 | task 58077 | n_past = 1285, slot.prompt.tokens.size() = 7117, seq_id = 2, pos_min = 6220, n_swa = 128
slot update_slots: id  2 | task 58077 | restored context checkpoint (pos_min = 884, pos_max = 1780, size = 21.034 MiB)
slot update_slots: id  2 | task 58077 | erased invalidated context checkpoint (pos_min = 1869, pos_max = 2765, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 58077 | erased invalidated context checkpoint (pos_min = 2583, pos_max = 3292, n_swa = 128, size = 16.649 MiB)
slot update_slots: id  2 | task 58077 | erased invalidated context checkpoint (pos_min = 3381, pos_max = 4277, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 58077 | erased invalidated context checkpoint (pos_min = 4190, pos_max = 4804, n_swa = 128, size = 14.421 MiB)
slot update_slots: id  2 | task 58077 | erased invalidated context checkpoint (pos_min = 4342, pos_max = 5106, n_swa = 128, size = 17.939 MiB)
slot update_slots: id  2 | task 58077 | erased invalidated context checkpoint (pos_min = 4957, pos_max = 5853, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 58077 | erased invalidated context checkpoint (pos_min = 5942, pos_max = 6838, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 58077 | n_tokens = 1285, memory_seq_rm [1285, end)
slot update_slots: id  2 | task 58077 | prompt processing progress, n_tokens = 2535, batch.n_tokens = 1250, progress = 0.975375
slot update_slots: id  2 | task 58077 | n_tokens = 2535, memory_seq_rm [2535, end)
slot update_slots: id  2 | task 58077 | prompt processing progress, n_tokens = 2599, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 58077 | prompt done, n_tokens = 2599, batch.n_tokens = 64
slot init_sampler: id  2 | task 58077 | init sampler, took 0.47 ms, tokens: text = 2599, total = 2599
slot update_slots: id  2 | task 58077 | created context checkpoint 2 of 8 (pos_min = 1638, pos_max = 2534, size = 21.034 MiB)
slot print_timing: id  2 | task 58077 | 
prompt eval time =    1795.06 ms /  1314 tokens (    1.37 ms per token,   732.01 tokens per second)
       eval time =    1865.55 ms /    78 tokens (   23.92 ms per token,    41.81 tokens per second)
      total time =    3660.61 ms /  1392 tokens
slot      release: id  2 | task 58077 | stop processing: n_tokens = 2676, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.725 (> 0.100 thold), f_keep = 0.971
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 58157 | processing task, is_child = 0
slot update_slots: id  2 | task 58157 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 3584
slot update_slots: id  2 | task 58157 | n_tokens = 2599, memory_seq_rm [2599, end)
slot update_slots: id  2 | task 58157 | prompt processing progress, n_tokens = 3520, batch.n_tokens = 921, progress = 0.982143
slot update_slots: id  2 | task 58157 | n_tokens = 3520, memory_seq_rm [3520, end)
slot update_slots: id  2 | task 58157 | prompt processing progress, n_tokens = 3584, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 58157 | prompt done, n_tokens = 3584, batch.n_tokens = 64
slot init_sampler: id  2 | task 58157 | init sampler, took 0.57 ms, tokens: text = 3584, total = 3584
slot update_slots: id  2 | task 58157 | created context checkpoint 3 of 8 (pos_min = 2623, pos_max = 3519, size = 21.034 MiB)
slot print_timing: id  2 | task 58157 | 
prompt eval time =    1105.98 ms /   985 tokens (    1.12 ms per token,   890.61 tokens per second)
       eval time =   13171.11 ms /   536 tokens (   24.57 ms per token,    40.70 tokens per second)
      total time =   14277.09 ms /  1521 tokens
slot      release: id  2 | task 58157 | stop processing: n_tokens = 4119, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.872 (> 0.100 thold), f_keep = 0.870
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 58695 | processing task, is_child = 0
slot update_slots: id  2 | task 58695 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 4111
slot update_slots: id  2 | task 58695 | n_tokens = 3584, memory_seq_rm [3584, end)
slot update_slots: id  2 | task 58695 | prompt processing progress, n_tokens = 4047, batch.n_tokens = 463, progress = 0.984432
slot update_slots: id  2 | task 58695 | n_tokens = 4047, memory_seq_rm [4047, end)
slot update_slots: id  2 | task 58695 | prompt processing progress, n_tokens = 4111, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 58695 | prompt done, n_tokens = 4111, batch.n_tokens = 64
slot init_sampler: id  2 | task 58695 | init sampler, took 0.66 ms, tokens: text = 4111, total = 4111
slot update_slots: id  2 | task 58695 | created context checkpoint 4 of 8 (pos_min = 3457, pos_max = 4046, size = 13.835 MiB)
slot print_timing: id  2 | task 58695 | 
prompt eval time =     678.16 ms /   527 tokens (    1.29 ms per token,   777.11 tokens per second)
       eval time =    1330.46 ms /    52 tokens (   25.59 ms per token,    39.08 tokens per second)
      total time =    2008.62 ms /   579 tokens
slot      release: id  2 | task 58695 | stop processing: n_tokens = 4162, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.807 (> 0.100 thold), f_keep = 0.988
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 58749 | processing task, is_child = 0
slot update_slots: id  2 | task 58749 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5096
slot update_slots: id  2 | task 58749 | n_tokens = 4111, memory_seq_rm [4111, end)
slot update_slots: id  2 | task 58749 | prompt processing progress, n_tokens = 5032, batch.n_tokens = 921, progress = 0.987441
slot update_slots: id  2 | task 58749 | n_tokens = 5032, memory_seq_rm [5032, end)
slot update_slots: id  2 | task 58749 | prompt processing progress, n_tokens = 5096, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 58749 | prompt done, n_tokens = 5096, batch.n_tokens = 64
slot init_sampler: id  2 | task 58749 | init sampler, took 1.26 ms, tokens: text = 5096, total = 5096
slot update_slots: id  2 | task 58749 | created context checkpoint 5 of 8 (pos_min = 4135, pos_max = 5031, size = 21.034 MiB)
slot print_timing: id  2 | task 58749 | 
prompt eval time =    1132.66 ms /   985 tokens (    1.15 ms per token,   869.64 tokens per second)
       eval time =   10375.80 ms /   402 tokens (   25.81 ms per token,    38.74 tokens per second)
      total time =   11508.46 ms /  1387 tokens
slot      release: id  2 | task 58749 | stop processing: n_tokens = 5497, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.939 (> 0.100 thold), f_keep = 0.927
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 59153 | processing task, is_child = 0
slot update_slots: id  2 | task 59153 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 5427
slot update_slots: id  2 | task 59153 | n_tokens = 5096, memory_seq_rm [5096, end)
slot update_slots: id  2 | task 59153 | prompt processing progress, n_tokens = 5363, batch.n_tokens = 267, progress = 0.988207
slot update_slots: id  2 | task 59153 | n_tokens = 5363, memory_seq_rm [5363, end)
slot update_slots: id  2 | task 59153 | prompt processing progress, n_tokens = 5427, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 59153 | prompt done, n_tokens = 5427, batch.n_tokens = 64
slot init_sampler: id  2 | task 59153 | init sampler, took 1.01 ms, tokens: text = 5427, total = 5427
slot update_slots: id  2 | task 59153 | created context checkpoint 6 of 8 (pos_min = 4621, pos_max = 5362, size = 17.399 MiB)
slot print_timing: id  2 | task 59153 | 
prompt eval time =     535.98 ms /   331 tokens (    1.62 ms per token,   617.56 tokens per second)
       eval time =    1350.17 ms /    52 tokens (   25.96 ms per token,    38.51 tokens per second)
      total time =    1886.15 ms /   383 tokens
slot      release: id  2 | task 59153 | stop processing: n_tokens = 5478, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.846 (> 0.100 thold), f_keep = 0.991
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 59207 | processing task, is_child = 0
slot update_slots: id  2 | task 59207 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6412
slot update_slots: id  2 | task 59207 | n_tokens = 5427, memory_seq_rm [5427, end)
slot update_slots: id  2 | task 59207 | prompt processing progress, n_tokens = 6348, batch.n_tokens = 921, progress = 0.990019
slot update_slots: id  2 | task 59207 | n_tokens = 6348, memory_seq_rm [6348, end)
slot update_slots: id  2 | task 59207 | prompt processing progress, n_tokens = 6412, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 59207 | prompt done, n_tokens = 6412, batch.n_tokens = 64
slot init_sampler: id  2 | task 59207 | init sampler, took 1.10 ms, tokens: text = 6412, total = 6412
slot update_slots: id  2 | task 59207 | created context checkpoint 7 of 8 (pos_min = 5451, pos_max = 6347, size = 21.034 MiB)
slot print_timing: id  2 | task 59207 | 
prompt eval time =    1193.35 ms /   985 tokens (    1.21 ms per token,   825.41 tokens per second)
       eval time =    1667.78 ms /    63 tokens (   26.47 ms per token,    37.77 tokens per second)
      total time =    2861.13 ms /  1048 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 59207 | stop processing: n_tokens = 6474, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.970 (> 0.100 thold), f_keep = 0.990
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 59272 | processing task, is_child = 0
slot update_slots: id  2 | task 59272 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 6613
slot update_slots: id  2 | task 59272 | n_tokens = 6412, memory_seq_rm [6412, end)
slot update_slots: id  2 | task 59272 | prompt processing progress, n_tokens = 6549, batch.n_tokens = 137, progress = 0.990322
slot update_slots: id  2 | task 59272 | n_tokens = 6549, memory_seq_rm [6549, end)
slot update_slots: id  2 | task 59272 | prompt processing progress, n_tokens = 6613, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 59272 | prompt done, n_tokens = 6613, batch.n_tokens = 64
slot init_sampler: id  2 | task 59272 | init sampler, took 1.29 ms, tokens: text = 6613, total = 6613
slot update_slots: id  2 | task 59272 | created context checkpoint 8 of 8 (pos_min = 5652, pos_max = 6548, size = 21.034 MiB)
slot print_timing: id  2 | task 59272 | 
prompt eval time =     427.35 ms /   201 tokens (    2.13 ms per token,   470.34 tokens per second)
       eval time =   22994.46 ms /   907 tokens (   25.35 ms per token,    39.44 tokens per second)
      total time =   23421.80 ms /  1108 tokens
slot      release: id  2 | task 59272 | stop processing: n_tokens = 7519, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.888 (> 0.100 thold), f_keep = 0.880
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 60181 | processing task, is_child = 0
slot update_slots: id  2 | task 60181 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7447
slot update_slots: id  2 | task 60181 | n_past = 6613, slot.prompt.tokens.size() = 7519, seq_id = 2, pos_min = 6622, n_swa = 128
slot update_slots: id  2 | task 60181 | restored context checkpoint (pos_min = 5652, pos_max = 6548, size = 21.034 MiB)
slot update_slots: id  2 | task 60181 | n_tokens = 6548, memory_seq_rm [6548, end)
slot update_slots: id  2 | task 60181 | prompt processing progress, n_tokens = 7383, batch.n_tokens = 835, progress = 0.991406
slot update_slots: id  2 | task 60181 | n_tokens = 7383, memory_seq_rm [7383, end)
slot update_slots: id  2 | task 60181 | prompt processing progress, n_tokens = 7447, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 60181 | prompt done, n_tokens = 7447, batch.n_tokens = 64
slot init_sampler: id  2 | task 60181 | init sampler, took 1.22 ms, tokens: text = 7447, total = 7447
slot update_slots: id  2 | task 60181 | erasing old context checkpoint (pos_min = 884, pos_max = 1780, size = 21.034 MiB)
slot update_slots: id  2 | task 60181 | created context checkpoint 8 of 8 (pos_min = 6486, pos_max = 7382, size = 21.034 MiB)
slot print_timing: id  2 | task 60181 | 
prompt eval time =    1256.45 ms /   899 tokens (    1.40 ms per token,   715.51 tokens per second)
       eval time =    1265.47 ms /    51 tokens (   24.81 ms per token,    40.30 tokens per second)
      total time =    2521.92 ms /   950 tokens
slot      release: id  2 | task 60181 | stop processing: n_tokens = 7497, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.944 (> 0.100 thold), f_keep = 0.993
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 60234 | processing task, is_child = 0
slot update_slots: id  2 | task 60234 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 7885
slot update_slots: id  2 | task 60234 | n_tokens = 7447, memory_seq_rm [7447, end)
slot update_slots: id  2 | task 60234 | prompt processing progress, n_tokens = 7821, batch.n_tokens = 374, progress = 0.991883
slot update_slots: id  2 | task 60234 | n_tokens = 7821, memory_seq_rm [7821, end)
slot update_slots: id  2 | task 60234 | prompt processing progress, n_tokens = 7885, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 60234 | prompt done, n_tokens = 7885, batch.n_tokens = 64
slot init_sampler: id  2 | task 60234 | init sampler, took 1.24 ms, tokens: text = 7885, total = 7885
slot update_slots: id  2 | task 60234 | erasing old context checkpoint (pos_min = 1638, pos_max = 2534, size = 21.034 MiB)
slot update_slots: id  2 | task 60234 | created context checkpoint 8 of 8 (pos_min = 6924, pos_max = 7820, size = 21.034 MiB)
slot print_timing: id  2 | task 60234 | 
prompt eval time =     623.17 ms /   438 tokens (    1.42 ms per token,   702.86 tokens per second)
       eval time =    5522.33 ms /   220 tokens (   25.10 ms per token,    39.84 tokens per second)
      total time =    6145.49 ms /   658 tokens
slot      release: id  2 | task 60234 | stop processing: n_tokens = 8104, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.978 (> 0.100 thold), f_keep = 0.973
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 60456 | processing task, is_child = 0
slot update_slots: id  2 | task 60456 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8062
slot update_slots: id  2 | task 60456 | n_tokens = 7885, memory_seq_rm [7885, end)
slot update_slots: id  2 | task 60456 | prompt processing progress, n_tokens = 7998, batch.n_tokens = 113, progress = 0.992061
slot update_slots: id  2 | task 60456 | n_tokens = 7998, memory_seq_rm [7998, end)
slot update_slots: id  2 | task 60456 | prompt processing progress, n_tokens = 8062, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 60456 | prompt done, n_tokens = 8062, batch.n_tokens = 64
slot init_sampler: id  2 | task 60456 | init sampler, took 1.29 ms, tokens: text = 8062, total = 8062
slot update_slots: id  2 | task 60456 | erasing old context checkpoint (pos_min = 2623, pos_max = 3519, size = 21.034 MiB)
slot update_slots: id  2 | task 60456 | created context checkpoint 8 of 8 (pos_min = 7207, pos_max = 7997, size = 18.548 MiB)
slot print_timing: id  2 | task 60456 | 
prompt eval time =     460.07 ms /   177 tokens (    2.60 ms per token,   384.72 tokens per second)
       eval time =    5835.37 ms /   234 tokens (   24.94 ms per token,    40.10 tokens per second)
      total time =    6295.44 ms /   411 tokens
slot      release: id  2 | task 60456 | stop processing: n_tokens = 8295, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.972 (> 0.100 thold), f_keep = 0.972
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 60692 | processing task, is_child = 0
slot update_slots: id  2 | task 60692 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8298
slot update_slots: id  2 | task 60692 | n_tokens = 8062, memory_seq_rm [8062, end)
slot update_slots: id  2 | task 60692 | prompt processing progress, n_tokens = 8234, batch.n_tokens = 172, progress = 0.992287
slot update_slots: id  2 | task 60692 | n_tokens = 8234, memory_seq_rm [8234, end)
slot update_slots: id  2 | task 60692 | prompt processing progress, n_tokens = 8298, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 60692 | prompt done, n_tokens = 8298, batch.n_tokens = 64
slot init_sampler: id  2 | task 60692 | init sampler, took 1.33 ms, tokens: text = 8298, total = 8298
slot update_slots: id  2 | task 60692 | erasing old context checkpoint (pos_min = 3457, pos_max = 4046, size = 13.835 MiB)
slot update_slots: id  2 | task 60692 | created context checkpoint 8 of 8 (pos_min = 7398, pos_max = 8233, size = 19.604 MiB)
slot print_timing: id  2 | task 60692 | 
prompt eval time =     438.17 ms /   236 tokens (    1.86 ms per token,   538.60 tokens per second)
       eval time =    7198.75 ms /   285 tokens (   25.26 ms per token,    39.59 tokens per second)
      total time =    7636.92 ms /   521 tokens
slot      release: id  2 | task 60692 | stop processing: n_tokens = 8582, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.982 (> 0.100 thold), f_keep = 0.967
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 60979 | processing task, is_child = 0
slot update_slots: id  2 | task 60979 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8448
slot update_slots: id  2 | task 60979 | n_tokens = 8298, memory_seq_rm [8298, end)
slot update_slots: id  2 | task 60979 | prompt processing progress, n_tokens = 8384, batch.n_tokens = 86, progress = 0.992424
slot update_slots: id  2 | task 60979 | n_tokens = 8384, memory_seq_rm [8384, end)
slot update_slots: id  2 | task 60979 | prompt processing progress, n_tokens = 8448, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 60979 | prompt done, n_tokens = 8448, batch.n_tokens = 64
slot init_sampler: id  2 | task 60979 | init sampler, took 1.42 ms, tokens: text = 8448, total = 8448
slot update_slots: id  2 | task 60979 | erasing old context checkpoint (pos_min = 4135, pos_max = 5031, size = 21.034 MiB)
slot update_slots: id  2 | task 60979 | created context checkpoint 8 of 8 (pos_min = 7685, pos_max = 8383, size = 16.391 MiB)
slot print_timing: id  2 | task 60979 | 
prompt eval time =     404.42 ms /   150 tokens (    2.70 ms per token,   370.91 tokens per second)
       eval time =    6728.48 ms /   272 tokens (   24.74 ms per token,    40.43 tokens per second)
      total time =    7132.89 ms /   422 tokens
slot      release: id  2 | task 60979 | stop processing: n_tokens = 8719, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.985 (> 0.100 thold), f_keep = 0.969
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 61253 | processing task, is_child = 0
slot update_slots: id  2 | task 61253 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 8573
slot update_slots: id  2 | task 61253 | n_tokens = 8448, memory_seq_rm [8448, end)
slot update_slots: id  2 | task 61253 | prompt processing progress, n_tokens = 8509, batch.n_tokens = 61, progress = 0.992535
slot update_slots: id  2 | task 61253 | n_tokens = 8509, memory_seq_rm [8509, end)
slot update_slots: id  2 | task 61253 | prompt processing progress, n_tokens = 8573, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 61253 | prompt done, n_tokens = 8573, batch.n_tokens = 64
slot init_sampler: id  2 | task 61253 | init sampler, took 1.74 ms, tokens: text = 8573, total = 8573
slot update_slots: id  2 | task 61253 | erasing old context checkpoint (pos_min = 4621, pos_max = 5362, size = 17.399 MiB)
slot update_slots: id  2 | task 61253 | created context checkpoint 8 of 8 (pos_min = 7848, pos_max = 8508, size = 15.500 MiB)
slot print_timing: id  2 | task 61253 | 
prompt eval time =     365.80 ms /   125 tokens (    2.93 ms per token,   341.72 tokens per second)
       eval time =    1397.34 ms /    54 tokens (   25.88 ms per token,    38.64 tokens per second)
      total time =    1763.14 ms /   179 tokens
slot      release: id  2 | task 61253 | stop processing: n_tokens = 8626, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.891 (> 0.100 thold), f_keep = 0.994
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 61309 | processing task, is_child = 0
slot update_slots: id  2 | task 61309 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 9622
slot update_slots: id  2 | task 61309 | n_tokens = 8573, memory_seq_rm [8573, end)
slot update_slots: id  2 | task 61309 | prompt processing progress, n_tokens = 9558, batch.n_tokens = 985, progress = 0.993349
slot update_slots: id  2 | task 61309 | n_tokens = 9558, memory_seq_rm [9558, end)
slot update_slots: id  2 | task 61309 | prompt processing progress, n_tokens = 9622, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 61309 | prompt done, n_tokens = 9622, batch.n_tokens = 64
slot init_sampler: id  2 | task 61309 | init sampler, took 1.99 ms, tokens: text = 9622, total = 9622
slot update_slots: id  2 | task 61309 | erasing old context checkpoint (pos_min = 5451, pos_max = 6347, size = 21.034 MiB)
slot update_slots: id  2 | task 61309 | created context checkpoint 8 of 8 (pos_min = 8661, pos_max = 9557, size = 21.034 MiB)
slot print_timing: id  2 | task 61309 | 
prompt eval time =    1267.05 ms /  1049 tokens (    1.21 ms per token,   827.90 tokens per second)
       eval time =    8060.13 ms /   321 tokens (   25.11 ms per token,    39.83 tokens per second)
      total time =    9327.18 ms /  1370 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 61309 | stop processing: n_tokens = 9942, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.993 (> 0.100 thold), f_keep = 0.968
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 61632 | processing task, is_child = 0
slot update_slots: id  2 | task 61632 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 9693
slot update_slots: id  2 | task 61632 | n_tokens = 9622, memory_seq_rm [9622, end)
slot update_slots: id  2 | task 61632 | prompt processing progress, n_tokens = 9629, batch.n_tokens = 7, progress = 0.993397
slot update_slots: id  2 | task 61632 | n_tokens = 9629, memory_seq_rm [9629, end)
slot update_slots: id  2 | task 61632 | prompt processing progress, n_tokens = 9693, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 61632 | prompt done, n_tokens = 9693, batch.n_tokens = 64
slot init_sampler: id  2 | task 61632 | init sampler, took 1.59 ms, tokens: text = 9693, total = 9693
slot update_slots: id  2 | task 61632 | erasing old context checkpoint (pos_min = 5652, pos_max = 6548, size = 21.034 MiB)
slot update_slots: id  2 | task 61632 | created context checkpoint 8 of 8 (pos_min = 9045, pos_max = 9628, size = 13.694 MiB)
slot print_timing: id  2 | task 61632 | 
prompt eval time =     236.16 ms /    71 tokens (    3.33 ms per token,   300.65 tokens per second)
       eval time =     890.33 ms /    35 tokens (   25.44 ms per token,    39.31 tokens per second)
      total time =    1126.48 ms /   106 tokens
slot      release: id  2 | task 61632 | stop processing: n_tokens = 9727, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.947 (> 0.100 thold), f_keep = 0.997
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 61669 | processing task, is_child = 0
slot update_slots: id  2 | task 61669 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10239
slot update_slots: id  2 | task 61669 | n_tokens = 9693, memory_seq_rm [9693, end)
slot update_slots: id  2 | task 61669 | prompt processing progress, n_tokens = 10175, batch.n_tokens = 482, progress = 0.993749
slot update_slots: id  2 | task 61669 | n_tokens = 10175, memory_seq_rm [10175, end)
slot update_slots: id  2 | task 61669 | prompt processing progress, n_tokens = 10239, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 61669 | prompt done, n_tokens = 10239, batch.n_tokens = 64
slot init_sampler: id  2 | task 61669 | init sampler, took 2.12 ms, tokens: text = 10239, total = 10239
slot update_slots: id  2 | task 61669 | erasing old context checkpoint (pos_min = 6486, pos_max = 7382, size = 21.034 MiB)
slot update_slots: id  2 | task 61669 | created context checkpoint 8 of 8 (pos_min = 9278, pos_max = 10174, size = 21.034 MiB)
slot print_timing: id  2 | task 61669 | 
prompt eval time =     723.96 ms /   546 tokens (    1.33 ms per token,   754.19 tokens per second)
       eval time =    4186.11 ms /   161 tokens (   26.00 ms per token,    38.46 tokens per second)
      total time =    4910.07 ms /   707 tokens
slot      release: id  2 | task 61669 | stop processing: n_tokens = 10399, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.994 (> 0.100 thold), f_keep = 0.985
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 61832 | processing task, is_child = 0
slot update_slots: id  2 | task 61832 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 10304
slot update_slots: id  2 | task 61832 | n_tokens = 10239, memory_seq_rm [10239, end)
slot update_slots: id  2 | task 61832 | prompt processing progress, n_tokens = 10240, batch.n_tokens = 1, progress = 0.993789
slot update_slots: id  2 | task 61832 | n_tokens = 10240, memory_seq_rm [10240, end)
slot update_slots: id  2 | task 61832 | prompt processing progress, n_tokens = 10304, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 61832 | prompt done, n_tokens = 10304, batch.n_tokens = 64
slot init_sampler: id  2 | task 61832 | init sampler, took 1.77 ms, tokens: text = 10304, total = 10304
slot update_slots: id  2 | task 61832 | erasing old context checkpoint (pos_min = 6924, pos_max = 7820, size = 21.034 MiB)
slot update_slots: id  2 | task 61832 | created context checkpoint 8 of 8 (pos_min = 9502, pos_max = 10239, size = 17.306 MiB)
slot print_timing: id  2 | task 61832 | 
prompt eval time =     272.00 ms /    65 tokens (    4.18 ms per token,   238.97 tokens per second)
       eval time =    4351.22 ms /   172 tokens (   25.30 ms per token,    39.53 tokens per second)
      total time =    4623.22 ms /   237 tokens
slot      release: id  2 | task 61832 | stop processing: n_tokens = 10475, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.983 (> 0.100 thold), f_keep = 0.043
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 10475, total state size = 266.592 MiB
srv          load:  - looking for better prompt, base f_keep = 0.043, sim = 0.983
srv          load:  - found better prompt with f_keep = 0.251, sim = 0.987
srv        update:  - cache state: 10 prompts, 4752.750 MiB (limits: 8192.000 MiB, 64000 tokens, 250999 est)
srv        update:    - prompt 0x5b74dc0d5ef0:    1042 tokens, checkpoints:  1,    56.513 MiB
srv        update:    - prompt 0x5b74e55a53f0:   26665 tokens, checkpoints:  8,   833.285 MiB
srv        update:    - prompt 0x5b74f4b2e0a0:   50148 tokens, checkpoints:  8,  1348.434 MiB
srv        update:    - prompt 0x5b74e492c580:   35435 tokens, checkpoints:  8,   986.641 MiB
srv        update:    - prompt 0x5b74d1dcc750:     937 tokens, checkpoints:  2,    65.775 MiB
srv        update:    - prompt 0x5b74e46f02e0:    1122 tokens, checkpoints:  4,    97.338 MiB
srv        update:    - prompt 0x5b74e5014d10:    4945 tokens, checkpoints:  8,   257.754 MiB
srv        update:    - prompt 0x5b74d1ea9d00:    7736 tokens, checkpoints:  8,   355.208 MiB
srv        update:    - prompt 0x5b74e47a0060:    7117 tokens, checkpoints:  8,   342.100 MiB
srv        update:    - prompt 0x5b74f4b2e2c0:   10475 tokens, checkpoints:  8,   409.703 MiB
srv  get_availabl: prompt cache update took 535.90 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 62006 | processing task, is_child = 0
slot update_slots: id  2 | task 62006 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 461
slot update_slots: id  2 | task 62006 | n_past = 455, slot.prompt.tokens.size() = 1810, seq_id = 2, pos_min = 913, n_swa = 128
slot update_slots: id  2 | task 62006 | restored context checkpoint (pos_min = 103, pos_max = 999, size = 21.034 MiB)
slot update_slots: id  2 | task 62006 | erased invalidated context checkpoint (pos_min = 431, pos_max = 1327, n_swa = 128, size = 21.034 MiB)
slot update_slots: id  2 | task 62006 | erased invalidated context checkpoint (pos_min = 684, pos_max = 1534, n_swa = 128, size = 19.955 MiB)
slot update_slots: id  2 | task 62006 | n_tokens = 455, memory_seq_rm [455, end)
slot update_slots: id  2 | task 62006 | prompt processing progress, n_tokens = 461, batch.n_tokens = 6, progress = 1.000000
slot update_slots: id  2 | task 62006 | prompt done, n_tokens = 461, batch.n_tokens = 6
slot init_sampler: id  2 | task 62006 | init sampler, took 0.09 ms, tokens: text = 461, total = 461
slot print_timing: id  2 | task 62006 | 
prompt eval time =     274.90 ms /     6 tokens (   45.82 ms per token,    21.83 tokens per second)
       eval time =     911.84 ms /    39 tokens (   23.38 ms per token,    42.77 tokens per second)
      total time =    1186.74 ms /    45 tokens
slot      release: id  2 | task 62006 | stop processing: n_tokens = 499, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.989 (> 0.100 thold), f_keep = 0.912
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 62046 | processing task, is_child = 0
slot update_slots: id  2 | task 62046 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 460
slot update_slots: id  2 | task 62046 | n_tokens = 455, memory_seq_rm [455, end)
slot update_slots: id  2 | task 62046 | prompt processing progress, n_tokens = 460, batch.n_tokens = 5, progress = 1.000000
slot update_slots: id  2 | task 62046 | prompt done, n_tokens = 460, batch.n_tokens = 5
slot init_sampler: id  2 | task 62046 | init sampler, took 0.08 ms, tokens: text = 460, total = 460
slot print_timing: id  2 | task 62046 | 
prompt eval time =      87.60 ms /     5 tokens (   17.52 ms per token,    57.08 tokens per second)
       eval time =     821.81 ms /    31 tokens (   26.51 ms per token,    37.72 tokens per second)
      total time =     909.42 ms /    36 tokens
slot      release: id  2 | task 62046 | stop processing: n_tokens = 490, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.876 (> 0.100 thold), f_keep = 0.939
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 62078 | processing task, is_child = 0
slot update_slots: id  2 | task 62078 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 525
slot update_slots: id  2 | task 62078 | n_tokens = 460, memory_seq_rm [460, end)
slot update_slots: id  2 | task 62078 | prompt processing progress, n_tokens = 461, batch.n_tokens = 1, progress = 0.878095
slot update_slots: id  2 | task 62078 | n_tokens = 461, memory_seq_rm [461, end)
slot update_slots: id  2 | task 62078 | prompt processing progress, n_tokens = 525, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 62078 | prompt done, n_tokens = 525, batch.n_tokens = 64
slot init_sampler: id  2 | task 62078 | init sampler, took 0.10 ms, tokens: text = 525, total = 525
slot print_timing: id  2 | task 62078 | 
prompt eval time =     176.45 ms /    65 tokens (    2.71 ms per token,   368.38 tokens per second)
       eval time =    1015.13 ms /    41 tokens (   24.76 ms per token,    40.39 tokens per second)
      total time =    1191.58 ms /   106 tokens
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
slot      release: id  2 | task 62078 | stop processing: n_tokens = 565, truncated = 0
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.490 (> 0.100 thold), f_keep = 0.929
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 62121 | processing task, is_child = 0
slot update_slots: id  2 | task 62121 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 1071
slot update_slots: id  2 | task 62121 | n_tokens = 525, memory_seq_rm [525, end)
slot update_slots: id  2 | task 62121 | prompt processing progress, n_tokens = 1007, batch.n_tokens = 482, progress = 0.940243
slot update_slots: id  2 | task 62121 | n_tokens = 1007, memory_seq_rm [1007, end)
slot update_slots: id  2 | task 62121 | prompt processing progress, n_tokens = 1071, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 62121 | prompt done, n_tokens = 1071, batch.n_tokens = 64
slot init_sampler: id  2 | task 62121 | init sampler, took 0.22 ms, tokens: text = 1071, total = 1071
slot print_timing: id  2 | task 62121 | 
prompt eval time =     614.57 ms /   546 tokens (    1.13 ms per token,   888.42 tokens per second)
       eval time =    1500.32 ms /    60 tokens (   25.01 ms per token,    39.99 tokens per second)
      total time =    2114.89 ms /   606 tokens
slot      release: id  2 | task 62121 | stop processing: n_tokens = 1130, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 1.000 (> 0.100 thold), f_keep = 0.407
srv  get_availabl: updating prompt cache
srv   prompt_save:  - saving prompt with length 1130, total state size = 43.663 MiB
srv          load:  - looking for better prompt, base f_keep = 0.407, sim = 1.000
srv        update:  - cache state: 11 prompts, 4837.636 MiB (limits: 8192.000 MiB, 64000 tokens, 248508 est)
srv        update:    - prompt 0x5b74dc0d5ef0:    1042 tokens, checkpoints:  1,    56.513 MiB
srv        update:    - prompt 0x5b74e55a53f0:   26665 tokens, checkpoints:  8,   833.285 MiB
srv        update:    - prompt 0x5b74f4b2e0a0:   50148 tokens, checkpoints:  8,  1348.434 MiB
srv        update:    - prompt 0x5b74e492c580:   35435 tokens, checkpoints:  8,   986.641 MiB
srv        update:    - prompt 0x5b74d1dcc750:     937 tokens, checkpoints:  2,    65.775 MiB
srv        update:    - prompt 0x5b74e46f02e0:    1122 tokens, checkpoints:  4,    97.338 MiB
srv        update:    - prompt 0x5b74e5014d10:    4945 tokens, checkpoints:  8,   257.754 MiB
srv        update:    - prompt 0x5b74d1ea9d00:    7736 tokens, checkpoints:  8,   355.208 MiB
srv        update:    - prompt 0x5b74e47a0060:    7117 tokens, checkpoints:  8,   342.100 MiB
srv        update:    - prompt 0x5b74f4b2e2c0:   10475 tokens, checkpoints:  8,   409.703 MiB
srv        update:    - prompt 0x5b74e4bd4f00:    1130 tokens, checkpoints:  3,    84.887 MiB
srv  get_availabl: prompt cache update took 35.45 ms
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 62183 | processing task, is_child = 0
slot update_slots: id  2 | task 62183 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 460
slot update_slots: id  2 | task 62183 | n_past = 460, slot.prompt.tokens.size() = 1130, seq_id = 2, pos_min = 398, n_swa = 128
slot update_slots: id  2 | task 62183 | restored context checkpoint (pos_min = 103, pos_max = 999, size = 21.034 MiB)
slot update_slots: id  2 | task 62183 | need to evaluate at least 1 token for each active slot (n_past = 460, task.n_tokens() = 460)
slot update_slots: id  2 | task 62183 | n_past was set to 459
slot update_slots: id  2 | task 62183 | n_tokens = 459, memory_seq_rm [459, end)
slot update_slots: id  2 | task 62183 | prompt processing progress, n_tokens = 460, batch.n_tokens = 1, progress = 1.000000
slot update_slots: id  2 | task 62183 | prompt done, n_tokens = 460, batch.n_tokens = 1
slot init_sampler: id  2 | task 62183 | init sampler, took 0.18 ms, tokens: text = 460, total = 460
slot print_timing: id  2 | task 62183 | 
prompt eval time =     243.16 ms /     1 tokens (  243.16 ms per token,     4.11 tokens per second)
       eval time =     921.26 ms /    35 tokens (   26.32 ms per token,    37.99 tokens per second)
      total time =    1164.42 ms /    36 tokens
slot      release: id  2 | task 62183 | stop processing: n_tokens = 494, truncated = 0
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  update_slots: all slots are idle
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.876 (> 0.100 thold), f_keep = 0.931
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 62219 | processing task, is_child = 0
slot update_slots: id  2 | task 62219 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 525
slot update_slots: id  2 | task 62219 | n_tokens = 460, memory_seq_rm [460, end)
slot update_slots: id  2 | task 62219 | prompt processing progress, n_tokens = 461, batch.n_tokens = 1, progress = 0.878095
slot update_slots: id  2 | task 62219 | n_tokens = 461, memory_seq_rm [461, end)
slot update_slots: id  2 | task 62219 | prompt processing progress, n_tokens = 525, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 62219 | prompt done, n_tokens = 525, batch.n_tokens = 64
slot init_sampler: id  2 | task 62219 | init sampler, took 0.09 ms, tokens: text = 525, total = 525
slot print_timing: id  2 | task 62219 | 
prompt eval time =     241.45 ms /    65 tokens (    3.71 ms per token,   269.21 tokens per second)
       eval time =     840.10 ms /    35 tokens (   24.00 ms per token,    41.66 tokens per second)
      total time =    1081.55 ms /   100 tokens
slot      release: id  2 | task 62219 | stop processing: n_tokens = 559, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 1.000 (> 0.100 thold), f_keep = 0.823
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 62256 | processing task, is_child = 0
slot update_slots: id  2 | task 62256 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 460
slot update_slots: id  2 | task 62256 | need to evaluate at least 1 token for each active slot (n_past = 460, task.n_tokens() = 460)
slot update_slots: id  2 | task 62256 | n_past was set to 459
slot update_slots: id  2 | task 62256 | n_tokens = 459, memory_seq_rm [459, end)
slot update_slots: id  2 | task 62256 | prompt processing progress, n_tokens = 460, batch.n_tokens = 1, progress = 1.000000
slot update_slots: id  2 | task 62256 | prompt done, n_tokens = 460, batch.n_tokens = 1
slot init_sampler: id  2 | task 62256 | init sampler, took 0.10 ms, tokens: text = 460, total = 460
slot print_timing: id  2 | task 62256 | 
prompt eval time =      34.58 ms /     1 tokens (   34.58 ms per token,    28.92 tokens per second)
       eval time =    1006.11 ms /    35 tokens (   28.75 ms per token,    34.79 tokens per second)
      total time =    1040.69 ms /    36 tokens
slot      release: id  2 | task 62256 | stop processing: n_tokens = 494, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.876 (> 0.100 thold), f_keep = 0.931
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 62292 | processing task, is_child = 0
slot update_slots: id  2 | task 62292 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 525
slot update_slots: id  2 | task 62292 | n_tokens = 460, memory_seq_rm [460, end)
slot update_slots: id  2 | task 62292 | prompt processing progress, n_tokens = 461, batch.n_tokens = 1, progress = 0.878095
slot update_slots: id  2 | task 62292 | n_tokens = 461, memory_seq_rm [461, end)
slot update_slots: id  2 | task 62292 | prompt processing progress, n_tokens = 525, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 62292 | prompt done, n_tokens = 525, batch.n_tokens = 64
slot init_sampler: id  2 | task 62292 | init sampler, took 0.11 ms, tokens: text = 525, total = 525
slot print_timing: id  2 | task 62292 | 
prompt eval time =     236.05 ms /    65 tokens (    3.63 ms per token,   275.36 tokens per second)
       eval time =    1170.65 ms /    48 tokens (   24.39 ms per token,    41.00 tokens per second)
      total time =    1406.70 ms /   113 tokens
slot      release: id  2 | task 62292 | stop processing: n_tokens = 572, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 1.000 (> 0.100 thold), f_keep = 0.804
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 62342 | processing task, is_child = 0
slot update_slots: id  2 | task 62342 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 460
slot update_slots: id  2 | task 62342 | need to evaluate at least 1 token for each active slot (n_past = 460, task.n_tokens() = 460)
slot update_slots: id  2 | task 62342 | n_past was set to 459
slot update_slots: id  2 | task 62342 | n_tokens = 459, memory_seq_rm [459, end)
slot update_slots: id  2 | task 62342 | prompt processing progress, n_tokens = 460, batch.n_tokens = 1, progress = 1.000000
slot update_slots: id  2 | task 62342 | prompt done, n_tokens = 460, batch.n_tokens = 1
slot init_sampler: id  2 | task 62342 | init sampler, took 0.09 ms, tokens: text = 460, total = 460
slot print_timing: id  2 | task 62342 | 
prompt eval time =      34.16 ms /     1 tokens (   34.16 ms per token,    29.27 tokens per second)
       eval time =     952.54 ms /    38 tokens (   25.07 ms per token,    39.89 tokens per second)
      total time =     986.70 ms /    39 tokens
slot      release: id  2 | task 62342 | stop processing: n_tokens = 497, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
srv  params_from_: Chat format: GPT-OSS
slot get_availabl: id  2 | task -1 | selected slot by LCP similarity, sim_best = 0.876 (> 0.100 thold), f_keep = 0.926
slot launch_slot_: id  2 | task -1 | sampler chain: logits -> ?penalties -> ?dry -> ?top-n-sigma -> top-k -> ?typical -> top-p -> min-p -> ?xtc -> temp-ext -> dist 
slot launch_slot_: id  2 | task 62381 | processing task, is_child = 0
slot update_slots: id  2 | task 62381 | new prompt, n_ctx_slot = 64000, n_keep = 0, task.n_tokens = 525
slot update_slots: id  2 | task 62381 | n_tokens = 460, memory_seq_rm [460, end)
slot update_slots: id  2 | task 62381 | prompt processing progress, n_tokens = 461, batch.n_tokens = 1, progress = 0.878095
slot update_slots: id  2 | task 62381 | n_tokens = 461, memory_seq_rm [461, end)
slot update_slots: id  2 | task 62381 | prompt processing progress, n_tokens = 525, batch.n_tokens = 64, progress = 1.000000
slot update_slots: id  2 | task 62381 | prompt done, n_tokens = 525, batch.n_tokens = 64
slot init_sampler: id  2 | task 62381 | init sampler, took 0.09 ms, tokens: text = 525, total = 525
slot print_timing: id  2 | task 62381 | 
prompt eval time =     178.85 ms /    65 tokens (    2.75 ms per token,   363.44 tokens per second)
       eval time =     630.89 ms /    27 tokens (   23.37 ms per token,    42.80 tokens per second)
      total time =     809.74 ms /    92 tokens
slot      release: id  2 | task 62381 | stop processing: n_tokens = 551, truncated = 0
srv  update_slots: all slots are idle
srv  log_server_r: request: POST /v1/chat/completions 127.0.0.1 200
